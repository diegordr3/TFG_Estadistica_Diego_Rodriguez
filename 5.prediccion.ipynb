{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20654e9d",
   "metadata": {},
   "source": [
    "Primero, preprocesamiento para ver cuantas variables se van a meter a la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f211d",
   "metadata": {},
   "source": [
    "Actual con diferencias, previo no, para hacer dos GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c230e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_diferencias=pd.read_csv('../data/actual_diferencias_preproc_escalado.csv')\n",
    "previos=pd.read_csv('../data/previos_preproc_escalado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc62bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9259, 19) (925900, 33)\n"
     ]
    }
   ],
   "source": [
    "print(actual_diferencias.shape, previos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fe8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(previos.shape[0]/actual_diferencias.shape[0])\n",
    "num_previos=int(previos.shape[0]/actual_diferencias.shape[0])\n",
    "print(num_previos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8020b0e",
   "metadata": {},
   "source": [
    "## RED NEURONAL PARA PREDECIR LA PROBABILIDAD DE GANAR SEGUN EL MERCADO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139685d",
   "metadata": {},
   "source": [
    "Primero valorar cuantas filas se pierden por predecir esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ae2c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_home</th>\n",
       "      <th>probability_away</th>\n",
       "      <th>vigorish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8466.000000</td>\n",
       "      <td>8466.000000</td>\n",
       "      <td>8466.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.511669</td>\n",
       "      <td>0.488331</td>\n",
       "      <td>0.057569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.206690</td>\n",
       "      <td>0.206690</td>\n",
       "      <td>0.011553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.020406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.354949</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.054945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.645051</td>\n",
       "      <td>0.063348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.108140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       probability_home  probability_away     vigorish\n",
       "count       8466.000000       8466.000000  8466.000000\n",
       "mean           0.511669          0.488331     0.057569\n",
       "std            0.206690          0.206690     0.011553\n",
       "min            0.023902          0.023902     0.020406\n",
       "25%            0.354949          0.337349     0.050000\n",
       "50%            0.514706          0.485294     0.054945\n",
       "75%            0.662651          0.645051     0.063348\n",
       "max            0.976098          0.976098     0.108140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_diferencias[['probability_home', 'probability_away', 'vigorish']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e6261",
   "metadata": {},
   "source": [
    "Merece la pena eliminar 793 filas de 9259, es un porcentaje muy bajo. Además serán torneos menores (rondas clasificatorias y asi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d251943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "probability_home    793\n",
       "probability_away    793\n",
       "vigorish            793\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_diferencias[['probability_home', 'probability_away', 'vigorish']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6859fd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9259, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_diferencias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d754114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8466, 19) (846600, 33)\n"
     ]
    }
   ],
   "source": [
    "filas_nulas = actual_diferencias[actual_diferencias.isnull().any(axis=1)].index.tolist()\n",
    "indices_previos_eliminar = []\n",
    "for idx in filas_nulas:\n",
    "    inicio = idx * num_previos\n",
    "    fin = inicio + num_previos  # no es inclusivo\n",
    "    indices_previos_eliminar.extend(range(inicio, fin))\n",
    "actual_diferencias.drop(index=filas_nulas, inplace=True)\n",
    "previos.drop(index=indices_previos_eliminar, inplace=True)\n",
    "print(actual_diferencias.shape, previos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a19d4a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>porcentajeActualRanking</th>\n",
       "      <th>porcentajeBestRanking</th>\n",
       "      <th>difHeight</th>\n",
       "      <th>difWeight</th>\n",
       "      <th>probability_away</th>\n",
       "      <th>groundType_Grass</th>\n",
       "      <th>groundType_Hardcourt_indoor</th>\n",
       "      <th>groundType_Hardcourt_outdoor</th>\n",
       "      <th>groundType_Red_clay</th>\n",
       "      <th>difLaterality_00</th>\n",
       "      <th>difLaterality_01</th>\n",
       "      <th>difLaterality_10</th>\n",
       "      <th>difLaterality_11</th>\n",
       "      <th>best_five</th>\n",
       "      <th>difYear</th>\n",
       "      <th>year_week_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.096934</td>\n",
       "      <td>-0.520517</td>\n",
       "      <td>-1.044343</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.766284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.859275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.177778</td>\n",
       "      <td>-0.246956</td>\n",
       "      <td>0.738353</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.943432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.087356</td>\n",
       "      <td>0.639723</td>\n",
       "      <td>0.528624</td>\n",
       "      <td>0.561874</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198134</td>\n",
       "      <td>1.104192</td>\n",
       "      <td>-0.205428</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.153211</td>\n",
       "      <td>-0.777271</td>\n",
       "      <td>0.528624</td>\n",
       "      <td>1.006422</td>\n",
       "      <td>0.422572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.290819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   porcentajeActualRanking  porcentajeBestRanking  difHeight  difWeight  \\\n",
       "0                -0.096934              -0.520517  -1.044343   0.228463   \n",
       "1                 0.177778              -0.246956   0.738353   0.228463   \n",
       "2                -0.087356               0.639723   0.528624   0.561874   \n",
       "3                 0.198134               1.104192  -0.205428   0.228463   \n",
       "4                -0.153211              -0.777271   0.528624   1.006422   \n",
       "\n",
       "   probability_away  groundType_Grass  groundType_Hardcourt_indoor  \\\n",
       "0          0.766284                 0                            0   \n",
       "1          0.392308                 0                            0   \n",
       "2          0.441489                 0                            0   \n",
       "3          0.135802                 0                            0   \n",
       "4          0.422572                 0                            0   \n",
       "\n",
       "   groundType_Hardcourt_outdoor  groundType_Red_clay  difLaterality_00  \\\n",
       "0                             1                    0                 0   \n",
       "1                             1                    0                 0   \n",
       "2                             1                    0                 0   \n",
       "3                             1                    0                 0   \n",
       "4                             1                    0                 0   \n",
       "\n",
       "   difLaterality_01  difLaterality_10  difLaterality_11  best_five   difYear  \\\n",
       "0                 0                 1                 0          0  0.859275   \n",
       "1                 0                 0                 1          0 -0.943432   \n",
       "2                 0                 0                 1          0  0.801265   \n",
       "3                 0                 0                 1          0  0.091960   \n",
       "4                 0                 0                 1          0 -0.290819   \n",
       "\n",
       "   year_week_id  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vigorish=actual_diferencias['vigorish']\n",
    "actual_diferencias=actual_diferencias.drop(columns=['vigorish', 'winnerCode', 'probability_home'])\n",
    "actual_diferencias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d08846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8466, 16) (423300, 33) (423300, 33)\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "num_filas = len(previos)\n",
    "tamano_bloque=int(num_previos/2)\n",
    "# Crear listas para almacenar los índices\n",
    "indices_home = []\n",
    "indices_away = []\n",
    "\n",
    "# Para cada bloque, extraer los índices correspondientes\n",
    "for i in range(actual_diferencias.shape[0]):\n",
    "    inicio_bloque = i * tamano_bloque * 2\n",
    "    \n",
    "    # Índices para home (primeras 50 filas del bloque)\n",
    "    indices_home.extend(range(inicio_bloque, inicio_bloque + tamano_bloque))\n",
    "    \n",
    "    # Índices para away (siguientes 50 filas del bloque)\n",
    "    indices_away.extend(range(inicio_bloque + tamano_bloque, inicio_bloque + tamano_bloque * 2))\n",
    "    \n",
    "# Crear DataFrames usando los índices\n",
    "previos_home = previos.iloc[indices_home].reset_index(drop=True)\n",
    "previos_away = previos.iloc[indices_away].reset_index(drop=True)\n",
    "actual_diferencias=actual_diferencias.reset_index(drop=True)\n",
    "print(actual_diferencias.shape, previos_home.shape, previos_away.shape)\n",
    "print(actual_diferencias.isnull().sum().sum(), previos_home.isnull().sum().sum(), previos_away.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e69f127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>porcentajeActualRanking</th>\n",
       "      <th>porcentajeBestRanking</th>\n",
       "      <th>difHeight</th>\n",
       "      <th>difWeight</th>\n",
       "      <th>probability_away</th>\n",
       "      <th>groundType_Grass</th>\n",
       "      <th>groundType_Hardcourt_indoor</th>\n",
       "      <th>groundType_Hardcourt_outdoor</th>\n",
       "      <th>groundType_Red_clay</th>\n",
       "      <th>difLaterality_00</th>\n",
       "      <th>difLaterality_01</th>\n",
       "      <th>difLaterality_10</th>\n",
       "      <th>difLaterality_11</th>\n",
       "      <th>best_five</th>\n",
       "      <th>difYear</th>\n",
       "      <th>year_week_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.096934</td>\n",
       "      <td>-0.520517</td>\n",
       "      <td>-1.044343</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.766284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.859275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.177778</td>\n",
       "      <td>-0.246956</td>\n",
       "      <td>0.738353</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.943432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.087356</td>\n",
       "      <td>0.639723</td>\n",
       "      <td>0.528624</td>\n",
       "      <td>0.561874</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198134</td>\n",
       "      <td>1.104192</td>\n",
       "      <td>-0.205428</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.153211</td>\n",
       "      <td>-0.777271</td>\n",
       "      <td>0.528624</td>\n",
       "      <td>1.006422</td>\n",
       "      <td>0.422572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.290819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   porcentajeActualRanking  porcentajeBestRanking  difHeight  difWeight  \\\n",
       "0                -0.096934              -0.520517  -1.044343   0.228463   \n",
       "1                 0.177778              -0.246956   0.738353   0.228463   \n",
       "2                -0.087356               0.639723   0.528624   0.561874   \n",
       "3                 0.198134               1.104192  -0.205428   0.228463   \n",
       "4                -0.153211              -0.777271   0.528624   1.006422   \n",
       "\n",
       "   probability_away  groundType_Grass  groundType_Hardcourt_indoor  \\\n",
       "0          0.766284                 0                            0   \n",
       "1          0.392308                 0                            0   \n",
       "2          0.441489                 0                            0   \n",
       "3          0.135802                 0                            0   \n",
       "4          0.422572                 0                            0   \n",
       "\n",
       "   groundType_Hardcourt_outdoor  groundType_Red_clay  difLaterality_00  \\\n",
       "0                             1                    0                 0   \n",
       "1                             1                    0                 0   \n",
       "2                             1                    0                 0   \n",
       "3                             1                    0                 0   \n",
       "4                             1                    0                 0   \n",
       "\n",
       "   difLaterality_01  difLaterality_10  difLaterality_11  best_five   difYear  \\\n",
       "0                 0                 1                 0          0  0.859275   \n",
       "1                 0                 0                 1          0 -0.943432   \n",
       "2                 0                 0                 1          0  0.801265   \n",
       "3                 0                 0                 1          0  0.091960   \n",
       "4                 0                 0                 1          0 -0.290819   \n",
       "\n",
       "   year_week_id  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_diferencias.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8e1d5",
   "metadata": {},
   "source": [
    "#### RED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34095e9",
   "metadata": {},
   "source": [
    "semanas 0-37: 2021, 38-79: 2022, 80-122: 2023, 123-164: 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b7fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventana 1 de 143\n",
      "Entrenando con semanas: [0 1 2 3 4 5 6 7 8 9], testeando en semanas [10 11 12], len train: 506, len test: 140, porcentaje: 0.78\n",
      "Ventana 1, Época: 0, Train Loss: 0.04670256, Test Loss: 0.03795493,R2: -0.0132, MAE: 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_19644\\691616427.py:289: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_visualization_global = pd.concat([df_visualization_global, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventana 1, Época: 5, Train Loss: 0.04027548, Test Loss: 0.03677423,R2: 0.0183, MAE: 0.1522\n",
      "Ventana 1, Época: 10, Train Loss: 0.03228220, Test Loss: 0.03839981,R2: -0.0251, MAE: 0.1557\n",
      "Ventana 1, Época: 12, Train Loss: 0.03071227, Test Loss: 0.03869670, R2: -0.0330, MAE: 0.1564\n",
      "Early stopping en la ventana 1, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 1\n",
      "-------------------\n",
      "Ventana 2 de 143\n",
      "Entrenando con semanas: [ 1  2  3  4  5  6  7  8  9 10], testeando en semanas [11 12 13], len train: 498, len test: 121, porcentaje: 0.80\n",
      "Iniciando ventana 2 con pesos de la ventana anterior\n",
      "Ventana 2, Época: 0, Train Loss: 0.03661659, Test Loss: 0.03736274,R2: 0.0216, MAE: 0.1532\n",
      "Ventana 2, Época: 5, Train Loss: 0.02989524, Test Loss: 0.03652114,R2: 0.0436, MAE: 0.1524\n",
      "Ventana 2, Época: 9, Train Loss: 0.02387996, Test Loss: 0.03938857, R2: -0.0315, MAE: 0.1587\n",
      "Early stopping en la ventana 2, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 2\n",
      "-------------------\n",
      "Ventana 3 de 143\n",
      "Entrenando con semanas: [ 2  3  4  5  6  7  8  9 10 11], testeando en semanas [12 13 14], len train: 497, len test: 106, porcentaje: 0.82\n",
      "Iniciando ventana 3 con pesos de la ventana anterior\n",
      "Ventana 3, Época: 0, Train Loss: 0.03118068, Test Loss: 0.04641212,R2: -0.0176, MAE: 0.1802\n",
      "Ventana 3, Época: 5, Train Loss: 0.02555625, Test Loss: 0.04459505,R2: 0.0223, MAE: 0.1778\n",
      "Ventana 3, Época: 10, Train Loss: 0.02028081, Test Loss: 0.04371357,R2: 0.0416, MAE: 0.1719\n",
      "Ventana 3, Época: 12, Train Loss: 0.01950396, Test Loss: 0.04455085, R2: 0.0232, MAE: 0.1713\n",
      "Early stopping en la ventana 3, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 3\n",
      "-------------------\n",
      "Ventana 4 de 143\n",
      "Entrenando con semanas: [ 3  4  5  6  7  8  9 10 11 12], testeando en semanas [13 14 15], len train: 431, len test: 109, porcentaje: 0.80\n",
      "Iniciando ventana 4 con pesos de la ventana anterior\n",
      "Ventana 4, Época: 0, Train Loss: 0.02272063, Test Loss: 0.03868246,R2: 0.1284, MAE: 0.1666\n",
      "Ventana 4, Época: 5, Train Loss: 0.01957628, Test Loss: 0.03333494,R2: 0.2489, MAE: 0.1539\n",
      "Ventana 4, Época: 10, Train Loss: 0.01711178, Test Loss: 0.02871194,R2: 0.3531, MAE: 0.1398\n",
      "Ventana 4, Época: 15, Train Loss: 0.01524388, Test Loss: 0.02539588,R2: 0.4278, MAE: 0.1283\n",
      "Ventana 4, Época: 20, Train Loss: 0.01287159, Test Loss: 0.02218228,R2: 0.5002, MAE: 0.1206\n",
      "Ventana 4, Época: 25, Train Loss: 0.01064760, Test Loss: 0.01770885,R2: 0.6010, MAE: 0.1102\n",
      "Ventana 4, Época: 30, Train Loss: 0.00919755, Test Loss: 0.01332165,R2: 0.6998, MAE: 0.0936\n",
      "Ventana 4, Época: 35, Train Loss: 0.00839558, Test Loss: 0.01273279,R2: 0.7131, MAE: 0.0919\n",
      "Ventana 4, Época: 38, Train Loss: 0.00887106, Test Loss: 0.01193697, R2: 0.7310, MAE: 0.0928\n",
      "Early stopping en la ventana 4, época 38\n",
      "Mejor modelo guardado en la época  33 para la ventana 4\n",
      "-------------------\n",
      "Ventana 5 de 143\n",
      "Entrenando con semanas: [ 4  5  6  7  8  9 10 11 12 13], testeando en semanas [14 15 16], len train: 425, len test: 227, porcentaje: 0.65\n",
      "Iniciando ventana 5 con pesos de la ventana anterior\n",
      "Ventana 5, Época: 0, Train Loss: 0.00807303, Test Loss: 0.01353127,R2: 0.6937, MAE: 0.0955\n",
      "Ventana 5, Época: 5, Train Loss: 0.00782886, Test Loss: 0.01297030,R2: 0.7064, MAE: 0.0947\n",
      "Ventana 5, Época: 10, Train Loss: 0.00664739, Test Loss: 0.01165219,R2: 0.7363, MAE: 0.0870\n",
      "Ventana 5, Época: 15, Train Loss: 0.00644409, Test Loss: 0.01144211,R2: 0.7410, MAE: 0.0869\n",
      "Ventana 5, Época: 18, Train Loss: 0.00592227, Test Loss: 0.01144858, R2: 0.7409, MAE: 0.0871\n",
      "Early stopping en la ventana 5, época 18\n",
      "Mejor modelo guardado en la época  13 para la ventana 5\n",
      "-------------------\n",
      "Ventana 6 de 143\n",
      "Entrenando con semanas: [ 5  6  7  8  9 10 11 12 13 14], testeando en semanas [15 16 17], len train: 469, len test: 265, porcentaje: 0.64\n",
      "Iniciando ventana 6 con pesos de la ventana anterior\n",
      "Ventana 6, Época: 0, Train Loss: 0.00684322, Test Loss: 0.01238818,R2: 0.7578, MAE: 0.0901\n",
      "Ventana 6, Época: 5, Train Loss: 0.00682432, Test Loss: 0.01390662,R2: 0.7281, MAE: 0.0961\n",
      "Ventana 6, Época: 9, Train Loss: 0.00668461, Test Loss: 0.01303027, R2: 0.7452, MAE: 0.0933\n",
      "Early stopping en la ventana 6, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 6\n",
      "-------------------\n",
      "Ventana 7 de 143\n",
      "Entrenando con semanas: [ 6  7  8  9 10 11 12 13 14 15], testeando en semanas [16 17 18], len train: 489, len test: 225, porcentaje: 0.68\n",
      "Iniciando ventana 7 con pesos de la ventana anterior\n",
      "Ventana 7, Época: 0, Train Loss: 0.00731936, Test Loss: 0.01313678,R2: 0.7525, MAE: 0.0939\n",
      "Ventana 7, Época: 5, Train Loss: 0.00640154, Test Loss: 0.01258998,R2: 0.7628, MAE: 0.0921\n",
      "Ventana 7, Época: 10, Train Loss: 0.00547763, Test Loss: 0.01090150,R2: 0.7946, MAE: 0.0848\n",
      "Ventana 7, Época: 15, Train Loss: 0.00568936, Test Loss: 0.01155617, R2: 0.7823, MAE: 0.0881\n",
      "Early stopping en la ventana 7, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 7\n",
      "-------------------\n",
      "Ventana 8 de 143\n",
      "Entrenando con semanas: [ 7  8  9 10 11 12 13 14 15 16], testeando en semanas [17 18 19], len train: 576, len test: 164, porcentaje: 0.78\n",
      "Iniciando ventana 8 con pesos de la ventana anterior\n",
      "Ventana 8, Época: 0, Train Loss: 0.00634448, Test Loss: 0.01981288,R2: 0.6312, MAE: 0.1102\n",
      "Ventana 8, Época: 5, Train Loss: 0.00688662, Test Loss: 0.01488198,R2: 0.7230, MAE: 0.0977\n",
      "Ventana 8, Época: 6, Train Loss: 0.00594113, Test Loss: 0.01595781, R2: 0.7030, MAE: 0.0996\n",
      "Early stopping en la ventana 8, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 8\n",
      "-------------------\n",
      "Ventana 9 de 143\n",
      "Entrenando con semanas: [ 8  9 10 11 12 13 14 15 16 17], testeando en semanas [18 19 20], len train: 593, len test: 175, porcentaje: 0.77\n",
      "Iniciando ventana 9 con pesos de la ventana anterior\n",
      "Ventana 9, Época: 0, Train Loss: 0.00873210, Test Loss: 0.03661901,R2: -0.1127, MAE: 0.1541\n",
      "Ventana 9, Época: 5, Train Loss: 0.00747369, Test Loss: 0.02568525,R2: 0.2195, MAE: 0.1241\n",
      "Ventana 9, Época: 6, Train Loss: 0.01021414, Test Loss: 0.02590052, R2: 0.2130, MAE: 0.1260\n",
      "Early stopping en la ventana 9, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 9\n",
      "-------------------\n",
      "Ventana 10 de 143\n",
      "Entrenando con semanas: [ 9 10 11 12 13 14 15 16 17 18], testeando en semanas [19 20 21], len train: 499, len test: 273, porcentaje: 0.65\n",
      "Iniciando ventana 10 con pesos de la ventana anterior\n",
      "Ventana 10, Época: 0, Train Loss: 0.00814532, Test Loss: 0.04555291,R2: -0.1183, MAE: 0.1741\n",
      "Ventana 10, Época: 5, Train Loss: 0.01122253, Test Loss: 0.02925333,R2: 0.2818, MAE: 0.1343\n",
      "Ventana 10, Época: 7, Train Loss: 0.01006734, Test Loss: 0.03143998, R2: 0.2282, MAE: 0.1395\n",
      "Early stopping en la ventana 10, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 10\n",
      "-------------------\n",
      "Ventana 11 de 143\n",
      "Entrenando con semanas: [10 11 12 13 14 15 16 17 18 19], testeando en semanas [20 21 22], len train: 535, len test: 227, porcentaje: 0.70\n",
      "Iniciando ventana 11 con pesos de la ventana anterior\n",
      "Ventana 11, Época: 0, Train Loss: 0.01363914, Test Loss: 0.05537386,R2: -0.2393, MAE: 0.1955\n",
      "Ventana 11, Época: 5, Train Loss: 0.00865178, Test Loss: 0.03578084,R2: 0.1992, MAE: 0.1534\n",
      "Ventana 11, Época: 10, Train Loss: 0.01035319, Test Loss: 0.02630243,R2: 0.4113, MAE: 0.1245\n",
      "Ventana 11, Época: 15, Train Loss: 0.01012591, Test Loss: 0.03065624, R2: 0.3139, MAE: 0.1331\n",
      "Early stopping en la ventana 11, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 11\n",
      "-------------------\n",
      "Ventana 12 de 143\n",
      "Entrenando con semanas: [11 12 13 14 15 16 17 18 19 20], testeando en semanas [21 22 23], len train: 616, len test: 149, porcentaje: 0.81\n",
      "Iniciando ventana 12 con pesos de la ventana anterior\n",
      "Ventana 12, Época: 0, Train Loss: 0.01093843, Test Loss: 0.02239923,R2: 0.5760, MAE: 0.1159\n",
      "Ventana 12, Época: 5, Train Loss: 0.01064162, Test Loss: 0.01976130,R2: 0.6259, MAE: 0.1076\n",
      "Ventana 12, Época: 10, Train Loss: 0.00950961, Test Loss: 0.01838261,R2: 0.6520, MAE: 0.1031\n",
      "Ventana 12, Época: 15, Train Loss: 0.00842063, Test Loss: 0.01820343,R2: 0.6554, MAE: 0.1028\n",
      "Ventana 12, Época: 20, Train Loss: 0.00765377, Test Loss: 0.01719753,R2: 0.6744, MAE: 0.1007\n",
      "Ventana 12, Época: 25, Train Loss: 0.00685877, Test Loss: 0.01716575,R2: 0.6750, MAE: 0.1009\n",
      "Ventana 12, Época: 30, Train Loss: 0.00623858, Test Loss: 0.01677145,R2: 0.6825, MAE: 0.1000\n",
      "Ventana 12, Época: 35, Train Loss: 0.00607029, Test Loss: 0.01691300, R2: 0.6798, MAE: 0.1013\n",
      "Early stopping en la ventana 12, época 35\n",
      "Mejor modelo guardado en la época  30 para la ventana 12\n",
      "-------------------\n",
      "Ventana 13 de 143\n",
      "Entrenando con semanas: [12 13 14 15 16 17 18 19 20 21], testeando en semanas [22 23 25], len train: 654, len test: 88, porcentaje: 0.88\n",
      "Iniciando ventana 13 con pesos de la ventana anterior\n",
      "Ventana 13, Época: 0, Train Loss: 0.00862807, Test Loss: 0.01388847,R2: 0.5829, MAE: 0.0976\n",
      "Ventana 13, Época: 5, Train Loss: 0.00764000, Test Loss: 0.01351545,R2: 0.5941, MAE: 0.0964\n",
      "Ventana 13, Época: 10, Train Loss: 0.00681236, Test Loss: 0.01295739,R2: 0.6109, MAE: 0.0939\n",
      "Ventana 13, Época: 15, Train Loss: 0.00655577, Test Loss: 0.01278325,R2: 0.6161, MAE: 0.0929\n",
      "Ventana 13, Época: 17, Train Loss: 0.00667485, Test Loss: 0.01309026, R2: 0.6069, MAE: 0.0925\n",
      "Early stopping en la ventana 13, época 17\n",
      "Mejor modelo guardado en la época  12 para la ventana 13\n",
      "-------------------\n",
      "Ventana 14 de 143\n",
      "Entrenando con semanas: [13 14 15 16 17 18 19 20 21 22], testeando en semanas [23 25 26], len train: 622, len test: 120, porcentaje: 0.84\n",
      "Iniciando ventana 14 con pesos de la ventana anterior\n",
      "Ventana 14, Época: 0, Train Loss: 0.00747126, Test Loss: 0.01435198,R2: 0.4667, MAE: 0.0971\n",
      "Ventana 14, Época: 5, Train Loss: 0.00655155, Test Loss: 0.01511733, R2: 0.4382, MAE: 0.0995\n",
      "Early stopping en la ventana 14, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 14\n",
      "-------------------\n",
      "Ventana 15 de 143\n",
      "Entrenando con semanas: [14 15 16 17 18 19 20 21 22 23], testeando en semanas [25 26 27], len train: 644, len test: 148, porcentaje: 0.81\n",
      "Iniciando ventana 15 con pesos de la ventana anterior\n",
      "Ventana 15, Época: 0, Train Loss: 0.00738834, Test Loss: 0.01371918,R2: 0.5338, MAE: 0.0941\n",
      "Ventana 15, Época: 5, Train Loss: 0.00704992, Test Loss: 0.01359182,R2: 0.5382, MAE: 0.0931\n",
      "Ventana 15, Época: 9, Train Loss: 0.00645790, Test Loss: 0.01366997, R2: 0.5355, MAE: 0.0933\n",
      "Early stopping en la ventana 15, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 15\n",
      "-------------------\n",
      "Ventana 16 de 143\n",
      "Entrenando con semanas: [15 16 17 18 19 20 21 22 23 25], testeando en semanas [26 27 28], len train: 636, len test: 204, porcentaje: 0.76\n",
      "Iniciando ventana 16 con pesos de la ventana anterior\n",
      "Ventana 16, Época: 0, Train Loss: 0.00744201, Test Loss: 0.01561498,R2: 0.4020, MAE: 0.1009\n",
      "Ventana 16, Época: 5, Train Loss: 0.00684234, Test Loss: 0.01426957,R2: 0.4536, MAE: 0.0964\n",
      "Ventana 16, Época: 10, Train Loss: 0.00593809, Test Loss: 0.01410451,R2: 0.4599, MAE: 0.0957\n",
      "Ventana 16, Época: 15, Train Loss: 0.00599808, Test Loss: 0.01390695,R2: 0.4674, MAE: 0.0954\n",
      "Ventana 16, Época: 17, Train Loss: 0.00544382, Test Loss: 0.01408343, R2: 0.4607, MAE: 0.0954\n",
      "Early stopping en la ventana 16, época 17\n",
      "Mejor modelo guardado en la época  12 para la ventana 16\n",
      "-------------------\n",
      "Ventana 17 de 143\n",
      "Entrenando con semanas: [16 17 18 19 20 21 22 23 25 26], testeando en semanas [27 28 29], len train: 633, len test: 267, porcentaje: 0.70\n",
      "Iniciando ventana 17 con pesos de la ventana anterior\n",
      "Ventana 17, Época: 0, Train Loss: 0.00677271, Test Loss: 0.01371478,R2: 0.6651, MAE: 0.0938\n",
      "Ventana 17, Época: 5, Train Loss: 0.00602090, Test Loss: 0.01358082,R2: 0.6684, MAE: 0.0941\n",
      "Ventana 17, Época: 10, Train Loss: 0.00580140, Test Loss: 0.01290445,R2: 0.6849, MAE: 0.0911\n",
      "Ventana 17, Época: 15, Train Loss: 0.00477386, Test Loss: 0.01244611,R2: 0.6961, MAE: 0.0894\n",
      "Ventana 17, Época: 20, Train Loss: 0.00454938, Test Loss: 0.01253611,R2: 0.6939, MAE: 0.0901\n",
      "Ventana 17, Época: 23, Train Loss: 0.00438033, Test Loss: 0.01281694, R2: 0.6870, MAE: 0.0917\n",
      "Early stopping en la ventana 17, época 23\n",
      "Mejor modelo guardado en la época  18 para la ventana 17\n",
      "-------------------\n",
      "Ventana 18 de 143\n",
      "Entrenando con semanas: [17 18 19 20 21 22 23 25 26 27], testeando en semanas [28 29 30], len train: 565, len test: 224, porcentaje: 0.72\n",
      "Iniciando ventana 18 con pesos de la ventana anterior\n",
      "Ventana 18, Época: 0, Train Loss: 0.00506421, Test Loss: 0.01469880,R2: 0.6722, MAE: 0.0982\n",
      "Ventana 18, Época: 5, Train Loss: 0.00474112, Test Loss: 0.01272480,R2: 0.7162, MAE: 0.0906\n",
      "Ventana 18, Época: 10, Train Loss: 0.00422911, Test Loss: 0.01360979, R2: 0.6965, MAE: 0.0939\n",
      "Early stopping en la ventana 18, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 18\n",
      "-------------------\n",
      "Ventana 19 de 143\n",
      "Entrenando con semanas: [18 19 20 21 22 23 25 26 27 28], testeando en semanas [29 30 31], len train: 575, len test: 179, porcentaje: 0.76\n",
      "Iniciando ventana 19 con pesos de la ventana anterior\n",
      "Ventana 19, Época: 0, Train Loss: 0.00656376, Test Loss: 0.01546010,R2: 0.7333, MAE: 0.0986\n",
      "Ventana 19, Época: 5, Train Loss: 0.00670667, Test Loss: 0.01141200,R2: 0.8032, MAE: 0.0854\n",
      "Ventana 19, Época: 10, Train Loss: 0.00484604, Test Loss: 0.00875240,R2: 0.8490, MAE: 0.0749\n",
      "Ventana 19, Época: 15, Train Loss: 0.00469122, Test Loss: 0.00904137,R2: 0.8441, MAE: 0.0762\n",
      "Ventana 19, Época: 19, Train Loss: 0.00393476, Test Loss: 0.00927244, R2: 0.8401, MAE: 0.0769\n",
      "Early stopping en la ventana 19, época 19\n",
      "Mejor modelo guardado en la época  14 para la ventana 19\n",
      "-------------------\n",
      "Ventana 20 de 143\n",
      "Entrenando con semanas: [19 20 21 22 23 25 26 27 28 29], testeando en semanas [30 31 32], len train: 675, len test: 103, porcentaje: 0.87\n",
      "Iniciando ventana 20 con pesos de la ventana anterior\n",
      "Ventana 20, Época: 0, Train Loss: 0.00529987, Test Loss: 0.00836854,R2: 0.8161, MAE: 0.0710\n",
      "Ventana 20, Época: 5, Train Loss: 0.00559939, Test Loss: 0.00540004,R2: 0.8813, MAE: 0.0568\n",
      "Ventana 20, Época: 10, Train Loss: 0.00413565, Test Loss: 0.00554198,R2: 0.8782, MAE: 0.0580\n",
      "Ventana 20, Época: 15, Train Loss: 0.00366528, Test Loss: 0.00493670,R2: 0.8915, MAE: 0.0540\n",
      "Ventana 20, Época: 20, Train Loss: 0.00359670, Test Loss: 0.00485161,R2: 0.8934, MAE: 0.0539\n",
      "Ventana 20, Época: 25, Train Loss: 0.00350416, Test Loss: 0.00458990,R2: 0.8991, MAE: 0.0518\n",
      "Ventana 20, Época: 30, Train Loss: 0.00306048, Test Loss: 0.00485277,R2: 0.8934, MAE: 0.0543\n",
      "Ventana 20, Época: 35, Train Loss: 0.00266811, Test Loss: 0.00435246,R2: 0.9044, MAE: 0.0502\n",
      "Ventana 20, Época: 40, Train Loss: 0.00257332, Test Loss: 0.00462186,R2: 0.8984, MAE: 0.0523\n",
      "Ventana 20, Época: 43, Train Loss: 0.00276115, Test Loss: 0.00444078, R2: 0.9024, MAE: 0.0516\n",
      "Early stopping en la ventana 20, época 43\n",
      "Mejor modelo guardado en la época  38 para la ventana 20\n",
      "-------------------\n",
      "Ventana 21 de 143\n",
      "Entrenando con semanas: [20 21 22 23 25 26 27 28 29 30], testeando en semanas [31 32 34], len train: 625, len test: 123, porcentaje: 0.84\n",
      "Iniciando ventana 21 con pesos de la ventana anterior\n",
      "Ventana 21, Época: 0, Train Loss: 0.00267329, Test Loss: 0.00618198,R2: 0.8457, MAE: 0.0620\n",
      "Ventana 21, Época: 5, Train Loss: 0.00249334, Test Loss: 0.00543853,R2: 0.8643, MAE: 0.0571\n",
      "Ventana 21, Época: 10, Train Loss: 0.00244287, Test Loss: 0.00597046, R2: 0.8510, MAE: 0.0602\n",
      "Early stopping en la ventana 21, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 21\n",
      "-------------------\n",
      "Ventana 22 de 143\n",
      "Entrenando con semanas: [21 22 23 25 26 27 28 29 30 31], testeando en semanas [32 34 35], len train: 579, len test: 119, porcentaje: 0.83\n",
      "Iniciando ventana 22 con pesos de la ventana anterior\n",
      "Ventana 22, Época: 0, Train Loss: 0.00317197, Test Loss: 0.01005316,R2: 0.7602, MAE: 0.0819\n",
      "Ventana 22, Época: 5, Train Loss: 0.00311335, Test Loss: 0.00737291,R2: 0.8241, MAE: 0.0679\n",
      "Ventana 22, Época: 6, Train Loss: 0.00367985, Test Loss: 0.00721972, R2: 0.8278, MAE: 0.0668\n",
      "Early stopping en la ventana 22, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 22\n",
      "-------------------\n",
      "Ventana 23 de 143\n",
      "Entrenando con semanas: [22 23 25 26 27 28 29 30 31 32], testeando en semanas [34 35 36], len train: 505, len test: 87, porcentaje: 0.85\n",
      "Iniciando ventana 23 con pesos de la ventana anterior\n",
      "Ventana 23, Época: 0, Train Loss: 0.00293909, Test Loss: 0.01251564,R2: 0.7175, MAE: 0.0904\n",
      "Ventana 23, Época: 5, Train Loss: 0.00368678, Test Loss: 0.00914813,R2: 0.7935, MAE: 0.0774\n",
      "Ventana 23, Época: 6, Train Loss: 0.00304369, Test Loss: 0.00898076, R2: 0.7973, MAE: 0.0765\n",
      "Early stopping en la ventana 23, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 23\n",
      "-------------------\n",
      "Ventana 24 de 143\n",
      "Entrenando con semanas: [23 25 26 27 28 29 30 31 32 34], testeando en semanas [35 36 37], len train: 521, len test: 69, porcentaje: 0.88\n",
      "Iniciando ventana 24 con pesos de la ventana anterior\n",
      "Ventana 24, Época: 0, Train Loss: 0.00347932, Test Loss: 0.00892568,R2: 0.8108, MAE: 0.0742\n",
      "Ventana 24, Época: 5, Train Loss: 0.00299980, Test Loss: 0.00839951,R2: 0.8220, MAE: 0.0699\n",
      "Ventana 24, Época: 10, Train Loss: 0.00272333, Test Loss: 0.00750264,R2: 0.8410, MAE: 0.0665\n",
      "Ventana 24, Época: 15, Train Loss: 0.00241818, Test Loss: 0.00719986,R2: 0.8474, MAE: 0.0634\n",
      "Ventana 24, Época: 20, Train Loss: 0.00242503, Test Loss: 0.00654168,R2: 0.8613, MAE: 0.0610\n",
      "Ventana 24, Época: 24, Train Loss: 0.00225931, Test Loss: 0.00665765, R2: 0.8589, MAE: 0.0615\n",
      "Early stopping en la ventana 24, época 24\n",
      "Mejor modelo guardado en la época  19 para la ventana 24\n",
      "-------------------\n",
      "Ventana 25 de 143\n",
      "Entrenando con semanas: [25 26 27 28 29 30 31 32 34 35], testeando en semanas [36 37 38], len train: 549, len test: 20, porcentaje: 0.96\n",
      "Iniciando ventana 25 con pesos de la ventana anterior\n",
      "Ventana 25, Época: 0, Train Loss: 0.00246191, Test Loss: 0.00874692,R2: 0.5341, MAE: 0.0691\n",
      "Ventana 25, Época: 5, Train Loss: 0.00253951, Test Loss: 0.00859486,R2: 0.5422, MAE: 0.0683\n",
      "Ventana 25, Época: 10, Train Loss: 0.00230896, Test Loss: 0.00760739,R2: 0.5948, MAE: 0.0666\n",
      "Ventana 25, Época: 15, Train Loss: 0.00203240, Test Loss: 0.00747079,R2: 0.6021, MAE: 0.0647\n",
      "Ventana 25, Época: 20, Train Loss: 0.00179062, Test Loss: 0.00736613,R2: 0.6077, MAE: 0.0618\n",
      "Ventana 25, Época: 25, Train Loss: 0.00188128, Test Loss: 0.00746772,R2: 0.6023, MAE: 0.0620\n",
      "Ventana 25, Época: 26, Train Loss: 0.00175778, Test Loss: 0.00735094, R2: 0.6085, MAE: 0.0606\n",
      "Early stopping en la ventana 25, época 26\n",
      "Mejor modelo guardado en la época  21 para la ventana 25\n",
      "-------------------\n",
      "Ventana 26 de 143\n",
      "Entrenando con semanas: [26 27 28 29 30 31 32 34 35 36], testeando en semanas [37 38 39], len train: 504, len test: 116, porcentaje: 0.81\n",
      "Iniciando ventana 26 con pesos de la ventana anterior\n",
      "Ventana 26, Época: 0, Train Loss: 0.00197857, Test Loss: 0.00742962,R2: 0.6140, MAE: 0.0656\n",
      "Ventana 26, Época: 5, Train Loss: 0.00172669, Test Loss: 0.00781804,R2: 0.5938, MAE: 0.0690\n",
      "Ventana 26, Época: 8, Train Loss: 0.00185967, Test Loss: 0.00754097, R2: 0.6082, MAE: 0.0671\n",
      "Early stopping en la ventana 26, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 26\n",
      "-------------------\n",
      "Ventana 27 de 143\n",
      "Entrenando con semanas: [27 28 29 30 31 32 34 35 36 37], testeando en semanas [38 39 40], len train: 470, len test: 217, porcentaje: 0.68\n",
      "Iniciando ventana 27 con pesos de la ventana anterior\n",
      "Ventana 27, Época: 0, Train Loss: 0.00217646, Test Loss: 0.01229031,R2: 0.6975, MAE: 0.0866\n",
      "Ventana 27, Época: 5, Train Loss: 0.00238400, Test Loss: 0.00854857,R2: 0.7896, MAE: 0.0709\n",
      "Ventana 27, Época: 9, Train Loss: 0.00228448, Test Loss: 0.01045730, R2: 0.7426, MAE: 0.0787\n",
      "Early stopping en la ventana 27, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 27\n",
      "-------------------\n",
      "Ventana 28 de 143\n",
      "Entrenando con semanas: [28 29 30 31 32 34 35 36 37 38], testeando en semanas [39 40 41], len train: 421, len test: 223, porcentaje: 0.65\n",
      "Iniciando ventana 28 con pesos de la ventana anterior\n",
      "Ventana 28, Época: 0, Train Loss: 0.00251637, Test Loss: 0.01616853,R2: 0.6028, MAE: 0.1005\n",
      "Ventana 28, Época: 5, Train Loss: 0.00290473, Test Loss: 0.00822079,R2: 0.7980, MAE: 0.0696\n",
      "Ventana 28, Época: 10, Train Loss: 0.00263792, Test Loss: 0.00966829,R2: 0.7625, MAE: 0.0766\n",
      "Ventana 28, Época: 14, Train Loss: 0.00211280, Test Loss: 0.01026358, R2: 0.7479, MAE: 0.0789\n",
      "Early stopping en la ventana 28, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 28\n",
      "-------------------\n",
      "Ventana 29 de 143\n",
      "Entrenando con semanas: [29 30 31 32 34 35 36 37 38 39], testeando en semanas [40 41 43], len train: 416, len test: 156, porcentaje: 0.73\n",
      "Iniciando ventana 29 con pesos de la ventana anterior\n",
      "Ventana 29, Época: 0, Train Loss: 0.00392853, Test Loss: 0.01862972,R2: 0.6634, MAE: 0.1105\n",
      "Ventana 29, Época: 5, Train Loss: 0.00477446, Test Loss: 0.01237470,R2: 0.7764, MAE: 0.0887\n",
      "Ventana 29, Época: 10, Train Loss: 0.00335236, Test Loss: 0.00807542,R2: 0.8541, MAE: 0.0698\n",
      "Ventana 29, Época: 15, Train Loss: 0.00219548, Test Loss: 0.00852329, R2: 0.8460, MAE: 0.0735\n",
      "Early stopping en la ventana 29, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 29\n",
      "-------------------\n",
      "Ventana 30 de 143\n",
      "Entrenando con semanas: [30 31 32 34 35 36 37 38 39 40], testeando en semanas [41 43 44], len train: 420, len test: 67, porcentaje: 0.86\n",
      "Iniciando ventana 30 con pesos de la ventana anterior\n",
      "Ventana 30, Época: 0, Train Loss: 0.00469843, Test Loss: 0.00653175,R2: 0.7947, MAE: 0.0643\n",
      "Ventana 30, Época: 5, Train Loss: 0.00406377, Test Loss: 0.00651911,R2: 0.7951, MAE: 0.0624\n",
      "Ventana 30, Época: 9, Train Loss: 0.00346750, Test Loss: 0.00669854, R2: 0.7895, MAE: 0.0628\n",
      "Early stopping en la ventana 30, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 30\n",
      "-------------------\n",
      "Ventana 31 de 143\n",
      "Entrenando con semanas: [31 32 34 35 36 37 38 39 40 41], testeando en semanas [43 44 45], len train: 420, len test: 117, porcentaje: 0.78\n",
      "Iniciando ventana 31 con pesos de la ventana anterior\n",
      "Ventana 31, Época: 0, Train Loss: 0.00381077, Test Loss: 0.00505779,R2: 0.8942, MAE: 0.0559\n",
      "Ventana 31, Época: 5, Train Loss: 0.00301561, Test Loss: 0.00494860,R2: 0.8965, MAE: 0.0545\n",
      "Ventana 31, Época: 10, Train Loss: 0.00285483, Test Loss: 0.00517533,R2: 0.8918, MAE: 0.0568\n",
      "Ventana 31, Época: 12, Train Loss: 0.00292127, Test Loss: 0.00480701, R2: 0.8995, MAE: 0.0541\n",
      "Early stopping en la ventana 31, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 31\n",
      "-------------------\n",
      "Ventana 32 de 143\n",
      "Entrenando con semanas: [32 34 35 36 37 38 39 40 41 43], testeando en semanas [44 45 46], len train: 393, len test: 143, porcentaje: 0.73\n",
      "Iniciando ventana 32 con pesos de la ventana anterior\n",
      "Ventana 32, Época: 0, Train Loss: 0.00345722, Test Loss: 0.00600265,R2: 0.8707, MAE: 0.0603\n",
      "Ventana 32, Época: 5, Train Loss: 0.00301826, Test Loss: 0.00597443,R2: 0.8713, MAE: 0.0599\n",
      "Ventana 32, Época: 6, Train Loss: 0.00298189, Test Loss: 0.00597511, R2: 0.8713, MAE: 0.0597\n",
      "Early stopping en la ventana 32, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 32\n",
      "-------------------\n",
      "Ventana 33 de 143\n",
      "Entrenando con semanas: [34 35 36 37 38 39 40 41 43 44], testeando en semanas [45 46 47], len train: 384, len test: 153, porcentaje: 0.72\n",
      "Iniciando ventana 33 con pesos de la ventana anterior\n",
      "Ventana 33, Época: 0, Train Loss: 0.00366239, Test Loss: 0.00679186,R2: 0.8567, MAE: 0.0647\n",
      "Ventana 33, Época: 5, Train Loss: 0.00333066, Test Loss: 0.00583635,R2: 0.8769, MAE: 0.0606\n",
      "Ventana 33, Época: 10, Train Loss: 0.00304553, Test Loss: 0.00582264,R2: 0.8772, MAE: 0.0596\n",
      "Ventana 33, Época: 11, Train Loss: 0.00276265, Test Loss: 0.00580317, R2: 0.8776, MAE: 0.0601\n",
      "Early stopping en la ventana 33, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 33\n",
      "-------------------\n",
      "Ventana 34 de 143\n",
      "Entrenando con semanas: [35 36 37 38 39 40 41 43 44 45], testeando en semanas [46 47 48], len train: 414, len test: 161, porcentaje: 0.72\n",
      "Iniciando ventana 34 con pesos de la ventana anterior\n",
      "Ventana 34, Época: 0, Train Loss: 0.00364336, Test Loss: 0.00634133,R2: 0.8383, MAE: 0.0611\n",
      "Ventana 34, Época: 5, Train Loss: 0.00282229, Test Loss: 0.00703042, R2: 0.8207, MAE: 0.0639\n",
      "Early stopping en la ventana 34, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 34\n",
      "-------------------\n",
      "Ventana 35 de 143\n",
      "Entrenando con semanas: [36 37 38 39 40 41 43 44 45 46], testeando en semanas [47 48 49], len train: 417, len test: 128, porcentaje: 0.77\n",
      "Iniciando ventana 35 con pesos de la ventana anterior\n",
      "Ventana 35, Época: 0, Train Loss: 0.00424761, Test Loss: 0.00671034,R2: 0.8346, MAE: 0.0628\n",
      "Ventana 35, Época: 5, Train Loss: 0.00364681, Test Loss: 0.00625537,R2: 0.8458, MAE: 0.0588\n",
      "Ventana 35, Época: 7, Train Loss: 0.00323266, Test Loss: 0.00649952, R2: 0.8398, MAE: 0.0597\n",
      "Early stopping en la ventana 35, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 35\n",
      "-------------------\n",
      "Ventana 36 de 143\n",
      "Entrenando con semanas: [37 38 39 40 41 43 44 45 46 47], testeando en semanas [48 49 50], len train: 450, len test: 97, porcentaje: 0.82\n",
      "Iniciando ventana 36 con pesos de la ventana anterior\n",
      "Ventana 36, Época: 0, Train Loss: 0.00410831, Test Loss: 0.00911708,R2: 0.7820, MAE: 0.0746\n",
      "Ventana 36, Época: 5, Train Loss: 0.00444753, Test Loss: 0.00720048,R2: 0.8279, MAE: 0.0628\n",
      "Ventana 36, Época: 10, Train Loss: 0.00285255, Test Loss: 0.00738672, R2: 0.8234, MAE: 0.0648\n",
      "Early stopping en la ventana 36, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 36\n",
      "-------------------\n",
      "Ventana 37 de 143\n",
      "Entrenando con semanas: [38 39 40 41 43 44 45 46 47 48], testeando en semanas [49 50 51], len train: 506, len test: 78, porcentaje: 0.87\n",
      "Iniciando ventana 37 con pesos de la ventana anterior\n",
      "Ventana 37, Época: 0, Train Loss: 0.00373167, Test Loss: 0.01226269,R2: 0.6747, MAE: 0.0853\n",
      "Ventana 37, Época: 5, Train Loss: 0.00335302, Test Loss: 0.01269536, R2: 0.6632, MAE: 0.0861\n",
      "Early stopping en la ventana 37, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 37\n",
      "-------------------\n",
      "Ventana 38 de 143\n",
      "Entrenando con semanas: [39 40 41 43 44 45 46 47 48 49], testeando en semanas [50 51 52], len train: 525, len test: 100, porcentaje: 0.84\n",
      "Iniciando ventana 38 con pesos de la ventana anterior\n",
      "Ventana 38, Época: 0, Train Loss: 0.00369186, Test Loss: 0.01969681,R2: 0.4923, MAE: 0.1132\n",
      "Ventana 38, Época: 5, Train Loss: 0.00338650, Test Loss: 0.01934600,R2: 0.5014, MAE: 0.1128\n",
      "Ventana 38, Época: 10, Train Loss: 0.00309837, Test Loss: 0.01906293,R2: 0.5087, MAE: 0.1126\n",
      "Ventana 38, Época: 15, Train Loss: 0.00278554, Test Loss: 0.01975992,R2: 0.4907, MAE: 0.1144\n",
      "Ventana 38, Época: 18, Train Loss: 0.00270175, Test Loss: 0.01944702, R2: 0.4988, MAE: 0.1136\n",
      "Early stopping en la ventana 38, época 18\n",
      "Mejor modelo guardado en la época  13 para la ventana 38\n",
      "-------------------\n",
      "Ventana 39 de 143\n",
      "Entrenando con semanas: [40 41 43 44 45 46 47 48 49 50], testeando en semanas [51 52 53], len train: 431, len test: 99, porcentaje: 0.81\n",
      "Iniciando ventana 39 con pesos de la ventana anterior\n",
      "Ventana 39, Época: 0, Train Loss: 0.00304989, Test Loss: 0.01971612,R2: 0.4906, MAE: 0.1145\n",
      "Ventana 39, Época: 5, Train Loss: 0.00293754, Test Loss: 0.01872335,R2: 0.5163, MAE: 0.1121\n",
      "Ventana 39, Época: 10, Train Loss: 0.00276700, Test Loss: 0.01923789, R2: 0.5030, MAE: 0.1133\n",
      "Early stopping en la ventana 39, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 39\n",
      "-------------------\n",
      "Ventana 40 de 143\n",
      "Entrenando con semanas: [41 43 44 45 46 47 48 49 50 51], testeando en semanas [52 53 54], len train: 367, len test: 104, porcentaje: 0.78\n",
      "Iniciando ventana 40 con pesos de la ventana anterior\n",
      "Ventana 40, Época: 0, Train Loss: 0.00504875, Test Loss: 0.01891099,R2: 0.5565, MAE: 0.1106\n",
      "Ventana 40, Época: 5, Train Loss: 0.00381939, Test Loss: 0.01509807,R2: 0.6459, MAE: 0.1005\n",
      "Ventana 40, Época: 10, Train Loss: 0.00366667, Test Loss: 0.01461718,R2: 0.6572, MAE: 0.0986\n",
      "Ventana 40, Época: 15, Train Loss: 0.00293477, Test Loss: 0.01536104,R2: 0.6398, MAE: 0.1011\n",
      "Ventana 40, Época: 16, Train Loss: 0.00292494, Test Loss: 0.01459083, R2: 0.6578, MAE: 0.0988\n",
      "Early stopping en la ventana 40, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 40\n",
      "-------------------\n",
      "Ventana 41 de 143\n",
      "Entrenando con semanas: [43 44 45 46 47 48 49 50 51 52], testeando en semanas [53 54 55], len train: 402, len test: 109, porcentaje: 0.79\n",
      "Iniciando ventana 41 con pesos de la ventana anterior\n",
      "Ventana 41, Época: 0, Train Loss: 0.00511812, Test Loss: 0.01103442,R2: 0.7484, MAE: 0.0850\n",
      "Ventana 41, Época: 5, Train Loss: 0.00417386, Test Loss: 0.01072979,R2: 0.7553, MAE: 0.0862\n",
      "Ventana 41, Época: 10, Train Loss: 0.00354482, Test Loss: 0.01042558,R2: 0.7622, MAE: 0.0830\n",
      "Ventana 41, Época: 14, Train Loss: 0.00308143, Test Loss: 0.01041564, R2: 0.7625, MAE: 0.0842\n",
      "Early stopping en la ventana 41, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 41\n",
      "-------------------\n",
      "Ventana 42 de 143\n",
      "Entrenando con semanas: [44 45 46 47 48 49 50 51 52 53], testeando en semanas [54 55 56], len train: 374, len test: 236, porcentaje: 0.61\n",
      "Iniciando ventana 42 con pesos de la ventana anterior\n",
      "Ventana 42, Época: 0, Train Loss: 0.00387792, Test Loss: 0.01517429,R2: 0.6077, MAE: 0.0962\n",
      "Ventana 42, Época: 5, Train Loss: 0.00363533, Test Loss: 0.01484466,R2: 0.6162, MAE: 0.0953\n",
      "Ventana 42, Época: 10, Train Loss: 0.00275887, Test Loss: 0.01584999, R2: 0.5902, MAE: 0.0989\n",
      "Early stopping en la ventana 42, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 42\n",
      "-------------------\n",
      "Ventana 43 de 143\n",
      "Entrenando con semanas: [45 46 47 48 49 50 51 52 53 54], testeando en semanas [55 56 57], len train: 404, len test: 277, porcentaje: 0.59\n",
      "Iniciando ventana 43 con pesos de la ventana anterior\n",
      "Ventana 43, Época: 0, Train Loss: 0.00424219, Test Loss: 0.01759206,R2: 0.6396, MAE: 0.1037\n",
      "Ventana 43, Época: 5, Train Loss: 0.00456866, Test Loss: 0.01652621,R2: 0.6614, MAE: 0.0999\n",
      "Ventana 43, Época: 10, Train Loss: 0.00386321, Test Loss: 0.01465612,R2: 0.6997, MAE: 0.0932\n",
      "Ventana 43, Época: 14, Train Loss: 0.00356385, Test Loss: 0.01389487, R2: 0.7153, MAE: 0.0892\n",
      "Early stopping en la ventana 43, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 43\n",
      "-------------------\n",
      "Ventana 44 de 143\n",
      "Entrenando con semanas: [46 47 48 49 50 51 52 53 54 55], testeando en semanas [56 57 58], len train: 394, len test: 237, porcentaje: 0.62\n",
      "Iniciando ventana 44 con pesos de la ventana anterior\n",
      "Ventana 44, Época: 0, Train Loss: 0.00482100, Test Loss: 0.01628077,R2: 0.6679, MAE: 0.0990\n",
      "Ventana 44, Época: 5, Train Loss: 0.00339590, Test Loss: 0.01486374,R2: 0.6968, MAE: 0.0937\n",
      "Ventana 44, Época: 10, Train Loss: 0.00387726, Test Loss: 0.01609128,R2: 0.6717, MAE: 0.0980\n",
      "Ventana 44, Época: 15, Train Loss: 0.00336205, Test Loss: 0.01493907,R2: 0.6952, MAE: 0.0927\n",
      "Ventana 44, Época: 19, Train Loss: 0.00284412, Test Loss: 0.01365866, R2: 0.7214, MAE: 0.0887\n",
      "Early stopping en la ventana 44, época 19\n",
      "Mejor modelo guardado en la época  14 para la ventana 44\n",
      "-------------------\n",
      "Ventana 45 de 143\n",
      "Entrenando con semanas: [47 48 49 50 51 52 53 54 55 56], testeando en semanas [57 58 60], len train: 467, len test: 167, porcentaje: 0.74\n",
      "Iniciando ventana 45 con pesos de la ventana anterior\n",
      "Ventana 45, Época: 0, Train Loss: 0.00742201, Test Loss: 0.00969399,R2: 0.8270, MAE: 0.0751\n",
      "Ventana 45, Época: 5, Train Loss: 0.00517855, Test Loss: 0.00924000,R2: 0.8351, MAE: 0.0754\n",
      "Ventana 45, Época: 10, Train Loss: 0.00452754, Test Loss: 0.00969327, R2: 0.8270, MAE: 0.0743\n",
      "Early stopping en la ventana 45, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 45\n",
      "-------------------\n",
      "Ventana 46 de 143\n",
      "Entrenando con semanas: [48 49 50 51 52 53 54 55 56 57], testeando en semanas [58 60 61], len train: 528, len test: 179, porcentaje: 0.75\n",
      "Iniciando ventana 46 con pesos de la ventana anterior\n",
      "Ventana 46, Época: 0, Train Loss: 0.00639641, Test Loss: 0.01437045,R2: 0.5764, MAE: 0.0873\n",
      "Ventana 46, Época: 5, Train Loss: 0.00535116, Test Loss: 0.01496631, R2: 0.5588, MAE: 0.0908\n",
      "Early stopping en la ventana 46, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 46\n",
      "-------------------\n",
      "Ventana 47 de 143\n",
      "Entrenando con semanas: [49 50 51 52 53 54 55 56 57 58], testeando en semanas [60 61 62], len train: 470, len test: 283, porcentaje: 0.62\n",
      "Iniciando ventana 47 con pesos de la ventana anterior\n",
      "Ventana 47, Época: 0, Train Loss: 0.00723003, Test Loss: 0.01652895,R2: 0.6292, MAE: 0.0968\n",
      "Ventana 47, Época: 5, Train Loss: 0.00492134, Test Loss: 0.01898880, R2: 0.5741, MAE: 0.1043\n",
      "Early stopping en la ventana 47, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 47\n",
      "-------------------\n",
      "Ventana 48 de 143\n",
      "Entrenando con semanas: [50 51 52 53 54 55 56 57 58 60], testeando en semanas [61 62 63], len train: 506, len test: 233, porcentaje: 0.68\n",
      "Iniciando ventana 48 con pesos de la ventana anterior\n",
      "Ventana 48, Época: 0, Train Loss: 0.00704237, Test Loss: 0.01730579,R2: 0.6420, MAE: 0.0967\n",
      "Ventana 48, Época: 5, Train Loss: 0.00505827, Test Loss: 0.01777842,R2: 0.6322, MAE: 0.0985\n",
      "Ventana 48, Época: 6, Train Loss: 0.00513288, Test Loss: 0.01824228, R2: 0.6226, MAE: 0.0999\n",
      "Early stopping en la ventana 48, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 48\n",
      "-------------------\n",
      "Ventana 49 de 143\n",
      "Entrenando con semanas: [51 52 53 54 55 56 57 58 60 61], testeando en semanas [62 63 65], len train: 610, len test: 154, porcentaje: 0.80\n",
      "Iniciando ventana 49 con pesos de la ventana anterior\n",
      "Ventana 49, Época: 0, Train Loss: 0.00794845, Test Loss: 0.01578372,R2: 0.7238, MAE: 0.0938\n",
      "Ventana 49, Época: 5, Train Loss: 0.00636479, Test Loss: 0.01378966,R2: 0.7587, MAE: 0.0883\n",
      "Ventana 49, Época: 10, Train Loss: 0.00538134, Test Loss: 0.01382795,R2: 0.7580, MAE: 0.0896\n",
      "Ventana 49, Época: 13, Train Loss: 0.00487665, Test Loss: 0.01374676, R2: 0.7594, MAE: 0.0897\n",
      "Early stopping en la ventana 49, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 49\n",
      "-------------------\n",
      "Ventana 50 de 143\n",
      "Entrenando con semanas: [52 53 54 55 56 57 58 60 61 62], testeando en semanas [63 65 67], len train: 675, len test: 86, porcentaje: 0.89\n",
      "Iniciando ventana 50 con pesos de la ventana anterior\n",
      "Ventana 50, Época: 0, Train Loss: 0.00756051, Test Loss: 0.00815663,R2: 0.7874, MAE: 0.0735\n",
      "Ventana 50, Época: 5, Train Loss: 0.00614766, Test Loss: 0.00801367,R2: 0.7911, MAE: 0.0701\n",
      "Ventana 50, Época: 7, Train Loss: 0.00561465, Test Loss: 0.00866470, R2: 0.7741, MAE: 0.0729\n",
      "Early stopping en la ventana 50, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 50\n",
      "-------------------\n",
      "Ventana 51 de 143\n",
      "Entrenando con semanas: [53 54 55 56 57 58 60 61 62 63], testeando en semanas [65 67 68], len train: 639, len test: 132, porcentaje: 0.83\n",
      "Iniciando ventana 51 con pesos de la ventana anterior\n",
      "Ventana 51, Época: 0, Train Loss: 0.00701831, Test Loss: 0.00839956,R2: 0.7228, MAE: 0.0708\n",
      "Ventana 51, Época: 5, Train Loss: 0.00543979, Test Loss: 0.00798164,R2: 0.7366, MAE: 0.0683\n",
      "Ventana 51, Época: 6, Train Loss: 0.00507113, Test Loss: 0.00808679, R2: 0.7331, MAE: 0.0689\n",
      "Early stopping en la ventana 51, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 51\n",
      "-------------------\n",
      "Ventana 52 de 143\n",
      "Entrenando con semanas: [54 55 56 57 58 60 61 62 63 65], testeando en semanas [67 68 69], len train: 665, len test: 154, porcentaje: 0.81\n",
      "Iniciando ventana 52 con pesos de la ventana anterior\n",
      "Ventana 52, Época: 0, Train Loss: 0.00642837, Test Loss: 0.00623628,R2: 0.7972, MAE: 0.0603\n",
      "Ventana 52, Época: 5, Train Loss: 0.00542886, Test Loss: 0.00648311, R2: 0.7892, MAE: 0.0617\n",
      "Early stopping en la ventana 52, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 52\n",
      "-------------------\n",
      "Ventana 53 de 143\n",
      "Entrenando con semanas: [55 56 57 58 60 61 62 63 65 67], testeando en semanas [68 69 70], len train: 657, len test: 216, porcentaje: 0.75\n",
      "Iniciando ventana 53 con pesos de la ventana anterior\n",
      "Ventana 53, Época: 0, Train Loss: 0.00651791, Test Loss: 0.00929374,R2: 0.6539, MAE: 0.0761\n",
      "Ventana 53, Época: 5, Train Loss: 0.00558904, Test Loss: 0.00870447,R2: 0.6758, MAE: 0.0723\n",
      "Ventana 53, Época: 10, Train Loss: 0.00449880, Test Loss: 0.00925773, R2: 0.6552, MAE: 0.0747\n",
      "Early stopping en la ventana 53, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 53\n",
      "-------------------\n",
      "Ventana 54 de 143\n",
      "Entrenando con semanas: [56 57 58 60 61 62 63 65 67 68], testeando en semanas [69 70 71], len train: 662, len test: 270, porcentaje: 0.71\n",
      "Iniciando ventana 54 con pesos de la ventana anterior\n",
      "Ventana 54, Época: 0, Train Loss: 0.00558770, Test Loss: 0.01099540,R2: 0.7440, MAE: 0.0812\n",
      "Ventana 54, Época: 5, Train Loss: 0.00452782, Test Loss: 0.01044882,R2: 0.7567, MAE: 0.0781\n",
      "Ventana 54, Época: 10, Train Loss: 0.00435657, Test Loss: 0.01109864, R2: 0.7416, MAE: 0.0817\n",
      "Early stopping en la ventana 54, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 54\n",
      "-------------------\n",
      "Ventana 55 de 143\n",
      "Entrenando con semanas: [57 58 60 61 62 63 65 67 68 69], testeando en semanas [70 71 72], len train: 583, len test: 230, porcentaje: 0.72\n",
      "Iniciando ventana 55 con pesos de la ventana anterior\n",
      "Ventana 55, Época: 0, Train Loss: 0.00494906, Test Loss: 0.01557051,R2: 0.6492, MAE: 0.0994\n",
      "Ventana 55, Época: 5, Train Loss: 0.00444114, Test Loss: 0.01182016,R2: 0.7337, MAE: 0.0837\n",
      "Ventana 55, Época: 6, Train Loss: 0.00422711, Test Loss: 0.01441997, R2: 0.6751, MAE: 0.0939\n",
      "Early stopping en la ventana 55, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 55\n",
      "-------------------\n",
      "Ventana 56 de 143\n",
      "Entrenando con semanas: [58 60 61 62 63 65 67 68 69 70], testeando en semanas [71 72 74], len train: 596, len test: 182, porcentaje: 0.77\n",
      "Iniciando ventana 56 con pesos de la ventana anterior\n",
      "Ventana 56, Época: 0, Train Loss: 0.00653776, Test Loss: 0.02231316,R2: 0.6255, MAE: 0.1208\n",
      "Ventana 56, Época: 5, Train Loss: 0.00846577, Test Loss: 0.01114379,R2: 0.8130, MAE: 0.0828\n",
      "Ventana 56, Época: 10, Train Loss: 0.00476231, Test Loss: 0.01018584,R2: 0.8290, MAE: 0.0777\n",
      "Ventana 56, Época: 15, Train Loss: 0.00405817, Test Loss: 0.01036355,R2: 0.8261, MAE: 0.0798\n",
      "Ventana 56, Época: 16, Train Loss: 0.00446491, Test Loss: 0.01098834, R2: 0.8156, MAE: 0.0820\n",
      "Early stopping en la ventana 56, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 56\n",
      "-------------------\n",
      "Ventana 57 de 143\n",
      "Entrenando con semanas: [60 61 62 63 65 67 68 69 70 71], testeando en semanas [72 74 76], len train: 695, len test: 134, porcentaje: 0.84\n",
      "Iniciando ventana 57 con pesos de la ventana anterior\n",
      "Ventana 57, Época: 0, Train Loss: 0.00532793, Test Loss: 0.01015934,R2: 0.7748, MAE: 0.0789\n",
      "Ventana 57, Época: 5, Train Loss: 0.00512802, Test Loss: 0.00873759,R2: 0.8064, MAE: 0.0716\n",
      "Ventana 57, Época: 10, Train Loss: 0.00436269, Test Loss: 0.00746077,R2: 0.8347, MAE: 0.0676\n",
      "Ventana 57, Época: 15, Train Loss: 0.00365317, Test Loss: 0.00721936,R2: 0.8400, MAE: 0.0659\n",
      "Ventana 57, Época: 20, Train Loss: 0.00345868, Test Loss: 0.00752260,R2: 0.8333, MAE: 0.0671\n",
      "Ventana 57, Época: 25, Train Loss: 0.00290205, Test Loss: 0.00775439,R2: 0.8281, MAE: 0.0682\n",
      "Ventana 57, Época: 27, Train Loss: 0.00303373, Test Loss: 0.00743766, R2: 0.8352, MAE: 0.0668\n",
      "Early stopping en la ventana 57, época 27\n",
      "Mejor modelo guardado en la época  22 para la ventana 57\n",
      "-------------------\n",
      "Ventana 58 de 143\n",
      "Entrenando con semanas: [61 62 63 65 67 68 69 70 71 72], testeando en semanas [74 76 77], len train: 646, len test: 178, porcentaje: 0.78\n",
      "Iniciando ventana 58 con pesos de la ventana anterior\n",
      "Ventana 58, Época: 0, Train Loss: 0.00321327, Test Loss: 0.00681709,R2: 0.8485, MAE: 0.0634\n",
      "Ventana 58, Época: 5, Train Loss: 0.00323116, Test Loss: 0.00713303, R2: 0.8415, MAE: 0.0650\n",
      "Early stopping en la ventana 58, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 58\n",
      "-------------------\n",
      "Ventana 59 de 143\n",
      "Entrenando con semanas: [62 63 65 67 68 69 70 71 72 74], testeando en semanas [76 77 78], len train: 599, len test: 119, porcentaje: 0.83\n",
      "Iniciando ventana 59 con pesos de la ventana anterior\n",
      "Ventana 59, Época: 0, Train Loss: 0.00376757, Test Loss: 0.00774851,R2: 0.8071, MAE: 0.0700\n",
      "Ventana 59, Época: 5, Train Loss: 0.00353976, Test Loss: 0.00701817,R2: 0.8253, MAE: 0.0655\n",
      "Ventana 59, Época: 6, Train Loss: 0.00322896, Test Loss: 0.00697261, R2: 0.8264, MAE: 0.0651\n",
      "Early stopping en la ventana 59, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 59\n",
      "-------------------\n",
      "Ventana 60 de 143\n",
      "Entrenando con semanas: [63 65 67 68 69 70 71 72 74 76], testeando en semanas [77 78 79], len train: 546, len test: 70, porcentaje: 0.89\n",
      "Iniciando ventana 60 con pesos de la ventana anterior\n",
      "Ventana 60, Época: 0, Train Loss: 0.00412616, Test Loss: 0.00864097,R2: 0.7857, MAE: 0.0711\n",
      "Ventana 60, Época: 5, Train Loss: 0.00336283, Test Loss: 0.00704368,R2: 0.8253, MAE: 0.0659\n",
      "Ventana 60, Época: 10, Train Loss: 0.00293191, Test Loss: 0.00634834,R2: 0.8426, MAE: 0.0641\n",
      "Ventana 60, Época: 15, Train Loss: 0.00273298, Test Loss: 0.00577850,R2: 0.8567, MAE: 0.0605\n",
      "Ventana 60, Época: 20, Train Loss: 0.00263319, Test Loss: 0.00608682,R2: 0.8491, MAE: 0.0612\n",
      "Ventana 60, Época: 21, Train Loss: 0.00243731, Test Loss: 0.00589625, R2: 0.8538, MAE: 0.0603\n",
      "Early stopping en la ventana 60, época 21\n",
      "Mejor modelo guardado en la época  16 para la ventana 60\n",
      "-------------------\n",
      "Ventana 61 de 143\n",
      "Entrenando con semanas: [65 67 68 69 70 71 72 74 76 77], testeando en semanas [78 79 82], len train: 591, len test: 129, porcentaje: 0.82\n",
      "Iniciando ventana 61 con pesos de la ventana anterior\n",
      "Ventana 61, Época: 0, Train Loss: 0.00293050, Test Loss: 0.00823793,R2: 0.8626, MAE: 0.0737\n",
      "Ventana 61, Época: 5, Train Loss: 0.00254036, Test Loss: 0.00780427,R2: 0.8698, MAE: 0.0714\n",
      "Ventana 61, Época: 10, Train Loss: 0.00227378, Test Loss: 0.00757541,R2: 0.8736, MAE: 0.0692\n",
      "Ventana 61, Época: 12, Train Loss: 0.00223406, Test Loss: 0.00792997, R2: 0.8677, MAE: 0.0718\n",
      "Early stopping en la ventana 61, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 61\n",
      "-------------------\n",
      "Ventana 62 de 143\n",
      "Entrenando con semanas: [67 68 69 70 71 72 74 76 77 78], testeando en semanas [79 82 83], len train: 564, len test: 138, porcentaje: 0.80\n",
      "Iniciando ventana 62 con pesos de la ventana anterior\n",
      "Ventana 62, Época: 0, Train Loss: 0.00242386, Test Loss: 0.00780592,R2: 0.8690, MAE: 0.0717\n",
      "Ventana 62, Época: 5, Train Loss: 0.00218140, Test Loss: 0.00722375,R2: 0.8788, MAE: 0.0675\n",
      "Ventana 62, Época: 10, Train Loss: 0.00206049, Test Loss: 0.00708829,R2: 0.8811, MAE: 0.0679\n",
      "Ventana 62, Época: 13, Train Loss: 0.00204625, Test Loss: 0.00708305, R2: 0.8812, MAE: 0.0664\n",
      "Early stopping en la ventana 62, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 62\n",
      "-------------------\n",
      "Ventana 63 de 143\n",
      "Entrenando con semanas: [68 69 70 71 72 74 76 77 78 79], testeando en semanas [82 83 84], len train: 530, len test: 137, porcentaje: 0.79\n",
      "Iniciando ventana 63 con pesos de la ventana anterior\n",
      "Ventana 63, Época: 0, Train Loss: 0.00235214, Test Loss: 0.00699659,R2: 0.8847, MAE: 0.0664\n",
      "Ventana 63, Época: 5, Train Loss: 0.00254750, Test Loss: 0.00705088, R2: 0.8838, MAE: 0.0678\n",
      "Early stopping en la ventana 63, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 63\n",
      "-------------------\n",
      "Ventana 64 de 143\n",
      "Entrenando con semanas: [69 70 71 72 74 76 77 78 79 82], testeando en semanas [83 84 85], len train: 588, len test: 65, porcentaje: 0.90\n",
      "Iniciando ventana 64 con pesos de la ventana anterior\n",
      "Ventana 64, Época: 0, Train Loss: 0.00340846, Test Loss: 0.00644783,R2: 0.8329, MAE: 0.0640\n",
      "Ventana 64, Época: 5, Train Loss: 0.00341186, Test Loss: 0.00604727,R2: 0.8433, MAE: 0.0624\n",
      "Ventana 64, Época: 10, Train Loss: 0.00293883, Test Loss: 0.00616861,R2: 0.8402, MAE: 0.0606\n",
      "Ventana 64, Época: 15, Train Loss: 0.00242572, Test Loss: 0.00559789,R2: 0.8550, MAE: 0.0590\n",
      "Ventana 64, Época: 17, Train Loss: 0.00232095, Test Loss: 0.00589800, R2: 0.8472, MAE: 0.0600\n",
      "Early stopping en la ventana 64, época 17\n",
      "Mejor modelo guardado en la época  12 para la ventana 64\n",
      "-------------------\n",
      "Ventana 65 de 143\n",
      "Entrenando con semanas: [70 71 72 74 76 77 78 79 82 83], testeando en semanas [84 85 86], len train: 548, len test: 105, porcentaje: 0.84\n",
      "Iniciando ventana 65 con pesos de la ventana anterior\n",
      "Ventana 65, Época: 0, Train Loss: 0.00278195, Test Loss: 0.00646697,R2: 0.8286, MAE: 0.0619\n",
      "Ventana 65, Época: 5, Train Loss: 0.00252247, Test Loss: 0.00715242, R2: 0.8104, MAE: 0.0647\n",
      "Early stopping en la ventana 65, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 65\n",
      "-------------------\n",
      "Ventana 66 de 143\n",
      "Entrenando con semanas: [71 72 74 76 77 78 79 82 83 84], testeando en semanas [85 86 87], len train: 451, len test: 154, porcentaje: 0.75\n",
      "Iniciando ventana 66 con pesos de la ventana anterior\n",
      "Ventana 66, Época: 0, Train Loss: 0.00296201, Test Loss: 0.00711478,R2: 0.8424, MAE: 0.0648\n",
      "Ventana 66, Época: 5, Train Loss: 0.00340076, Test Loss: 0.00726289,R2: 0.8391, MAE: 0.0651\n",
      "Ventana 66, Época: 10, Train Loss: 0.00270306, Test Loss: 0.00589763,R2: 0.8694, MAE: 0.0579\n",
      "Ventana 66, Época: 11, Train Loss: 0.00236267, Test Loss: 0.00674614, R2: 0.8506, MAE: 0.0625\n",
      "Early stopping en la ventana 66, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 66\n",
      "-------------------\n",
      "Ventana 67 de 143\n",
      "Entrenando con semanas: [72 74 76 77 78 79 82 83 84 85], testeando en semanas [86 87 88], len train: 383, len test: 217, porcentaje: 0.64\n",
      "Iniciando ventana 67 con pesos de la ventana anterior\n",
      "Ventana 67, Época: 0, Train Loss: 0.00307750, Test Loss: 0.00835402,R2: 0.8075, MAE: 0.0723\n",
      "Ventana 67, Época: 5, Train Loss: 0.00479245, Test Loss: 0.00591241,R2: 0.8637, MAE: 0.0606\n",
      "Ventana 67, Época: 10, Train Loss: 0.00292465, Test Loss: 0.00582547,R2: 0.8658, MAE: 0.0604\n",
      "Ventana 67, Época: 12, Train Loss: 0.00236685, Test Loss: 0.00627134, R2: 0.8555, MAE: 0.0625\n",
      "Early stopping en la ventana 67, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 67\n",
      "-------------------\n",
      "Ventana 68 de 143\n",
      "Entrenando con semanas: [74 76 77 78 79 82 83 84 85 86], testeando en semanas [87 88 89], len train: 423, len test: 191, porcentaje: 0.69\n",
      "Iniciando ventana 68 con pesos de la ventana anterior\n",
      "Ventana 68, Época: 0, Train Loss: 0.00349378, Test Loss: 0.00842748,R2: 0.8124, MAE: 0.0731\n",
      "Ventana 68, Época: 5, Train Loss: 0.00272900, Test Loss: 0.00576205,R2: 0.8718, MAE: 0.0595\n",
      "Ventana 68, Época: 10, Train Loss: 0.00232784, Test Loss: 0.00577188,R2: 0.8715, MAE: 0.0578\n",
      "Ventana 68, Época: 15, Train Loss: 0.00226509, Test Loss: 0.00538063,R2: 0.8802, MAE: 0.0573\n",
      "Ventana 68, Época: 20, Train Loss: 0.00222856, Test Loss: 0.00528670,R2: 0.8823, MAE: 0.0562\n",
      "Ventana 68, Época: 24, Train Loss: 0.00181403, Test Loss: 0.00553345, R2: 0.8768, MAE: 0.0573\n",
      "Early stopping en la ventana 68, época 24\n",
      "Mejor modelo guardado en la época  19 para la ventana 68\n",
      "-------------------\n",
      "Ventana 69 de 143\n",
      "Entrenando con semanas: [76 77 78 79 82 83 84 85 86 87], testeando en semanas [88 89 90], len train: 423, len test: 233, porcentaje: 0.64\n",
      "Iniciando ventana 69 con pesos de la ventana anterior\n",
      "Ventana 69, Época: 0, Train Loss: 0.00277758, Test Loss: 0.00604650,R2: 0.8478, MAE: 0.0617\n",
      "Ventana 69, Época: 5, Train Loss: 0.00288997, Test Loss: 0.00535337,R2: 0.8653, MAE: 0.0574\n",
      "Ventana 69, Época: 10, Train Loss: 0.00221718, Test Loss: 0.00561268,R2: 0.8587, MAE: 0.0598\n",
      "Ventana 69, Época: 13, Train Loss: 0.00221589, Test Loss: 0.00553439, R2: 0.8607, MAE: 0.0592\n",
      "Early stopping en la ventana 69, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 69\n",
      "-------------------\n",
      "Ventana 70 de 143\n",
      "Entrenando con semanas: [77 78 79 82 83 84 85 86 87 88], testeando en semanas [89 90 91], len train: 466, len test: 151, porcentaje: 0.76\n",
      "Iniciando ventana 70 con pesos de la ventana anterior\n",
      "Ventana 70, Época: 0, Train Loss: 0.00320706, Test Loss: 0.00575674,R2: 0.8649, MAE: 0.0604\n",
      "Ventana 70, Época: 5, Train Loss: 0.00285617, Test Loss: 0.00537504,R2: 0.8739, MAE: 0.0584\n",
      "Ventana 70, Época: 10, Train Loss: 0.00257164, Test Loss: 0.00482593,R2: 0.8868, MAE: 0.0543\n",
      "Ventana 70, Época: 14, Train Loss: 0.00235411, Test Loss: 0.00562056, R2: 0.8681, MAE: 0.0598\n",
      "Early stopping en la ventana 70, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 70\n",
      "-------------------\n",
      "Ventana 71 de 143\n",
      "Entrenando con semanas: [78 79 82 83 84 85 86 87 88 89], testeando en semanas [90 91 92], len train: 436, len test: 149, porcentaje: 0.75\n",
      "Iniciando ventana 71 con pesos de la ventana anterior\n",
      "Ventana 71, Época: 0, Train Loss: 0.00292871, Test Loss: 0.00742902,R2: 0.8216, MAE: 0.0675\n",
      "Ventana 71, Época: 5, Train Loss: 0.00244303, Test Loss: 0.00698131,R2: 0.8324, MAE: 0.0627\n",
      "Ventana 71, Época: 10, Train Loss: 0.00223731, Test Loss: 0.00658911,R2: 0.8418, MAE: 0.0642\n",
      "Ventana 71, Época: 15, Train Loss: 0.00228734, Test Loss: 0.00635503,R2: 0.8474, MAE: 0.0614\n",
      "Ventana 71, Época: 20, Train Loss: 0.00215112, Test Loss: 0.00632809,R2: 0.8481, MAE: 0.0600\n",
      "Ventana 71, Época: 24, Train Loss: 0.00177881, Test Loss: 0.00625266, R2: 0.8499, MAE: 0.0608\n",
      "Early stopping en la ventana 71, época 24\n",
      "Mejor modelo guardado en la época  19 para la ventana 71\n",
      "-------------------\n",
      "Ventana 72 de 143\n",
      "Entrenando con semanas: [79 82 83 84 85 86 87 88 89 90], testeando en semanas [91 92 93], len train: 537, len test: 124, porcentaje: 0.81\n",
      "Iniciando ventana 72 con pesos de la ventana anterior\n",
      "Ventana 72, Época: 0, Train Loss: 0.00270055, Test Loss: 0.01072189,R2: 0.7074, MAE: 0.0822\n",
      "Ventana 72, Época: 5, Train Loss: 0.00251949, Test Loss: 0.01247630, R2: 0.6595, MAE: 0.0893\n",
      "Early stopping en la ventana 72, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 72\n",
      "-------------------\n",
      "Ventana 73 de 143\n",
      "Entrenando con semanas: [82 83 84 85 86 87 88 89 90 91], testeando en semanas [92 93 94], len train: 547, len test: 173, porcentaje: 0.76\n",
      "Iniciando ventana 73 con pesos de la ventana anterior\n",
      "Ventana 73, Época: 0, Train Loss: 0.00306057, Test Loss: 0.01803149,R2: 0.5889, MAE: 0.1117\n",
      "Ventana 73, Época: 5, Train Loss: 0.00329382, Test Loss: 0.01239173,R2: 0.7174, MAE: 0.0892\n",
      "Ventana 73, Época: 7, Train Loss: 0.00318979, Test Loss: 0.01406222, R2: 0.6794, MAE: 0.0964\n",
      "Early stopping en la ventana 73, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 73\n",
      "-------------------\n",
      "Ventana 74 de 143\n",
      "Entrenando con semanas: [83 84 85 86 87 88 89 90 91 92], testeando en semanas [93 94 95], len train: 456, len test: 256, porcentaje: 0.64\n",
      "Iniciando ventana 74 con pesos de la ventana anterior\n",
      "Ventana 74, Época: 0, Train Loss: 0.00445239, Test Loss: 0.02053742,R2: 0.4787, MAE: 0.1191\n",
      "Ventana 74, Época: 5, Train Loss: 0.00505794, Test Loss: 0.01525479,R2: 0.6128, MAE: 0.1021\n",
      "Ventana 74, Época: 8, Train Loss: 0.00530969, Test Loss: 0.01169847, R2: 0.7031, MAE: 0.0867\n",
      "Early stopping en la ventana 74, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 74\n",
      "-------------------\n",
      "Ventana 75 de 143\n",
      "Entrenando con semanas: [84 85 86 87 88 89 90 91 92 93], testeando en semanas [94 95 96], len train: 523, len test: 201, porcentaje: 0.72\n",
      "Iniciando ventana 75 con pesos de la ventana anterior\n",
      "Ventana 75, Época: 0, Train Loss: 0.00537937, Test Loss: 0.01389905,R2: 0.6836, MAE: 0.0974\n",
      "Ventana 75, Época: 5, Train Loss: 0.00399369, Test Loss: 0.01197325,R2: 0.7274, MAE: 0.0897\n",
      "Ventana 75, Época: 10, Train Loss: 0.00366115, Test Loss: 0.01073036,R2: 0.7557, MAE: 0.0862\n",
      "Ventana 75, Época: 15, Train Loss: 0.00298823, Test Loss: 0.01024641,R2: 0.7667, MAE: 0.0834\n",
      "Ventana 75, Época: 20, Train Loss: 0.00288580, Test Loss: 0.00973520,R2: 0.7784, MAE: 0.0815\n",
      "Ventana 75, Época: 25, Train Loss: 0.00262486, Test Loss: 0.00986901, R2: 0.7753, MAE: 0.0813\n",
      "Early stopping en la ventana 75, época 25\n",
      "Mejor modelo guardado en la época  20 para la ventana 75\n",
      "-------------------\n",
      "Ventana 76 de 143\n",
      "Entrenando con semanas: [85 86 87 88 89 90 91 92 93 94], testeando en semanas [95 96 97], len train: 583, len test: 237, porcentaje: 0.71\n",
      "Iniciando ventana 76 con pesos de la ventana anterior\n",
      "Ventana 76, Época: 0, Train Loss: 0.00443213, Test Loss: 0.00980716,R2: 0.7400, MAE: 0.0788\n",
      "Ventana 76, Época: 5, Train Loss: 0.00382956, Test Loss: 0.00970705,R2: 0.7427, MAE: 0.0771\n",
      "Ventana 76, Época: 10, Train Loss: 0.00323740, Test Loss: 0.00938470,R2: 0.7512, MAE: 0.0759\n",
      "Ventana 76, Época: 14, Train Loss: 0.00326202, Test Loss: 0.00928533, R2: 0.7539, MAE: 0.0748\n",
      "Early stopping en la ventana 76, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 76\n",
      "-------------------\n",
      "Ventana 77 de 143\n",
      "Entrenando con semanas: [86 87 88 89 90 91 92 93 94 95], testeando en semanas [96 97 98], len train: 647, len test: 154, porcentaje: 0.81\n",
      "Iniciando ventana 77 con pesos de la ventana anterior\n",
      "Ventana 77, Época: 0, Train Loss: 0.00429013, Test Loss: 0.01005047,R2: 0.7660, MAE: 0.0770\n",
      "Ventana 77, Época: 5, Train Loss: 0.00386957, Test Loss: 0.00913192,R2: 0.7874, MAE: 0.0740\n",
      "Ventana 77, Época: 10, Train Loss: 0.00342347, Test Loss: 0.00878239,R2: 0.7955, MAE: 0.0728\n",
      "Ventana 77, Época: 15, Train Loss: 0.00296656, Test Loss: 0.00852163,R2: 0.8016, MAE: 0.0716\n",
      "Ventana 77, Época: 20, Train Loss: 0.00284141, Test Loss: 0.00803719,R2: 0.8129, MAE: 0.0702\n",
      "Ventana 77, Época: 22, Train Loss: 0.00279908, Test Loss: 0.00791129, R2: 0.8158, MAE: 0.0700\n",
      "Early stopping en la ventana 77, época 22\n",
      "Mejor modelo guardado en la época  17 para la ventana 77\n",
      "-------------------\n",
      "Ventana 78 de 143\n",
      "Entrenando con semanas: [87 88 89 90 91 92 93 94 95 96], testeando en semanas [97 98 99], len train: 619, len test: 260, porcentaje: 0.70\n",
      "Iniciando ventana 78 con pesos de la ventana anterior\n",
      "Ventana 78, Época: 0, Train Loss: 0.00318154, Test Loss: 0.01030324,R2: 0.7157, MAE: 0.0807\n",
      "Ventana 78, Época: 5, Train Loss: 0.00288976, Test Loss: 0.00969414,R2: 0.7325, MAE: 0.0789\n",
      "Ventana 78, Época: 10, Train Loss: 0.00233802, Test Loss: 0.00939090,R2: 0.7409, MAE: 0.0765\n",
      "Ventana 78, Época: 11, Train Loss: 0.00279942, Test Loss: 0.00950140, R2: 0.7379, MAE: 0.0771\n",
      "Early stopping en la ventana 78, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 78\n",
      "-------------------\n",
      "Ventana 79 de 143\n",
      "Entrenando con semanas: [88 89 90 91 92 93 94 95 96 97], testeando en semanas [ 98  99 100], len train: 666, len test: 247, porcentaje: 0.73\n",
      "Iniciando ventana 79 con pesos de la ventana anterior\n",
      "Ventana 79, Época: 0, Train Loss: 0.00378257, Test Loss: 0.01057547,R2: 0.7673, MAE: 0.0812\n",
      "Ventana 79, Época: 5, Train Loss: 0.00349697, Test Loss: 0.00982881,R2: 0.7837, MAE: 0.0778\n",
      "Ventana 79, Época: 10, Train Loss: 0.00326536, Test Loss: 0.00973904,R2: 0.7857, MAE: 0.0770\n",
      "Ventana 79, Época: 15, Train Loss: 0.00275762, Test Loss: 0.00923797,R2: 0.7967, MAE: 0.0748\n",
      "Ventana 79, Época: 19, Train Loss: 0.00254057, Test Loss: 0.00936797, R2: 0.7939, MAE: 0.0751\n",
      "Early stopping en la ventana 79, época 19\n",
      "Mejor modelo guardado en la época  14 para la ventana 79\n",
      "-------------------\n",
      "Ventana 80 de 143\n",
      "Entrenando con semanas: [89 90 91 92 93 94 95 96 97 98], testeando en semanas [ 99 100 101], len train: 584, len test: 235, porcentaje: 0.71\n",
      "Iniciando ventana 80 con pesos de la ventana anterior\n",
      "Ventana 80, Época: 0, Train Loss: 0.00327471, Test Loss: 0.00981995,R2: 0.7807, MAE: 0.0766\n",
      "Ventana 80, Época: 5, Train Loss: 0.00292402, Test Loss: 0.00959021,R2: 0.7858, MAE: 0.0748\n",
      "Ventana 80, Época: 6, Train Loss: 0.00283719, Test Loss: 0.00953985, R2: 0.7870, MAE: 0.0749\n",
      "Early stopping en la ventana 80, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 80\n",
      "-------------------\n",
      "Ventana 81 de 143\n",
      "Entrenando con semanas: [90 91 92 93 94 95 96 97 98 99], testeando en semanas [100 101 102], len train: 688, len test: 129, porcentaje: 0.84\n",
      "Iniciando ventana 81 con pesos de la ventana anterior\n",
      "Ventana 81, Época: 0, Train Loss: 0.00433352, Test Loss: 0.01015023,R2: 0.8240, MAE: 0.0751\n",
      "Ventana 81, Época: 5, Train Loss: 0.00395248, Test Loss: 0.00989511,R2: 0.8284, MAE: 0.0756\n",
      "Ventana 81, Época: 10, Train Loss: 0.00345632, Test Loss: 0.00964063,R2: 0.8328, MAE: 0.0743\n",
      "Ventana 81, Época: 15, Train Loss: 0.00305647, Test Loss: 0.01010875,R2: 0.8247, MAE: 0.0764\n",
      "Ventana 81, Época: 16, Train Loss: 0.00312155, Test Loss: 0.00974633, R2: 0.8310, MAE: 0.0745\n",
      "Early stopping en la ventana 81, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 81\n",
      "-------------------\n",
      "Ventana 82 de 143\n",
      "Entrenando con semanas: [ 91  92  93  94  95  96  97  98  99 100], testeando en semanas [101 102 103], len train: 680, len test: 94, porcentaje: 0.88\n",
      "Iniciando ventana 82 con pesos de la ventana anterior\n",
      "Ventana 82, Época: 0, Train Loss: 0.00439580, Test Loss: 0.01053985,R2: 0.7496, MAE: 0.0812\n",
      "Ventana 82, Época: 5, Train Loss: 0.00373579, Test Loss: 0.01124510, R2: 0.7329, MAE: 0.0848\n",
      "Early stopping en la ventana 82, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 82\n",
      "-------------------\n",
      "Ventana 83 de 143\n",
      "Entrenando con semanas: [ 92  93  94  95  96  97  98  99 100 101], testeando en semanas [102 103 104], len train: 668, len test: 188, porcentaje: 0.78\n",
      "Iniciando ventana 83 con pesos de la ventana anterior\n",
      "Ventana 83, Época: 0, Train Loss: 0.00410591, Test Loss: 0.01868094,R2: 0.4770, MAE: 0.1042\n",
      "Ventana 83, Época: 5, Train Loss: 0.00366468, Test Loss: 0.01914776,R2: 0.4639, MAE: 0.1051\n",
      "Ventana 83, Época: 6, Train Loss: 0.00325234, Test Loss: 0.01912511, R2: 0.4646, MAE: 0.1050\n",
      "Early stopping en la ventana 83, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 83\n",
      "-------------------\n",
      "Ventana 84 de 143\n",
      "Entrenando con semanas: [ 93  94  95  96  97  98  99 100 101 102], testeando en semanas [103 104 105], len train: 668, len test: 281, porcentaje: 0.70\n",
      "Iniciando ventana 84 con pesos de la ventana anterior\n",
      "Ventana 84, Época: 0, Train Loss: 0.00420666, Test Loss: 0.01747199,R2: 0.6259, MAE: 0.1011\n",
      "Ventana 84, Época: 5, Train Loss: 0.00331905, Test Loss: 0.01815245, R2: 0.6113, MAE: 0.1032\n",
      "Early stopping en la ventana 84, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 84\n",
      "-------------------\n",
      "Ventana 85 de 143\n",
      "Entrenando con semanas: [ 94  95  96  97  98  99 100 101 102 103], testeando en semanas [104 105 106], len train: 650, len test: 232, porcentaje: 0.74\n",
      "Iniciando ventana 85 con pesos de la ventana anterior\n",
      "Ventana 85, Época: 0, Train Loss: 0.00531032, Test Loss: 0.02079586,R2: 0.5723, MAE: 0.1103\n",
      "Ventana 85, Época: 5, Train Loss: 0.00391835, Test Loss: 0.01780042,R2: 0.6339, MAE: 0.1011\n",
      "Ventana 85, Época: 10, Train Loss: 0.00346877, Test Loss: 0.01738846,R2: 0.6424, MAE: 0.1003\n",
      "Ventana 85, Época: 15, Train Loss: 0.00333820, Test Loss: 0.01745731, R2: 0.6410, MAE: 0.1010\n",
      "Early stopping en la ventana 85, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 85\n",
      "-------------------\n",
      "Ventana 86 de 143\n",
      "Entrenando con semanas: [ 95  96  97  98  99 100 101 102 103 104], testeando en semanas [105 106 107], len train: 683, len test: 139, porcentaje: 0.83\n",
      "Iniciando ventana 86 con pesos de la ventana anterior\n",
      "Ventana 86, Época: 0, Train Loss: 0.00662661, Test Loss: 0.01247051,R2: 0.7948, MAE: 0.0858\n",
      "Ventana 86, Época: 5, Train Loss: 0.00504108, Test Loss: 0.01084700,R2: 0.8215, MAE: 0.0792\n",
      "Ventana 86, Época: 10, Train Loss: 0.00440635, Test Loss: 0.01211471, R2: 0.8006, MAE: 0.0838\n",
      "Early stopping en la ventana 86, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 86\n",
      "-------------------\n",
      "Ventana 87 de 143\n",
      "Entrenando con semanas: [ 96  97  98  99 100 101 102 103 104 105], testeando en semanas [106 107 108], len train: 693, len test: 68, porcentaje: 0.91\n",
      "Iniciando ventana 87 con pesos de la ventana anterior\n",
      "Ventana 87, Época: 0, Train Loss: 0.00670883, Test Loss: 0.00614350,R2: 0.8705, MAE: 0.0596\n",
      "Ventana 87, Época: 5, Train Loss: 0.00517932, Test Loss: 0.00613013,R2: 0.8708, MAE: 0.0635\n",
      "Ventana 87, Época: 7, Train Loss: 0.00474658, Test Loss: 0.00599098, R2: 0.8737, MAE: 0.0618\n",
      "Early stopping en la ventana 87, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 87\n",
      "-------------------\n",
      "Ventana 88 de 143\n",
      "Entrenando con semanas: [ 97  98  99 100 101 102 103 104 105 106], testeando en semanas [107 108 109], len train: 681, len test: 122, porcentaje: 0.85\n",
      "Iniciando ventana 88 con pesos de la ventana anterior\n",
      "Ventana 88, Época: 0, Train Loss: 0.00535594, Test Loss: 0.00733046,R2: 0.8280, MAE: 0.0642\n",
      "Ventana 88, Época: 5, Train Loss: 0.00437994, Test Loss: 0.00785555,R2: 0.8157, MAE: 0.0670\n",
      "Ventana 88, Época: 6, Train Loss: 0.00426189, Test Loss: 0.00790256, R2: 0.8146, MAE: 0.0674\n",
      "Early stopping en la ventana 88, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 88\n",
      "-------------------\n",
      "Ventana 89 de 143\n",
      "Entrenando con semanas: [ 98  99 100 101 102 103 104 105 106 107], testeando en semanas [108 109 110], len train: 585, len test: 188, porcentaje: 0.76\n",
      "Iniciando ventana 89 con pesos de la ventana anterior\n",
      "Ventana 89, Época: 0, Train Loss: 0.00525419, Test Loss: 0.00808064,R2: 0.7952, MAE: 0.0676\n",
      "Ventana 89, Época: 5, Train Loss: 0.00426329, Test Loss: 0.00809145,R2: 0.7949, MAE: 0.0689\n",
      "Ventana 89, Época: 9, Train Loss: 0.00408948, Test Loss: 0.00814680, R2: 0.7935, MAE: 0.0689\n",
      "Early stopping en la ventana 89, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 89\n",
      "-------------------\n",
      "Ventana 90 de 143\n",
      "Entrenando con semanas: [ 99 100 101 102 103 104 105 106 107 108], testeando en semanas [109 110 111], len train: 607, len test: 191, porcentaje: 0.76\n",
      "Iniciando ventana 90 con pesos de la ventana anterior\n",
      "Ventana 90, Época: 0, Train Loss: 0.00455881, Test Loss: 0.00882838,R2: 0.7658, MAE: 0.0721\n",
      "Ventana 90, Época: 5, Train Loss: 0.00385661, Test Loss: 0.00797274,R2: 0.7885, MAE: 0.0676\n",
      "Ventana 90, Época: 9, Train Loss: 0.00346377, Test Loss: 0.00851699, R2: 0.7740, MAE: 0.0704\n",
      "Early stopping en la ventana 90, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 90\n",
      "-------------------\n",
      "Ventana 91 de 143\n",
      "Entrenando con semanas: [100 101 102 103 104 105 106 107 108 109], testeando en semanas [110 111 112], len train: 543, len test: 231, porcentaje: 0.70\n",
      "Iniciando ventana 91 con pesos de la ventana anterior\n",
      "Ventana 91, Época: 0, Train Loss: 0.00503968, Test Loss: 0.00962550,R2: 0.6597, MAE: 0.0758\n",
      "Ventana 91, Época: 5, Train Loss: 0.00409874, Test Loss: 0.00925866,R2: 0.6727, MAE: 0.0755\n",
      "Ventana 91, Época: 10, Train Loss: 0.00364616, Test Loss: 0.00985835,R2: 0.6515, MAE: 0.0766\n",
      "Ventana 91, Época: 11, Train Loss: 0.00350770, Test Loss: 0.00967092, R2: 0.6581, MAE: 0.0759\n",
      "Early stopping en la ventana 91, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 91\n",
      "-------------------\n",
      "Ventana 92 de 143\n",
      "Entrenando con semanas: [101 102 103 104 105 106 107 108 109 110], testeando en semanas [111 112 113], len train: 526, len test: 261, porcentaje: 0.67\n",
      "Iniciando ventana 92 con pesos de la ventana anterior\n",
      "Ventana 92, Época: 0, Train Loss: 0.00444103, Test Loss: 0.01009393,R2: 0.7699, MAE: 0.0753\n",
      "Ventana 92, Época: 5, Train Loss: 0.00383626, Test Loss: 0.00907438,R2: 0.7932, MAE: 0.0713\n",
      "Ventana 92, Época: 10, Train Loss: 0.00336836, Test Loss: 0.00846542,R2: 0.8070, MAE: 0.0699\n",
      "Ventana 92, Época: 15, Train Loss: 0.00279639, Test Loss: 0.00816386,R2: 0.8139, MAE: 0.0680\n",
      "Ventana 92, Época: 20, Train Loss: 0.00306884, Test Loss: 0.00897542, R2: 0.7954, MAE: 0.0715\n",
      "Early stopping en la ventana 92, época 20\n",
      "Mejor modelo guardado en la época  15 para la ventana 92\n",
      "-------------------\n",
      "Ventana 93 de 143\n",
      "Entrenando con semanas: [102 103 104 105 106 107 108 109 110 111], testeando en semanas [112 113 114], len train: 563, len test: 223, porcentaje: 0.72\n",
      "Iniciando ventana 93 con pesos de la ventana anterior\n",
      "Ventana 93, Época: 0, Train Loss: 0.00294122, Test Loss: 0.00945498,R2: 0.7929, MAE: 0.0745\n",
      "Ventana 93, Época: 5, Train Loss: 0.00314374, Test Loss: 0.00824083,R2: 0.8195, MAE: 0.0689\n",
      "Ventana 93, Época: 10, Train Loss: 0.00322065, Test Loss: 0.00859010, R2: 0.8118, MAE: 0.0703\n",
      "Early stopping en la ventana 93, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 93\n",
      "-------------------\n",
      "Ventana 94 de 143\n",
      "Entrenando con semanas: [103 104 105 106 107 108 109 110 111 112], testeando en semanas [113 114 115], len train: 645, len test: 152, porcentaje: 0.81\n",
      "Iniciando ventana 94 con pesos de la ventana anterior\n",
      "Ventana 94, Época: 0, Train Loss: 0.00414534, Test Loss: 0.00604075,R2: 0.9051, MAE: 0.0592\n",
      "Ventana 94, Época: 5, Train Loss: 0.00333813, Test Loss: 0.00660892, R2: 0.8962, MAE: 0.0626\n",
      "Early stopping en la ventana 94, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 94\n",
      "-------------------\n",
      "Ventana 95 de 143\n",
      "Entrenando con semanas: [104 105 106 107 108 109 110 111 112 113], testeando en semanas [114 115 116], len train: 693, len test: 156, porcentaje: 0.82\n",
      "Iniciando ventana 95 con pesos de la ventana anterior\n",
      "Ventana 95, Época: 0, Train Loss: 0.00468017, Test Loss: 0.00624313,R2: 0.8603, MAE: 0.0596\n",
      "Ventana 95, Época: 5, Train Loss: 0.00352749, Test Loss: 0.00534664,R2: 0.8804, MAE: 0.0563\n",
      "Ventana 95, Época: 10, Train Loss: 0.00343363, Test Loss: 0.00584847, R2: 0.8691, MAE: 0.0606\n",
      "Early stopping en la ventana 95, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 95\n",
      "-------------------\n",
      "Ventana 96 de 143\n",
      "Entrenando con semanas: [105 106 107 108 109 110 111 112 113 114], testeando en semanas [115 116 117], len train: 598, len test: 181, porcentaje: 0.77\n",
      "Iniciando ventana 96 con pesos de la ventana anterior\n",
      "Ventana 96, Época: 0, Train Loss: 0.00386594, Test Loss: 0.00769684,R2: 0.8244, MAE: 0.0694\n",
      "Ventana 96, Época: 5, Train Loss: 0.00354451, Test Loss: 0.00582078,R2: 0.8672, MAE: 0.0599\n",
      "Ventana 96, Época: 6, Train Loss: 0.00312517, Test Loss: 0.00609792, R2: 0.8609, MAE: 0.0613\n",
      "Early stopping en la ventana 96, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 96\n",
      "-------------------\n",
      "Ventana 97 de 143\n",
      "Entrenando con semanas: [106 107 108 109 110 111 112 113 114 115], testeando en semanas [116 117 118], len train: 516, len test: 201, porcentaje: 0.72\n",
      "Iniciando ventana 97 con pesos de la ventana anterior\n",
      "Ventana 97, Época: 0, Train Loss: 0.00422043, Test Loss: 0.00832898,R2: 0.7931, MAE: 0.0722\n",
      "Ventana 97, Época: 5, Train Loss: 0.00329423, Test Loss: 0.00593058,R2: 0.8527, MAE: 0.0609\n",
      "Ventana 97, Época: 10, Train Loss: 0.00353310, Test Loss: 0.00604626,R2: 0.8498, MAE: 0.0614\n",
      "Ventana 97, Época: 12, Train Loss: 0.00336206, Test Loss: 0.00640293, R2: 0.8409, MAE: 0.0626\n",
      "Early stopping en la ventana 97, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 97\n",
      "-------------------\n",
      "Ventana 98 de 143\n",
      "Entrenando con semanas: [107 108 109 110 111 112 113 114 115 116], testeando en semanas [117 118 119], len train: 617, len test: 170, porcentaje: 0.78\n",
      "Iniciando ventana 98 con pesos de la ventana anterior\n",
      "Ventana 98, Época: 0, Train Loss: 0.00355882, Test Loss: 0.01080250,R2: 0.7005, MAE: 0.0837\n",
      "Ventana 98, Época: 5, Train Loss: 0.00323053, Test Loss: 0.00723323,R2: 0.7994, MAE: 0.0660\n",
      "Ventana 98, Época: 10, Train Loss: 0.00332134, Test Loss: 0.00758319,R2: 0.7897, MAE: 0.0698\n",
      "Ventana 98, Época: 13, Train Loss: 0.00287957, Test Loss: 0.00680604, R2: 0.8113, MAE: 0.0653\n",
      "Early stopping en la ventana 98, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 98\n",
      "-------------------\n",
      "Ventana 99 de 143\n",
      "Entrenando con semanas: [108 109 110 111 112 113 114 115 116 117], testeando en semanas [118 119 120], len train: 640, len test: 188, porcentaje: 0.77\n",
      "Iniciando ventana 99 con pesos de la ventana anterior\n",
      "Ventana 99, Época: 0, Train Loss: 0.00309236, Test Loss: 0.00755786,R2: 0.7813, MAE: 0.0695\n",
      "Ventana 99, Época: 5, Train Loss: 0.00302609, Test Loss: 0.00741449,R2: 0.7854, MAE: 0.0665\n",
      "Ventana 99, Época: 6, Train Loss: 0.00302279, Test Loss: 0.00655347, R2: 0.8103, MAE: 0.0637\n",
      "Early stopping en la ventana 99, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 99\n",
      "-------------------\n",
      "Ventana 100 de 143\n",
      "Entrenando con semanas: [109 110 111 112 113 114 115 116 117 118], testeando en semanas [119 120 121], len train: 649, len test: 136, porcentaje: 0.83\n",
      "Iniciando ventana 100 con pesos de la ventana anterior\n",
      "Ventana 100, Época: 0, Train Loss: 0.00339990, Test Loss: 0.00608488,R2: 0.8325, MAE: 0.0623\n",
      "Ventana 100, Época: 5, Train Loss: 0.00312279, Test Loss: 0.00584207,R2: 0.8392, MAE: 0.0598\n",
      "Ventana 100, Época: 6, Train Loss: 0.00293366, Test Loss: 0.00568600, R2: 0.8435, MAE: 0.0596\n",
      "Early stopping en la ventana 100, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 100\n",
      "-------------------\n",
      "Ventana 101 de 143\n",
      "Entrenando con semanas: [110 111 112 113 114 115 116 117 118 119], testeando en semanas [120 121 122], len train: 665, len test: 68, porcentaje: 0.91\n",
      "Iniciando ventana 101 con pesos de la ventana anterior\n",
      "Ventana 101, Época: 0, Train Loss: 0.00376202, Test Loss: 0.00556400,R2: 0.8455, MAE: 0.0597\n",
      "Ventana 101, Época: 5, Train Loss: 0.00307189, Test Loss: 0.00547485,R2: 0.8480, MAE: 0.0588\n",
      "Ventana 101, Época: 10, Train Loss: 0.00271612, Test Loss: 0.00612199,R2: 0.8300, MAE: 0.0611\n",
      "Ventana 101, Época: 15, Train Loss: 0.00254044, Test Loss: 0.00484432,R2: 0.8655, MAE: 0.0556\n",
      "Ventana 101, Época: 19, Train Loss: 0.00269708, Test Loss: 0.00417010, R2: 0.8842, MAE: 0.0527\n",
      "Early stopping en la ventana 101, época 19\n",
      "Mejor modelo guardado en la época  14 para la ventana 101\n",
      "-------------------\n",
      "Ventana 102 de 143\n",
      "Entrenando con semanas: [111 112 113 114 115 116 117 118 119 120], testeando en semanas [121 122 123], len train: 640, len test: 138, porcentaje: 0.82\n",
      "Iniciando ventana 102 con pesos de la ventana anterior\n",
      "Ventana 102, Época: 0, Train Loss: 0.00261618, Test Loss: 0.00727193,R2: 0.7561, MAE: 0.0671\n",
      "Ventana 102, Época: 5, Train Loss: 0.00264844, Test Loss: 0.00679361,R2: 0.7722, MAE: 0.0655\n",
      "Ventana 102, Época: 6, Train Loss: 0.00254573, Test Loss: 0.00759514, R2: 0.7453, MAE: 0.0692\n",
      "Early stopping en la ventana 102, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 102\n",
      "-------------------\n",
      "Ventana 103 de 143\n",
      "Entrenando con semanas: [112 113 114 115 116 117 118 119 120 121], testeando en semanas [122 123 124], len train: 594, len test: 232, porcentaje: 0.72\n",
      "Iniciando ventana 103 con pesos de la ventana anterior\n",
      "Ventana 103, Época: 0, Train Loss: 0.00310037, Test Loss: 0.01256139,R2: 0.7270, MAE: 0.0863\n",
      "Ventana 103, Época: 5, Train Loss: 0.00290797, Test Loss: 0.00884244,R2: 0.8078, MAE: 0.0743\n",
      "Ventana 103, Época: 10, Train Loss: 0.00320761, Test Loss: 0.00913118,R2: 0.8015, MAE: 0.0752\n",
      "Ventana 103, Época: 11, Train Loss: 0.00255938, Test Loss: 0.00939929, R2: 0.7957, MAE: 0.0765\n",
      "Early stopping en la ventana 103, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 103\n",
      "-------------------\n",
      "Ventana 104 de 143\n",
      "Entrenando con semanas: [113 114 115 116 117 118 119 120 121 122], testeando en semanas [123 124 125], len train: 502, len test: 230, porcentaje: 0.69\n",
      "Iniciando ventana 104 con pesos de la ventana anterior\n",
      "Ventana 104, Época: 0, Train Loss: 0.00266682, Test Loss: 0.00901913,R2: 0.8156, MAE: 0.0754\n",
      "Ventana 104, Época: 5, Train Loss: 0.00228264, Test Loss: 0.00899353,R2: 0.8161, MAE: 0.0743\n",
      "Ventana 104, Época: 6, Train Loss: 0.00223177, Test Loss: 0.00928144, R2: 0.8103, MAE: 0.0757\n",
      "Early stopping en la ventana 104, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 104\n",
      "-------------------\n",
      "Ventana 105 de 143\n",
      "Entrenando con semanas: [114 115 116 117 118 119 120 121 122 123], testeando en semanas [124 125 126], len train: 517, len test: 117, porcentaje: 0.82\n",
      "Iniciando ventana 105 con pesos de la ventana anterior\n",
      "Ventana 105, Época: 0, Train Loss: 0.00407811, Test Loss: 0.01267734,R2: 0.8061, MAE: 0.0898\n",
      "Ventana 105, Época: 5, Train Loss: 0.00359294, Test Loss: 0.01069072,R2: 0.8365, MAE: 0.0822\n",
      "Ventana 105, Época: 6, Train Loss: 0.00323996, Test Loss: 0.01064208, R2: 0.8373, MAE: 0.0814\n",
      "Early stopping en la ventana 105, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 105\n",
      "-------------------\n",
      "Ventana 106 de 143\n",
      "Entrenando con semanas: [115 116 117 118 119 120 121 122 123 124], testeando en semanas [125 126 127], len train: 603, len test: 69, porcentaje: 0.90\n",
      "Iniciando ventana 106 con pesos de la ventana anterior\n",
      "Ventana 106, Época: 0, Train Loss: 0.00497930, Test Loss: 0.00629501,R2: 0.8063, MAE: 0.0644\n",
      "Ventana 106, Época: 5, Train Loss: 0.00381634, Test Loss: 0.00674301,R2: 0.7925, MAE: 0.0627\n",
      "Ventana 106, Época: 10, Train Loss: 0.00328242, Test Loss: 0.00564642,R2: 0.8263, MAE: 0.0599\n",
      "Ventana 106, Época: 12, Train Loss: 0.00311759, Test Loss: 0.00650517, R2: 0.7999, MAE: 0.0624\n",
      "Early stopping en la ventana 106, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 106\n",
      "-------------------\n",
      "Ventana 107 de 143\n",
      "Entrenando con semanas: [116 117 118 119 120 121 122 123 124 125], testeando en semanas [126 127 128], len train: 580, len test: 131, porcentaje: 0.82\n",
      "Iniciando ventana 107 con pesos de la ventana anterior\n",
      "Ventana 107, Época: 0, Train Loss: 0.00406782, Test Loss: 0.00828035,R2: 0.6783, MAE: 0.0695\n",
      "Ventana 107, Época: 5, Train Loss: 0.00287229, Test Loss: 0.00767799,R2: 0.7017, MAE: 0.0676\n",
      "Ventana 107, Época: 10, Train Loss: 0.00252223, Test Loss: 0.00765489,R2: 0.7026, MAE: 0.0672\n",
      "Ventana 107, Época: 13, Train Loss: 0.00257587, Test Loss: 0.00791694, R2: 0.6924, MAE: 0.0680\n",
      "Early stopping en la ventana 107, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 107\n",
      "-------------------\n",
      "Ventana 108 de 143\n",
      "Entrenando con semanas: [117 118 119 120 121 122 123 124 125 126], testeando en semanas [127 128 129], len train: 478, len test: 181, porcentaje: 0.73\n",
      "Iniciando ventana 108 con pesos de la ventana anterior\n",
      "Ventana 108, Época: 0, Train Loss: 0.00322360, Test Loss: 0.00757210,R2: 0.7626, MAE: 0.0678\n",
      "Ventana 108, Época: 5, Train Loss: 0.00237143, Test Loss: 0.00691707,R2: 0.7832, MAE: 0.0651\n",
      "Ventana 108, Época: 9, Train Loss: 0.00330228, Test Loss: 0.00669342, R2: 0.7902, MAE: 0.0641\n",
      "Early stopping en la ventana 108, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 108\n",
      "-------------------\n",
      "Ventana 109 de 143\n",
      "Entrenando con semanas: [118 119 120 121 122 123 124 125 126 127], testeando en semanas [128 129 130], len train: 491, len test: 233, porcentaje: 0.68\n",
      "Iniciando ventana 109 con pesos de la ventana anterior\n",
      "Ventana 109, Época: 0, Train Loss: 0.00310447, Test Loss: 0.00796680,R2: 0.7688, MAE: 0.0694\n",
      "Ventana 109, Época: 5, Train Loss: 0.00261050, Test Loss: 0.00758646,R2: 0.7799, MAE: 0.0674\n",
      "Ventana 109, Época: 10, Train Loss: 0.00282577, Test Loss: 0.00770379,R2: 0.7765, MAE: 0.0689\n",
      "Ventana 109, Época: 11, Train Loss: 0.00248130, Test Loss: 0.00752454, R2: 0.7817, MAE: 0.0684\n",
      "Early stopping en la ventana 109, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 109\n",
      "-------------------\n",
      "Ventana 110 de 143\n",
      "Entrenando con semanas: [119 120 121 122 123 124 125 126 127 128], testeando en semanas [129 130 131], len train: 510, len test: 184, porcentaje: 0.73\n",
      "Iniciando ventana 110 con pesos de la ventana anterior\n",
      "Ventana 110, Época: 0, Train Loss: 0.00349746, Test Loss: 0.00635815,R2: 0.8423, MAE: 0.0626\n",
      "Ventana 110, Época: 5, Train Loss: 0.00295830, Test Loss: 0.00677121, R2: 0.8320, MAE: 0.0650\n",
      "Early stopping en la ventana 110, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 110\n",
      "-------------------\n",
      "Ventana 111 de 143\n",
      "Entrenando con semanas: [120 121 122 123 124 125 126 127 128 129], testeando en semanas [130 131 132], len train: 489, len test: 223, porcentaje: 0.69\n",
      "Iniciando ventana 111 con pesos de la ventana anterior\n",
      "Ventana 111, Época: 0, Train Loss: 0.00402013, Test Loss: 0.00696881,R2: 0.8066, MAE: 0.0655\n",
      "Ventana 111, Época: 5, Train Loss: 0.00338480, Test Loss: 0.00672810,R2: 0.8133, MAE: 0.0632\n",
      "Ventana 111, Época: 6, Train Loss: 0.00364400, Test Loss: 0.00643828, R2: 0.8214, MAE: 0.0623\n",
      "Early stopping en la ventana 111, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 111\n",
      "-------------------\n",
      "Ventana 112 de 143\n",
      "Entrenando con semanas: [121 122 123 124 125 126 127 128 129 130], testeando en semanas [131 132 133], len train: 536, len test: 148, porcentaje: 0.78\n",
      "Iniciando ventana 112 con pesos de la ventana anterior\n",
      "Ventana 112, Época: 0, Train Loss: 0.00446596, Test Loss: 0.00627907,R2: 0.8512, MAE: 0.0626\n",
      "Ventana 112, Época: 5, Train Loss: 0.00387673, Test Loss: 0.00501253,R2: 0.8812, MAE: 0.0544\n",
      "Ventana 112, Época: 10, Train Loss: 0.00313808, Test Loss: 0.00497691,R2: 0.8820, MAE: 0.0533\n",
      "Ventana 112, Época: 15, Train Loss: 0.00275223, Test Loss: 0.00607133,R2: 0.8561, MAE: 0.0603\n",
      "Ventana 112, Época: 17, Train Loss: 0.00239877, Test Loss: 0.00504223, R2: 0.8805, MAE: 0.0552\n",
      "Early stopping en la ventana 112, época 17\n",
      "Mejor modelo guardado en la época  12 para la ventana 112\n",
      "-------------------\n",
      "Ventana 113 de 143\n",
      "Entrenando con semanas: [122 123 124 125 126 127 128 129 130 131], testeando en semanas [132 133 134], len train: 558, len test: 148, porcentaje: 0.79\n",
      "Iniciando ventana 113 con pesos de la ventana anterior\n",
      "Ventana 113, Época: 0, Train Loss: 0.00305515, Test Loss: 0.00618849,R2: 0.8278, MAE: 0.0608\n",
      "Ventana 113, Época: 5, Train Loss: 0.00248627, Test Loss: 0.00618390, R2: 0.8279, MAE: 0.0613\n",
      "Early stopping en la ventana 113, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 113\n",
      "-------------------\n",
      "Ventana 114 de 143\n",
      "Entrenando con semanas: [123 124 125 126 127 128 129 130 131 132], testeando en semanas [133 134 135], len train: 644, len test: 114, porcentaje: 0.85\n",
      "Iniciando ventana 114 con pesos de la ventana anterior\n",
      "Ventana 114, Época: 0, Train Loss: 0.00310836, Test Loss: 0.00716510,R2: 0.8191, MAE: 0.0651\n",
      "Ventana 114, Época: 5, Train Loss: 0.00294488, Test Loss: 0.00726465,R2: 0.8165, MAE: 0.0663\n",
      "Ventana 114, Época: 6, Train Loss: 0.00275142, Test Loss: 0.00724894, R2: 0.8169, MAE: 0.0660\n",
      "Early stopping en la ventana 114, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 114\n",
      "-------------------\n",
      "Ventana 115 de 143\n",
      "Entrenando con semanas: [124 125 126 127 128 129 130 131 132 133], testeando en semanas [134 135 136], len train: 546, len test: 132, porcentaje: 0.81\n",
      "Iniciando ventana 115 con pesos de la ventana anterior\n",
      "Ventana 115, Época: 0, Train Loss: 0.00335802, Test Loss: 0.00819691,R2: 0.7491, MAE: 0.0695\n",
      "Ventana 115, Época: 5, Train Loss: 0.00286236, Test Loss: 0.00803022,R2: 0.7542, MAE: 0.0692\n",
      "Ventana 115, Época: 10, Train Loss: 0.00234278, Test Loss: 0.00798681,R2: 0.7555, MAE: 0.0705\n",
      "Ventana 115, Época: 13, Train Loss: 0.00211765, Test Loss: 0.00838894, R2: 0.7432, MAE: 0.0720\n",
      "Early stopping en la ventana 115, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 115\n",
      "-------------------\n",
      "Ventana 116 de 143\n",
      "Entrenando con semanas: [125 126 127 128 129 130 131 132 133 134], testeando en semanas [135 136 137], len train: 474, len test: 210, porcentaje: 0.69\n",
      "Iniciando ventana 116 con pesos de la ventana anterior\n",
      "Ventana 116, Época: 0, Train Loss: 0.00317695, Test Loss: 0.00885470,R2: 0.7368, MAE: 0.0729\n",
      "Ventana 116, Época: 5, Train Loss: 0.00251270, Test Loss: 0.00975175, R2: 0.7101, MAE: 0.0760\n",
      "Early stopping en la ventana 116, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 116\n",
      "-------------------\n",
      "Ventana 117 de 143\n",
      "Entrenando con semanas: [126 127 128 129 130 131 132 133 134 135], testeando en semanas [136 137 138], len train: 528, len test: 164, porcentaje: 0.76\n",
      "Iniciando ventana 117 con pesos de la ventana anterior\n",
      "Ventana 117, Época: 0, Train Loss: 0.00342683, Test Loss: 0.01005343,R2: 0.7103, MAE: 0.0775\n",
      "Ventana 117, Época: 5, Train Loss: 0.00288310, Test Loss: 0.01017888,R2: 0.7067, MAE: 0.0787\n",
      "Ventana 117, Época: 7, Train Loss: 0.00267296, Test Loss: 0.00989406, R2: 0.7149, MAE: 0.0762\n",
      "Early stopping en la ventana 117, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 117\n",
      "-------------------\n",
      "Ventana 118 de 143\n",
      "Entrenando con semanas: [127 128 129 130 131 132 133 134 135 136], testeando en semanas [137 138 139], len train: 561, len test: 227, porcentaje: 0.71\n",
      "Iniciando ventana 118 con pesos de la ventana anterior\n",
      "Ventana 118, Época: 0, Train Loss: 0.00361142, Test Loss: 0.00924585,R2: 0.7146, MAE: 0.0731\n",
      "Ventana 118, Época: 5, Train Loss: 0.00310719, Test Loss: 0.00959320, R2: 0.7039, MAE: 0.0735\n",
      "Early stopping en la ventana 118, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 118\n",
      "-------------------\n",
      "Ventana 119 de 143\n",
      "Entrenando con semanas: [128 129 130 131 132 133 134 135 136 137], testeando en semanas [138 139 140], len train: 615, len test: 148, porcentaje: 0.81\n",
      "Iniciando ventana 119 con pesos de la ventana anterior\n",
      "Ventana 119, Época: 0, Train Loss: 0.00474914, Test Loss: 0.00900000,R2: 0.7294, MAE: 0.0719\n",
      "Ventana 119, Época: 5, Train Loss: 0.00378390, Test Loss: 0.00832889,R2: 0.7496, MAE: 0.0704\n",
      "Ventana 119, Época: 10, Train Loss: 0.00370809, Test Loss: 0.00838118,R2: 0.7480, MAE: 0.0699\n",
      "Ventana 119, Época: 15, Train Loss: 0.00328869, Test Loss: 0.00821811,R2: 0.7529, MAE: 0.0699\n",
      "Ventana 119, Época: 16, Train Loss: 0.00293634, Test Loss: 0.00853206, R2: 0.7435, MAE: 0.0713\n",
      "Early stopping en la ventana 119, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 119\n",
      "-------------------\n",
      "Ventana 120 de 143\n",
      "Entrenando con semanas: [129 130 131 132 133 134 135 136 137 138], testeando en semanas [139 140 141], len train: 561, len test: 223, porcentaje: 0.72\n",
      "Iniciando ventana 120 con pesos de la ventana anterior\n",
      "Ventana 120, Época: 0, Train Loss: 0.00405390, Test Loss: 0.01159761,R2: 0.6132, MAE: 0.0828\n",
      "Ventana 120, Época: 5, Train Loss: 0.00298631, Test Loss: 0.00988945,R2: 0.6702, MAE: 0.0777\n",
      "Ventana 120, Época: 6, Train Loss: 0.00424793, Test Loss: 0.00947877, R2: 0.6838, MAE: 0.0741\n",
      "Early stopping en la ventana 120, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 120\n",
      "-------------------\n",
      "Ventana 121 de 143\n",
      "Entrenando con semanas: [130 131 132 133 134 135 136 137 138 139], testeando en semanas [140 141 142], len train: 607, len test: 210, porcentaje: 0.74\n",
      "Iniciando ventana 121 con pesos de la ventana anterior\n",
      "Ventana 121, Época: 0, Train Loss: 0.00473674, Test Loss: 0.01852184,R2: 0.6225, MAE: 0.1038\n",
      "Ventana 121, Época: 5, Train Loss: 0.00673099, Test Loss: 0.01183120,R2: 0.7589, MAE: 0.0846\n",
      "Ventana 121, Época: 6, Train Loss: 0.00416828, Test Loss: 0.01453725, R2: 0.7037, MAE: 0.0944\n",
      "Early stopping en la ventana 121, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 121\n",
      "-------------------\n",
      "Ventana 122 de 143\n",
      "Entrenando con semanas: [131 132 133 134 135 136 137 138 139 140], testeando en semanas [141 142 143], len train: 530, len test: 197, porcentaje: 0.73\n",
      "Iniciando ventana 122 con pesos de la ventana anterior\n",
      "Ventana 122, Época: 0, Train Loss: 0.00500186, Test Loss: 0.01161269,R2: 0.7736, MAE: 0.0804\n",
      "Ventana 122, Época: 5, Train Loss: 0.00408635, Test Loss: 0.01020229,R2: 0.8011, MAE: 0.0769\n",
      "Ventana 122, Época: 10, Train Loss: 0.00340955, Test Loss: 0.01030961, R2: 0.7990, MAE: 0.0779\n",
      "Early stopping en la ventana 122, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 122\n",
      "-------------------\n",
      "Ventana 123 de 143\n",
      "Entrenando con semanas: [132 133 134 135 136 137 138 139 140 141], testeando en semanas [142 143 144], len train: 600, len test: 126, porcentaje: 0.83\n",
      "Iniciando ventana 123 con pesos de la ventana anterior\n",
      "Ventana 123, Época: 0, Train Loss: 0.00453946, Test Loss: 0.01179355,R2: 0.8088, MAE: 0.0827\n",
      "Ventana 123, Época: 5, Train Loss: 0.00382123, Test Loss: 0.01167375,R2: 0.8108, MAE: 0.0808\n",
      "Ventana 123, Época: 10, Train Loss: 0.00325123, Test Loss: 0.01103096,R2: 0.8212, MAE: 0.0790\n",
      "Ventana 123, Época: 15, Train Loss: 0.00264828, Test Loss: 0.01118890,R2: 0.8186, MAE: 0.0793\n",
      "Ventana 123, Época: 16, Train Loss: 0.00317816, Test Loss: 0.01122067, R2: 0.8181, MAE: 0.0793\n",
      "Early stopping en la ventana 123, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 123\n",
      "-------------------\n",
      "Ventana 124 de 143\n",
      "Entrenando con semanas: [133 134 135 136 137 138 139 140 141 142], testeando en semanas [143 144 145], len train: 594, len test: 91, porcentaje: 0.87\n",
      "Iniciando ventana 124 con pesos de la ventana anterior\n",
      "Ventana 124, Época: 0, Train Loss: 0.00438603, Test Loss: 0.01144002,R2: 0.7346, MAE: 0.0861\n",
      "Ventana 124, Época: 5, Train Loss: 0.00362265, Test Loss: 0.01098103,R2: 0.7452, MAE: 0.0843\n",
      "Ventana 124, Época: 10, Train Loss: 0.00321474, Test Loss: 0.01076728,R2: 0.7502, MAE: 0.0821\n",
      "Ventana 124, Época: 12, Train Loss: 0.00349682, Test Loss: 0.01051814, R2: 0.7560, MAE: 0.0815\n",
      "Early stopping en la ventana 124, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 124\n",
      "-------------------\n",
      "Ventana 125 de 143\n",
      "Entrenando con semanas: [134 135 136 137 138 139 140 141 142 143], testeando en semanas [144 145 146], len train: 579, len test: 158, porcentaje: 0.79\n",
      "Iniciando ventana 125 con pesos de la ventana anterior\n",
      "Ventana 125, Época: 0, Train Loss: 0.00375264, Test Loss: 0.01169554,R2: 0.7079, MAE: 0.0852\n",
      "Ventana 125, Época: 5, Train Loss: 0.00321983, Test Loss: 0.01155451,R2: 0.7114, MAE: 0.0841\n",
      "Ventana 125, Época: 10, Train Loss: 0.00299901, Test Loss: 0.01171907, R2: 0.7073, MAE: 0.0844\n",
      "Early stopping en la ventana 125, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 125\n",
      "-------------------\n",
      "Ventana 126 de 143\n",
      "Entrenando con semanas: [135 136 137 138 139 140 141 142 143 144], testeando en semanas [145 146 147], len train: 578, len test: 244, porcentaje: 0.70\n",
      "Iniciando ventana 126 con pesos de la ventana anterior\n",
      "Ventana 126, Época: 0, Train Loss: 0.00376945, Test Loss: 0.01248916,R2: 0.7706, MAE: 0.0886\n",
      "Ventana 126, Época: 5, Train Loss: 0.00294478, Test Loss: 0.01212612,R2: 0.7773, MAE: 0.0863\n",
      "Ventana 126, Época: 6, Train Loss: 0.00273532, Test Loss: 0.01163293, R2: 0.7864, MAE: 0.0840\n",
      "Early stopping en la ventana 126, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 126\n",
      "-------------------\n",
      "Ventana 127 de 143\n",
      "Entrenando con semanas: [136 137 138 139 140 141 142 143 144 145], testeando en semanas [146 147 148], len train: 571, len test: 208, porcentaje: 0.73\n",
      "Iniciando ventana 127 con pesos de la ventana anterior\n",
      "Ventana 127, Época: 0, Train Loss: 0.00439209, Test Loss: 0.01246516,R2: 0.7694, MAE: 0.0872\n",
      "Ventana 127, Época: 5, Train Loss: 0.00345856, Test Loss: 0.01118535,R2: 0.7930, MAE: 0.0815\n",
      "Ventana 127, Época: 10, Train Loss: 0.00297524, Test Loss: 0.01152651,R2: 0.7867, MAE: 0.0826\n",
      "Ventana 127, Época: 15, Train Loss: 0.00265156, Test Loss: 0.01077003,R2: 0.8007, MAE: 0.0804\n",
      "Ventana 127, Época: 20, Train Loss: 0.00252029, Test Loss: 0.01033570,R2: 0.8088, MAE: 0.0778\n",
      "Ventana 127, Época: 25, Train Loss: 0.00258455, Test Loss: 0.01064145,R2: 0.8031, MAE: 0.0783\n",
      "Ventana 127, Época: 28, Train Loss: 0.00244627, Test Loss: 0.01057495, R2: 0.8043, MAE: 0.0778\n",
      "Early stopping en la ventana 127, época 28\n",
      "Mejor modelo guardado en la época  23 para la ventana 127\n",
      "-------------------\n",
      "Ventana 128 de 143\n",
      "Entrenando con semanas: [137 138 139 140 141 142 143 144 145 146], testeando en semanas [147 148 149], len train: 605, len test: 159, porcentaje: 0.79\n",
      "Iniciando ventana 128 con pesos de la ventana anterior\n",
      "Ventana 128, Época: 0, Train Loss: 0.00367348, Test Loss: 0.00954974,R2: 0.8369, MAE: 0.0740\n",
      "Ventana 128, Época: 5, Train Loss: 0.00331160, Test Loss: 0.00778385,R2: 0.8670, MAE: 0.0678\n",
      "Ventana 128, Época: 10, Train Loss: 0.00276514, Test Loss: 0.00751194,R2: 0.8717, MAE: 0.0671\n",
      "Ventana 128, Época: 15, Train Loss: 0.00239059, Test Loss: 0.00710281,R2: 0.8787, MAE: 0.0654\n",
      "Ventana 128, Época: 19, Train Loss: 0.00234849, Test Loss: 0.00740109, R2: 0.8736, MAE: 0.0671\n",
      "Early stopping en la ventana 128, época 19\n",
      "Mejor modelo guardado en la época  14 para la ventana 128\n",
      "-------------------\n",
      "Ventana 129 de 143\n",
      "Entrenando con semanas: [138 139 140 141 142 143 144 145 146 147], testeando en semanas [148 149 150], len train: 612, len test: 67, porcentaje: 0.90\n",
      "Iniciando ventana 129 con pesos de la ventana anterior\n",
      "Ventana 129, Época: 0, Train Loss: 0.00362546, Test Loss: 0.00956349,R2: 0.6820, MAE: 0.0770\n",
      "Ventana 129, Época: 5, Train Loss: 0.00332084, Test Loss: 0.00928421,R2: 0.6913, MAE: 0.0784\n",
      "Ventana 129, Época: 10, Train Loss: 0.00332081, Test Loss: 0.00892038,R2: 0.7034, MAE: 0.0761\n",
      "Ventana 129, Época: 11, Train Loss: 0.00245663, Test Loss: 0.00896959, R2: 0.7017, MAE: 0.0766\n",
      "Early stopping en la ventana 129, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 129\n",
      "-------------------\n",
      "Ventana 130 de 143\n",
      "Entrenando con semanas: [139 140 141 142 143 144 145 146 147 148], testeando en semanas [149 150 151], len train: 615, len test: 99, porcentaje: 0.86\n",
      "Iniciando ventana 130 con pesos de la ventana anterior\n",
      "Ventana 130, Época: 0, Train Loss: 0.00313781, Test Loss: 0.00689040,R2: 0.7142, MAE: 0.0647\n",
      "Ventana 130, Época: 5, Train Loss: 0.00281675, Test Loss: 0.00684513,R2: 0.7161, MAE: 0.0654\n",
      "Ventana 130, Época: 10, Train Loss: 0.00286846, Test Loss: 0.00652434,R2: 0.7294, MAE: 0.0644\n",
      "Ventana 130, Época: 15, Train Loss: 0.00254554, Test Loss: 0.00643017,R2: 0.7333, MAE: 0.0642\n",
      "Ventana 130, Época: 20, Train Loss: 0.00204320, Test Loss: 0.00652927,R2: 0.7292, MAE: 0.0656\n",
      "Ventana 130, Época: 22, Train Loss: 0.00213845, Test Loss: 0.00657775, R2: 0.7272, MAE: 0.0662\n",
      "Early stopping en la ventana 130, época 22\n",
      "Mejor modelo guardado en la época  17 para la ventana 130\n",
      "-------------------\n",
      "Ventana 131 de 143\n",
      "Entrenando con semanas: [140 141 142 143 144 145 146 147 148 149], testeando en semanas [150 151 152], len train: 537, len test: 140, porcentaje: 0.79\n",
      "Iniciando ventana 131 con pesos de la ventana anterior\n",
      "Ventana 131, Época: 0, Train Loss: 0.00270480, Test Loss: 0.01015117,R2: 0.6124, MAE: 0.0813\n",
      "Ventana 131, Época: 5, Train Loss: 0.00262720, Test Loss: 0.00724033,R2: 0.7236, MAE: 0.0677\n",
      "Ventana 131, Época: 10, Train Loss: 0.00258226, Test Loss: 0.00784448, R2: 0.7005, MAE: 0.0704\n",
      "Early stopping en la ventana 131, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 131\n",
      "-------------------\n",
      "Ventana 132 de 143\n",
      "Entrenando con semanas: [141 142 143 144 145 146 147 148 149 150], testeando en semanas [151 152 153], len train: 531, len test: 182, porcentaje: 0.74\n",
      "Iniciando ventana 132 con pesos de la ventana anterior\n",
      "Ventana 132, Época: 0, Train Loss: 0.00271044, Test Loss: 0.01036105,R2: 0.6335, MAE: 0.0827\n",
      "Ventana 132, Época: 5, Train Loss: 0.00284672, Test Loss: 0.00760922,R2: 0.7309, MAE: 0.0708\n",
      "Ventana 132, Época: 7, Train Loss: 0.00273755, Test Loss: 0.00808945, R2: 0.7139, MAE: 0.0730\n",
      "Early stopping en la ventana 132, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 132\n",
      "-------------------\n",
      "Ventana 133 de 143\n",
      "Entrenando con semanas: [142 143 144 145 146 147 148 149 150 151], testeando en semanas [152 153 154], len train: 491, len test: 222, porcentaje: 0.69\n",
      "Iniciando ventana 133 con pesos de la ventana anterior\n",
      "Ventana 133, Época: 0, Train Loss: 0.00361813, Test Loss: 0.01439719,R2: 0.4674, MAE: 0.0964\n",
      "Ventana 133, Época: 5, Train Loss: 0.00432331, Test Loss: 0.00807946,R2: 0.7011, MAE: 0.0732\n",
      "Ventana 133, Época: 10, Train Loss: 0.00206016, Test Loss: 0.00758047,R2: 0.7196, MAE: 0.0695\n",
      "Ventana 133, Época: 15, Train Loss: 0.00286516, Test Loss: 0.00769053,R2: 0.7155, MAE: 0.0709\n",
      "Ventana 133, Época: 19, Train Loss: 0.00225771, Test Loss: 0.00774382, R2: 0.7135, MAE: 0.0707\n",
      "Early stopping en la ventana 133, época 19\n",
      "Mejor modelo guardado en la época  14 para la ventana 133\n",
      "-------------------\n",
      "Ventana 134 de 143\n",
      "Entrenando con semanas: [143 144 145 146 147 148 149 150 151 152], testeando en semanas [153 154 155], len train: 467, len test: 261, porcentaje: 0.64\n",
      "Iniciando ventana 134 con pesos de la ventana anterior\n",
      "Ventana 134, Época: 0, Train Loss: 0.00353142, Test Loss: 0.00858595,R2: 0.7921, MAE: 0.0732\n",
      "Ventana 134, Época: 5, Train Loss: 0.00248498, Test Loss: 0.00821401,R2: 0.8012, MAE: 0.0720\n",
      "Ventana 134, Época: 9, Train Loss: 0.00223183, Test Loss: 0.00781240, R2: 0.8109, MAE: 0.0694\n",
      "Early stopping en la ventana 134, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 134\n",
      "-------------------\n",
      "Ventana 135 de 143\n",
      "Entrenando con semanas: [144 145 146 147 148 149 150 151 152 153], testeando en semanas [154 155 156], len train: 516, len test: 212, porcentaje: 0.71\n",
      "Iniciando ventana 135 con pesos de la ventana anterior\n",
      "Ventana 135, Época: 0, Train Loss: 0.00274667, Test Loss: 0.00834665,R2: 0.8162, MAE: 0.0721\n",
      "Ventana 135, Época: 5, Train Loss: 0.00265704, Test Loss: 0.00819006,R2: 0.8196, MAE: 0.0700\n",
      "Ventana 135, Época: 6, Train Loss: 0.00217779, Test Loss: 0.00839504, R2: 0.8151, MAE: 0.0709\n",
      "Early stopping en la ventana 135, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 135\n",
      "-------------------\n",
      "Ventana 136 de 143\n",
      "Entrenando con semanas: [145 146 147 148 149 150 151 152 153 154], testeando en semanas [155 156 157], len train: 587, len test: 191, porcentaje: 0.75\n",
      "Iniciando ventana 136 con pesos de la ventana anterior\n",
      "Ventana 136, Época: 0, Train Loss: 0.00405683, Test Loss: 0.00670069,R2: 0.8734, MAE: 0.0654\n",
      "Ventana 136, Época: 5, Train Loss: 0.00311790, Test Loss: 0.00669009,R2: 0.8736, MAE: 0.0646\n",
      "Ventana 136, Época: 10, Train Loss: 0.00264541, Test Loss: 0.00643160,R2: 0.8785, MAE: 0.0637\n",
      "Ventana 136, Época: 13, Train Loss: 0.00233629, Test Loss: 0.00607140, R2: 0.8853, MAE: 0.0622\n",
      "Early stopping en la ventana 136, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 136\n",
      "-------------------\n",
      "Ventana 137 de 143\n",
      "Entrenando con semanas: [146 147 148 149 150 151 152 153 154 155], testeando en semanas [156 157 158], len train: 637, len test: 184, porcentaje: 0.78\n",
      "Iniciando ventana 137 con pesos de la ventana anterior\n",
      "Ventana 137, Época: 0, Train Loss: 0.00379245, Test Loss: 0.00514731,R2: 0.8775, MAE: 0.0590\n",
      "Ventana 137, Época: 5, Train Loss: 0.00297610, Test Loss: 0.00486947,R2: 0.8841, MAE: 0.0578\n",
      "Ventana 137, Época: 10, Train Loss: 0.00287130, Test Loss: 0.00456986,R2: 0.8913, MAE: 0.0551\n",
      "Ventana 137, Época: 15, Train Loss: 0.00252201, Test Loss: 0.00456082, R2: 0.8915, MAE: 0.0547\n",
      "Early stopping en la ventana 137, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 137\n",
      "-------------------\n",
      "Ventana 138 de 143\n",
      "Entrenando con semanas: [147 148 149 150 151 152 153 154 155 156], testeando en semanas [157 158 159], len train: 570, len test: 210, porcentaje: 0.73\n",
      "Iniciando ventana 138 con pesos de la ventana anterior\n",
      "Ventana 138, Época: 0, Train Loss: 0.00227906, Test Loss: 0.00505672,R2: 0.8866, MAE: 0.0573\n",
      "Ventana 138, Época: 5, Train Loss: 0.00214608, Test Loss: 0.00520485,R2: 0.8832, MAE: 0.0592\n",
      "Ventana 138, Época: 6, Train Loss: 0.00217106, Test Loss: 0.00519031, R2: 0.8836, MAE: 0.0592\n",
      "Early stopping en la ventana 138, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 138\n",
      "-------------------\n",
      "Ventana 139 de 143\n",
      "Entrenando con semanas: [148 149 150 151 152 153 154 155 156 157], testeando en semanas [158 159 160], len train: 534, len test: 152, porcentaje: 0.78\n",
      "Iniciando ventana 139 con pesos de la ventana anterior\n",
      "Ventana 139, Época: 0, Train Loss: 0.00291903, Test Loss: 0.00562577,R2: 0.8772, MAE: 0.0603\n",
      "Ventana 139, Época: 5, Train Loss: 0.00259548, Test Loss: 0.00606749, R2: 0.8675, MAE: 0.0629\n",
      "Early stopping en la ventana 139, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 139\n",
      "-------------------\n",
      "Ventana 140 de 143\n",
      "Entrenando con semanas: [149 150 151 152 153 154 155 156 157 158], testeando en semanas [159 160 161], len train: 613, len test: 129, porcentaje: 0.83\n",
      "Iniciando ventana 140 con pesos de la ventana anterior\n",
      "Ventana 140, Época: 0, Train Loss: 0.00323799, Test Loss: 0.00577777,R2: 0.8342, MAE: 0.0623\n",
      "Ventana 140, Época: 5, Train Loss: 0.00254034, Test Loss: 0.00571228,R2: 0.8361, MAE: 0.0621\n",
      "Ventana 140, Época: 10, Train Loss: 0.00262668, Test Loss: 0.00569321,R2: 0.8366, MAE: 0.0610\n",
      "Ventana 140, Época: 13, Train Loss: 0.00225121, Test Loss: 0.00584835, R2: 0.8322, MAE: 0.0612\n",
      "Early stopping en la ventana 140, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 140\n",
      "-------------------\n",
      "Ventana 141 de 143\n",
      "Entrenando con semanas: [150 151 152 153 154 155 156 157 158 159], testeando en semanas [160 161 162], len train: 621, len test: 147, porcentaje: 0.81\n",
      "Iniciando ventana 141 con pesos de la ventana anterior\n",
      "Ventana 141, Época: 0, Train Loss: 0.00264899, Test Loss: 0.00549032,R2: 0.8058, MAE: 0.0605\n",
      "Ventana 141, Época: 5, Train Loss: 0.00241523, Test Loss: 0.00565057,R2: 0.8001, MAE: 0.0613\n",
      "Ventana 141, Época: 6, Train Loss: 0.00232632, Test Loss: 0.00552642, R2: 0.8045, MAE: 0.0607\n",
      "Early stopping en la ventana 141, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 141\n",
      "-------------------\n",
      "Ventana 142 de 143\n",
      "Entrenando con semanas: [151 152 153 154 155 156 157 158 159 160], testeando en semanas [161 162 163], len train: 619, len test: 134, porcentaje: 0.82\n",
      "Iniciando ventana 142 con pesos de la ventana anterior\n",
      "Ventana 142, Época: 0, Train Loss: 0.00297819, Test Loss: 0.00503168,R2: 0.8252, MAE: 0.0578\n",
      "Ventana 142, Época: 5, Train Loss: 0.00238532, Test Loss: 0.00485777,R2: 0.8312, MAE: 0.0565\n",
      "Ventana 142, Época: 10, Train Loss: 0.00221514, Test Loss: 0.00462229,R2: 0.8394, MAE: 0.0553\n",
      "Ventana 142, Época: 14, Train Loss: 0.00192012, Test Loss: 0.00506719, R2: 0.8239, MAE: 0.0573\n",
      "Early stopping en la ventana 142, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 142\n",
      "-------------------\n",
      "Ventana 143 de 143\n",
      "Entrenando con semanas: [152 153 154 155 156 157 158 159 160 161], testeando en semanas [162 163 164], len train: 643, len test: 69, porcentaje: 0.90\n",
      "Iniciando ventana 143 con pesos de la ventana anterior\n",
      "Ventana 143, Época: 0, Train Loss: 0.00250980, Test Loss: 0.00536606,R2: 0.8509, MAE: 0.0575\n",
      "Ventana 143, Época: 5, Train Loss: 0.00263288, Test Loss: 0.00486688,R2: 0.8648, MAE: 0.0561\n",
      "Ventana 143, Época: 10, Train Loss: 0.00213618, Test Loss: 0.00478320,R2: 0.8671, MAE: 0.0540\n",
      "Ventana 143, Época: 15, Train Loss: 0.00186124, Test Loss: 0.00507718, R2: 0.8589, MAE: 0.0570\n",
      "Early stopping en la ventana 143, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 143\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "ejemplos_predicciones = []\n",
    "\n",
    "class TennisRNN(nn.Module):\n",
    "    def __init__(self, input_size_actual, input_size_previos, hidden_size, num_layers, output_size, dropout_rate):\n",
    "        super(TennisRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU para datos históricos del jugador local\n",
    "        self.gru_home = nn.GRU(\n",
    "            input_size=input_size_previos,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0\n",
    "        )\n",
    "        # GRU para datos históricos del jugador visitante\n",
    "        self.gru_away = nn.GRU(\n",
    "            input_size=input_size_previos,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0\n",
    "        )\n",
    "        # Capa de proyección para las características actuales\n",
    "        self.actual_projection = nn.Linear(input_size_actual, input_size_actual * 2)\n",
    "\n",
    "        # Capa de concatenación y fully connected\n",
    "        combined_size = hidden_size * 2 + input_size_actual * 2  \n",
    "        self.fc1 = nn.Linear(combined_size, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size//2, output_size)\n",
    "        \n",
    "    def forward(self, x_actual, x_home, x_away):\n",
    "        _, (home_features, _) = self.gru_home(x_home)\n",
    "        _, (away_features, _) = self.gru_away(x_away)\n",
    "        \n",
    "        # Capa de proyección para las características actuales\n",
    "        x_actual_projected = self.actual_projection(x_actual)\n",
    "        combined = torch.cat((home_features, away_features, x_actual_projected), dim=1)\n",
    "\n",
    "        # Pasar por las capas fully connected\n",
    "        x = torch.relu(self.fc1(combined))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        # Utilizamos sigmoid para obtener un valor entre 0 y 1 (probabilidad)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def calculate_metrics(pred, target):\n",
    "    \"\"\"\n",
    "    Calcula métricas específicas para regresión\n",
    "    \"\"\"\n",
    "    pred_np = pred.cpu().numpy().flatten()\n",
    "    target_np = target.cpu().numpy().flatten()\n",
    "    \n",
    "    # Calcular métricas\n",
    "    mae = mean_absolute_error(target_np, pred_np)\n",
    "    mse = mean_squared_error(target_np, pred_np)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(target_np, pred_np)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error) - cuidado con divisiones por cero\n",
    "    mape = np.mean(np.abs((target_np - pred_np) / np.clip(target_np, 1e-8, None))) * 100\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mape': mape\n",
    "    }\n",
    "\n",
    "def guardar_ejemplos_prediccion(y_pred, y_true, indices_test, ventana, umbral_precision=0.05, umbral_error=0.20):\n",
    "    \"\"\"\n",
    "    Guarda ejemplos de predicciones para análisis posterior\n",
    "    \"\"\"\n",
    "    y_pred_np = y_pred.cpu().numpy().flatten()\n",
    "    y_true_np = y_true.cpu().numpy().flatten()\n",
    "    \n",
    "    # Calcular errores absolutos\n",
    "    errores = np.abs(y_pred_np - y_true_np)\n",
    "    \n",
    "    # Casos de alta precisión (error < umbral_precision)\n",
    "    indices_precision = np.where(errores < umbral_precision)[0]\n",
    "    \n",
    "    # Casos de error significativo (error > umbral_error)\n",
    "    indices_error = np.where(errores > umbral_error)[0]\n",
    "    \n",
    "    # Guardar algunos ejemplos de cada tipo (máximo 3 por ventana)\n",
    "    for idx in indices_precision[:3]:\n",
    "        ejemplo = {\n",
    "            'ventana': ventana,\n",
    "            'tipo': 'alta_precision',\n",
    "            'indice_dataset': indices_test[idx],\n",
    "            'prediccion': y_pred_np[idx],\n",
    "            'real': y_true_np[idx],\n",
    "            'error': errores[idx]\n",
    "        }\n",
    "        ejemplos_predicciones.append(ejemplo)\n",
    "    \n",
    "    for idx in indices_error[:3]:\n",
    "        ejemplo = {\n",
    "            'ventana': ventana,\n",
    "            'tipo': 'error_significativo',\n",
    "            'indice_dataset': indices_test[idx],\n",
    "            'prediccion': y_pred_np[idx],\n",
    "            'real': y_true_np[idx],\n",
    "            'error': errores[idx]\n",
    "        }\n",
    "        ejemplos_predicciones.append(ejemplo)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "total_partidos = len(actual_diferencias)\n",
    "num_previos = 50  \n",
    "input_size_actual = actual_diferencias.drop(columns=['probability_away', 'year_week_id']).shape[1]\n",
    "input_size_previos = previos.shape[1]\n",
    "\n",
    "df_visualization_global = pd.DataFrame({\n",
    "    'Window': pd.Series(dtype='int'),        \n",
    "    'Epoch': pd.Series(dtype='int'),      \n",
    "    'TrainingLoss': pd.Series(dtype='float'), \n",
    "    'ValidationLoss': pd.Series(dtype='float'),\n",
    "    'MAE': pd.Series(dtype='float'),\n",
    "    'MSE': pd.Series(dtype='float'), \n",
    "    'RMSE': pd.Series(dtype='float'),\n",
    "    'R2': pd.Series(dtype='float'),\n",
    "    'MAPE': pd.Series(dtype='float'),\n",
    "})\n",
    "\n",
    "# Inicialización del modelo\n",
    "model = TennisRNN(\n",
    "    input_size_actual=input_size_actual,\n",
    "    input_size_previos=input_size_previos,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    output_size=1,\n",
    "    dropout_rate=0.2,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Inicializar el estado del modelo para la primera ventana\n",
    "# Parámetros para early stopping\n",
    "previous_best_model_state = None\n",
    "patience = 5  # Número de épocas a esperar antes de detener el entrenamiento si no hay mejora\n",
    "min_delta = 0.00001  # Mejora mínima requerida para considerar que hay progreso\n",
    "\n",
    "# Parámetros de entrenamiento\n",
    "epochs = 100\n",
    "view_step = 5\n",
    "\n",
    "training_weeks = 10  # Número de semanas para entrenamiento\n",
    "testing_weeks = 3    # Número de semanas para prueba\n",
    "step_size = 1        # Paso de avance entre ventanas (en semanas)\n",
    "all_year_weeks = actual_diferencias['year_week_id'].unique()\n",
    "\n",
    "total_windows = (len(all_year_weeks) - (training_weeks + testing_weeks)) // step_size + 1\n",
    "# Bucle de entrenamiento con ventanas de tiempo\n",
    "for i in range(0, len(all_year_weeks) - (training_weeks + testing_weeks) + 1, step_size):\n",
    "    # Índice de la ventana actual (comenzando desde 1)\n",
    "    current_window = i // step_size + 1\n",
    "    print(f\"Ventana {current_window} de {total_windows}\")\n",
    "\n",
    "    # Semanas para entrenamiento y prueba\n",
    "    train_year_weeks = all_year_weeks[i:i+training_weeks]\n",
    "    test_year_weeks = all_year_weeks[i+training_weeks:i+training_weeks+testing_weeks]\n",
    "   \n",
    "    train_indices = actual_diferencias[actual_diferencias['year_week_id'].isin(train_year_weeks)].index\n",
    "    test_indices = actual_diferencias[actual_diferencias['year_week_id'].isin(test_year_weeks)].index\n",
    "    \n",
    "    print(f\"Entrenando con semanas: {train_year_weeks}, testeando en semanas {test_year_weeks}, len train: {len(train_indices)}, len test: {len(test_indices)}, porcentaje: {len(train_indices)/(len(train_indices)+len(test_indices)):.2f}\")\n",
    "\n",
    "    # Comprobar si hay suficientes datos\n",
    "    if len(train_indices) < 50 or len(test_indices) < 10:\n",
    "        print(f\"Saltando ventana {current_window} por datos insuficientes: train={len(train_indices)}, test={len(test_indices)}\")\n",
    "        continue\n",
    "    \n",
    "    # Preparar los datos de entrenamiento y test\n",
    "    X_train_actual = actual_diferencias.iloc[train_indices].drop(columns=['probability_away', 'year_week_id'])\n",
    "    Y_train_actual = actual_diferencias.iloc[train_indices]['probability_away'].values.reshape(-1, 1)\n",
    "    \n",
    "    X_test_actual = actual_diferencias.iloc[test_indices].drop(columns=['probability_away', 'year_week_id'])\n",
    "    Y_test_actual = actual_diferencias.iloc[test_indices]['probability_away'].values.reshape(-1, 1)\n",
    "    \n",
    "    previos_train_index= []\n",
    "    for idx in train_indices:\n",
    "        inicio = idx * num_previos\n",
    "        fin = inicio + num_previos \n",
    "        previos_train_index.extend(range(inicio, fin))\n",
    "    \n",
    "    previos_test_index= []\n",
    "    for idx in test_indices:\n",
    "        inicio = idx * num_previos\n",
    "        fin = inicio + num_previos  \n",
    "        previos_test_index.extend(range(inicio, fin))\n",
    "    \n",
    "    previos_train_home = previos_home.iloc[previos_train_index].values\n",
    "    previos_train_away = previos_away.iloc[previos_train_index].values\n",
    "    previos_test_home = previos_home.iloc[previos_test_index].values\n",
    "    previos_test_away = previos_away.iloc[previos_test_index].values\n",
    "\n",
    "    # Reshape para GRU: (n_samples, seq_length, n_features)\n",
    "    n_train_samples= len(train_indices)\n",
    "    n_test_samples= len(test_indices)\n",
    "    seq_length = num_previos\n",
    "    n_features = input_size_previos\n",
    "\n",
    "    X_train_previos_home = previos_train_home.reshape(n_train_samples, seq_length, n_features)\n",
    "    X_train_previos_away = previos_train_away.reshape(n_train_samples, seq_length, n_features)\n",
    "    X_test_previos_home = previos_test_home.reshape(n_test_samples, seq_length, n_features)\n",
    "    X_test_previos_away = previos_test_away.reshape(n_test_samples, seq_length, n_features)\n",
    "\n",
    "    # Convertir a tensores\n",
    "    tensor_X_train_actual = torch.tensor(X_train_actual.values, dtype=torch.float32).to(device)\n",
    "    tensor_Y_train_actual = torch.tensor(Y_train_actual, dtype=torch.float32).to(device)\n",
    "    tensor_X_test_actual = torch.tensor(X_test_actual.values, dtype=torch.float32).to(device)\n",
    "    tensor_Y_test_actual = torch.tensor(Y_test_actual, dtype=torch.float32).to(device)\n",
    "\n",
    "    tensor_X_train_previos_home = torch.tensor(X_train_previos_home, dtype=torch.float32).to(device)\n",
    "    tensor_X_train_previos_away = torch.tensor(X_train_previos_away, dtype=torch.float32).to(device)\n",
    "    tensor_X_test_previos_home = torch.tensor(X_test_previos_home, dtype=torch.float32).to(device)\n",
    "    tensor_X_test_previos_away = torch.tensor(X_test_previos_away, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_predictions = None\n",
    "    best_true_values = None\n",
    "    patience_counter = 0\n",
    "    epoca_mejor = 0\n",
    "\n",
    "    # Aplicar warm-up si no es la primera ventana\n",
    "    if i > 0 and previous_best_model_state is not None:\n",
    "        model.load_state_dict(previous_best_model_state)\n",
    "        print(f\"Iniciando ventana {current_window} con pesos de la ventana anterior\")\n",
    "    \n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(tensor_X_train_actual, tensor_X_train_previos_home, tensor_X_train_previos_away)\n",
    "        loss = criterion(y_pred, tensor_Y_train_actual)\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_test_pred = model(tensor_X_test_actual, tensor_X_test_previos_home, tensor_X_test_previos_away)\n",
    "            test_loss = criterion(y_test_pred, tensor_Y_test_actual).item()\n",
    "\n",
    "            # Calcular métricas de clasificación\n",
    "            metrics = calculate_metrics(y_test_pred, tensor_Y_test_actual)\n",
    "\n",
    "            # Guardar ejemplos de predicción\n",
    "            if epoch == 0 or (best_val_loss - test_loss > min_delta):\n",
    "                guardar_ejemplos_prediccion(y_test_pred, tensor_Y_test_actual, test_indices, current_window)\n",
    "            # Early stopping\n",
    "            if best_val_loss - test_loss > min_delta:\n",
    "                best_val_loss = test_loss\n",
    "                # Guardar el estado del modelo\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                patience_counter = 0\n",
    "                epoca_mejor = epoch\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Ventana {current_window}, Época: {epoch}, Train Loss: {train_loss:.8f}, Test Loss: {test_loss:.8f}, R2: {metrics[\"r2\"]:.4f}, MAE: {metrics[\"mae\"]:.4f}')\n",
    "                # Guardar información para visualización\n",
    "                new_row = pd.DataFrame({\n",
    "                    'Window': [current_window],\n",
    "                    'Epoch': [epoch],\n",
    "                    'TrainingLoss': [train_loss],\n",
    "                    'ValidationLoss': [test_loss],\n",
    "                    'MAE': [metrics[\"mae\"]],\n",
    "                    'MSE': [metrics[\"mse\"]],\n",
    "                    'RMSE': [metrics[\"rmse\"]],\n",
    "                    'R2': [metrics[\"r2\"]],\n",
    "                    'MAPE': [metrics[\"mape\"]],\n",
    "                })\n",
    "                df_visualization_global = pd.concat([df_visualization_global, new_row], ignore_index=True)\n",
    "                print(f\"Early stopping en la ventana {current_window}, época {epoch}\")\n",
    "                break\n",
    "                \n",
    "\n",
    "        if epoch % view_step == 0:\n",
    "            print(f'Ventana {current_window}, Época: {epoch}, Train Loss: {train_loss:.8f}, Test Loss: {test_loss:.8f},R2: {metrics[\"r2\"]:.4f}, MAE: {metrics[\"mae\"]:.4f}')\n",
    "            \n",
    "\n",
    "\n",
    "        # Guardar información para visualización\n",
    "        new_row = pd.DataFrame({\n",
    "                    'Window': [current_window],\n",
    "                    'Epoch': [epoch],\n",
    "                    'TrainingLoss': [train_loss],\n",
    "                    'ValidationLoss': [test_loss],\n",
    "                    'MAE': [metrics[\"mae\"]],\n",
    "                    'MSE': [metrics[\"mse\"]],\n",
    "                    'RMSE': [metrics[\"rmse\"]],\n",
    "                    'R2': [metrics[\"r2\"]],\n",
    "                    'MAPE': [metrics[\"mape\"]],\n",
    "        })\n",
    "\n",
    "        df_visualization_global = pd.concat([df_visualization_global, new_row], ignore_index=True)\n",
    "       \n",
    "    # Cargar el mejor modelo\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)  # Cargar el mejor modelo de esta ventana\n",
    "        previous_best_model_state = copy.deepcopy(best_model_state)  # Guardar para la siguiente ventana\n",
    "        print(f\"Mejor modelo guardado en la época  {epoca_mejor} para la ventana {current_window}\")\n",
    "\n",
    "    print(\"-------------------\") \n",
    "\n",
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'tennis_rnn_model_REGRESSION.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f391671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ejemplos = pd.DataFrame(ejemplos_predicciones)\n",
    "df_ejemplos.to_csv('ejemplos_predicciones_regresion.csv', index=False)\n",
    "df_visualization_global.to_csv('resultados/df_visualization_global_REGRESSION.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb19ba1",
   "metadata": {},
   "source": [
    "# RED NEURONAL PARA PREDEICR EL WINNERCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27a5bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f65915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689409f0",
   "metadata": {},
   "source": [
    "Actual con diferencias, previo no, para hacer dos gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69ec7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_diferencias=pd.read_csv('../data/actual_diferencias_preproc_escalado.csv')\n",
    "actual_diferencias=actual_diferencias.drop(columns=['probability_home', 'probability_away', 'vigorish'])\n",
    "previos=pd.read_csv('../data/previos_preproc_escalado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "649d7557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9259, 16) (925900, 33)\n"
     ]
    }
   ],
   "source": [
    "print(actual_diferencias.shape, previos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "958e8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(previos.shape[0]/actual_diferencias.shape[0])\n",
    "num_previos=int(previos.shape[0]/actual_diferencias.shape[0])\n",
    "print(num_previos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3da548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winnerCode</th>\n",
       "      <th>porcentajeActualRanking</th>\n",
       "      <th>porcentajeBestRanking</th>\n",
       "      <th>difHeight</th>\n",
       "      <th>difWeight</th>\n",
       "      <th>groundType_Grass</th>\n",
       "      <th>groundType_Hardcourt_indoor</th>\n",
       "      <th>groundType_Hardcourt_outdoor</th>\n",
       "      <th>groundType_Red_clay</th>\n",
       "      <th>difLaterality_00</th>\n",
       "      <th>difLaterality_01</th>\n",
       "      <th>difLaterality_10</th>\n",
       "      <th>difLaterality_11</th>\n",
       "      <th>best_five</th>\n",
       "      <th>difYear</th>\n",
       "      <th>year_week_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.096934</td>\n",
       "      <td>-0.520517</td>\n",
       "      <td>-1.044343</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.859275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>-0.246956</td>\n",
       "      <td>0.738353</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.943432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.087356</td>\n",
       "      <td>0.639723</td>\n",
       "      <td>0.528624</td>\n",
       "      <td>0.561874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.198134</td>\n",
       "      <td>1.104192</td>\n",
       "      <td>-0.205428</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.153211</td>\n",
       "      <td>-0.777271</td>\n",
       "      <td>0.528624</td>\n",
       "      <td>1.006422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.290819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winnerCode  porcentajeActualRanking  porcentajeBestRanking  difHeight  \\\n",
       "0           1                -0.096934              -0.520517  -1.044343   \n",
       "1           0                 0.177778              -0.246956   0.738353   \n",
       "2           1                -0.087356               0.639723   0.528624   \n",
       "3           0                 0.198134               1.104192  -0.205428   \n",
       "4           0                -0.153211              -0.777271   0.528624   \n",
       "\n",
       "   difWeight  groundType_Grass  groundType_Hardcourt_indoor  \\\n",
       "0   0.228463                 0                            0   \n",
       "1   0.228463                 0                            0   \n",
       "2   0.561874                 0                            0   \n",
       "3   0.228463                 0                            0   \n",
       "4   1.006422                 0                            0   \n",
       "\n",
       "   groundType_Hardcourt_outdoor  groundType_Red_clay  difLaterality_00  \\\n",
       "0                             1                    0                 0   \n",
       "1                             1                    0                 0   \n",
       "2                             1                    0                 0   \n",
       "3                             1                    0                 0   \n",
       "4                             1                    0                 0   \n",
       "\n",
       "   difLaterality_01  difLaterality_10  difLaterality_11  best_five   difYear  \\\n",
       "0                 0                 1                 0          0  0.859275   \n",
       "1                 0                 0                 1          0 -0.943432   \n",
       "2                 0                 0                 1          0  0.801265   \n",
       "3                 0                 0                 1          0  0.091960   \n",
       "4                 0                 0                 1          0 -0.290819   \n",
       "\n",
       "   year_week_id  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_diferencias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bb56b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winnerCode</th>\n",
       "      <th>ActualRankingHome</th>\n",
       "      <th>BestRankingHome</th>\n",
       "      <th>HeightHome</th>\n",
       "      <th>WeightHome</th>\n",
       "      <th>RightHandedHome</th>\n",
       "      <th>ActualRankingAway</th>\n",
       "      <th>BestRankingAway</th>\n",
       "      <th>HeightAway</th>\n",
       "      <th>WeightAway</th>\n",
       "      <th>RightHandedAway</th>\n",
       "      <th>homeScore</th>\n",
       "      <th>awayScore</th>\n",
       "      <th>set1performanceHome</th>\n",
       "      <th>set1performanceAway</th>\n",
       "      <th>set2performanceHome</th>\n",
       "      <th>set2performanceAway</th>\n",
       "      <th>set3performanceHome</th>\n",
       "      <th>set3performanceAway</th>\n",
       "      <th>set4performanceHome</th>\n",
       "      <th>set4performanceAway</th>\n",
       "      <th>set5performanceHome</th>\n",
       "      <th>set5performanceAway</th>\n",
       "      <th>totalGamesHome</th>\n",
       "      <th>totalGamesAway</th>\n",
       "      <th>days_no_played</th>\n",
       "      <th>best_five</th>\n",
       "      <th>edad_home</th>\n",
       "      <th>edad_away</th>\n",
       "      <th>groundType_Grass</th>\n",
       "      <th>groundType_Hardcourt_indoor</th>\n",
       "      <th>groundType_Hardcourt_outdoor</th>\n",
       "      <th>groundType_Red_clay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>-1.264435</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.574444</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>-0.248839</td>\n",
       "      <td>1.110974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.049115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661493</td>\n",
       "      <td>1.198959</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>-1.264435</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724444</td>\n",
       "      <td>0.775556</td>\n",
       "      <td>-0.540683</td>\n",
       "      <td>-0.289252</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>0</td>\n",
       "      <td>0.665848</td>\n",
       "      <td>-0.414577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>-1.264435</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645556</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>-1.270293</td>\n",
       "      <td>-0.133672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.201117</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670825</td>\n",
       "      <td>0.899011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>-1.264435</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>-0.978449</td>\n",
       "      <td>-1.067156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.277993</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671447</td>\n",
       "      <td>-1.319369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>-1.264435</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.635556</td>\n",
       "      <td>-1.270293</td>\n",
       "      <td>-0.289252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.141105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673935</td>\n",
       "      <td>0.228611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winnerCode  ActualRankingHome  BestRankingHome  HeightHome  WeightHome  \\\n",
       "0           1           0.817778         0.876667   -1.264435    0.031102   \n",
       "1           1           0.821111         0.876667   -1.264435    0.031102   \n",
       "2           0           0.821111         0.876667   -1.264435    0.031102   \n",
       "3           1           0.821111         0.876667   -1.264435    0.031102   \n",
       "4           0           0.821111         0.876667   -1.264435    0.031102   \n",
       "\n",
       "   RightHandedHome  ActualRankingAway  BestRankingAway  HeightAway  \\\n",
       "0                1           0.574444         0.946667   -0.248839   \n",
       "1                1           0.724444         0.775556   -0.540683   \n",
       "2                1           0.645556         0.688889   -1.270293   \n",
       "3                1           0.557778         0.695556   -0.978449   \n",
       "4                1           0.504444         0.635556   -1.270293   \n",
       "\n",
       "   WeightAway  RightHandedAway  homeScore  awayScore  set1performanceHome  \\\n",
       "0    1.110974                1   0.666667   0.000000                  0.6   \n",
       "1   -0.289252                1   0.666667   0.333333                  0.7   \n",
       "2   -0.133672                0   0.666667   0.000000                  0.7   \n",
       "3   -1.067156                0   0.000000   0.666667                  0.2   \n",
       "4   -0.289252                0   0.666667   0.000000                  0.7   \n",
       "\n",
       "   set1performanceAway  set2performanceHome  set2performanceAway  \\\n",
       "0                  0.7                  0.5                  0.7   \n",
       "1                  0.5                  0.5                  0.7   \n",
       "2                  0.6                  0.6                  0.4   \n",
       "3                  0.6                  0.4                  0.6   \n",
       "4                  0.5                  0.7                  0.5   \n",
       "\n",
       "   set3performanceHome  set3performanceAway  set4performanceHome  \\\n",
       "0                 0.00             0.000000                  0.0   \n",
       "1                 0.25             0.428571                  0.0   \n",
       "2                 0.00             0.000000                  0.0   \n",
       "3                 0.00             0.000000                  0.0   \n",
       "4                 0.00             0.000000                  0.0   \n",
       "\n",
       "   set4performanceAway  set5performanceHome  set5performanceAway  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   totalGamesHome  totalGamesAway  days_no_played  best_five  edad_home  \\\n",
       "0           0.275            0.35        2.049115          1   0.661493   \n",
       "1           0.400            0.45        0.064228          0   0.665848   \n",
       "2           0.325            0.25        0.201117          0   0.670825   \n",
       "3           0.150            0.30       -0.277993          0   0.671447   \n",
       "4           0.350            0.25       -0.141105          0   0.673935   \n",
       "\n",
       "   edad_away  groundType_Grass  groundType_Hardcourt_indoor  \\\n",
       "0   1.198959                 1                            0   \n",
       "1  -0.414577                 0                            0   \n",
       "2   0.899011                 0                            0   \n",
       "3  -1.319369                 0                            0   \n",
       "4   0.228611                 0                            0   \n",
       "\n",
       "   groundType_Hardcourt_outdoor  groundType_Red_clay  \n",
       "0                             0                    0  \n",
       "1                             0                    1  \n",
       "2                             0                    1  \n",
       "3                             0                    1  \n",
       "4                             0                    1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a6bca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9259\n",
      "(9259, 16) (462950, 33) (462950, 33)\n"
     ]
    }
   ],
   "source": [
    "num_filas = len(previos)\n",
    "tamano_bloque=int(num_previos/2)\n",
    "# Crear listas para almacenar los índices\n",
    "indices_home = []\n",
    "indices_away = []\n",
    "\n",
    "# Para cada bloque, extraer los índices correspondientes\n",
    "print(actual_diferencias.shape[0])\n",
    "for i in range(actual_diferencias.shape[0]):\n",
    "    inicio_bloque = i * tamano_bloque * 2\n",
    "    \n",
    "    # Índices para home (primeras 50 filas del bloque)\n",
    "    indices_home.extend(range(inicio_bloque, inicio_bloque + tamano_bloque))\n",
    "    \n",
    "    # Índices para away (siguientes 50 filas del bloque)\n",
    "    indices_away.extend(range(inicio_bloque + tamano_bloque, inicio_bloque + tamano_bloque * 2))\n",
    "    \n",
    "# Crear DataFrames usando los índices\n",
    "previos_home = previos.iloc[indices_home].reset_index(drop=True)\n",
    "previos_away = previos.iloc[indices_away].reset_index(drop=True)\n",
    "actual_diferencias=actual_diferencias.reset_index(drop=True)\n",
    "print(actual_diferencias.shape, previos_home.shape, previos_away.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c885f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventana 1 de 153\n",
      "Entrenando con semanas: [0 1 2 3 4 5 6 7 8 9], testeando en semanas [10 11 12], len train: 509, len test: 141, porcentaje: 0.78\n",
      "Ventana 1, Época: 0, Train Loss: 0.69356155, Test Loss: 0.69248962, AUC: 0.5636, Accuracy: 0.5035\n",
      "Ventana 1, Época: 5, Train Loss: 0.68079734, Test Loss: 0.68827677, AUC: 0.5674, Accuracy: 0.5319\n",
      "Ventana 1, Época: 10, Train Loss: 0.66094965, Test Loss: 0.68290997, AUC: 0.5803, Accuracy: 0.5603\n",
      "Ventana 1, Época: 15, Train Loss: 0.64043218, Test Loss: 0.68838543, AUC: 0.5839, Accuracy: 0.5674\n",
      "Ventana 1, Época: 16, Train Loss: 0.63180083, Test Loss: 0.68885678, AUC: 0.5861, Accuracy: 0.5674\n",
      "Early stopping en la ventana 1, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 1\n",
      "-------------------\n",
      "Ventana 2 de 153\n",
      "Entrenando con semanas: [ 1  2  3  4  5  6  7  8  9 10], testeando en semanas [11 12 13], len train: 501, len test: 143, porcentaje: 0.78\n",
      "Iniciando ventana 2 con pesos de la ventana anterior\n",
      "Ventana 2, Época: 0, Train Loss: 0.65462482, Test Loss: 0.68732291, AUC: 0.5685, Accuracy: 0.5455\n",
      "Ventana 2, Época: 5, Train Loss: 0.62950891, Test Loss: 0.69353569, AUC: 0.5705, Accuracy: 0.5455\n",
      "Early stopping en la ventana 2, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 2\n",
      "-------------------\n",
      "Ventana 3 de 153\n",
      "Entrenando con semanas: [ 2  3  4  5  6  7  8  9 10 11], testeando en semanas [12 13 14], len train: 500, len test: 148, porcentaje: 0.77\n",
      "Iniciando ventana 3 con pesos de la ventana anterior\n",
      "Ventana 3, Época: 0, Train Loss: 0.65573812, Test Loss: 0.67971450, AUC: 0.5910, Accuracy: 0.5608\n",
      "Ventana 3, Época: 5, Train Loss: 0.62603664, Test Loss: 0.69395387, AUC: 0.5804, Accuracy: 0.5608\n",
      "Early stopping en la ventana 3, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 3\n",
      "-------------------\n",
      "Ventana 4 de 153\n",
      "Entrenando con semanas: [ 3  4  5  6  7  8  9 10 11 12], testeando en semanas [13 14 15], len train: 434, len test: 151, porcentaje: 0.74\n",
      "Iniciando ventana 4 con pesos de la ventana anterior\n",
      "Ventana 4, Época: 0, Train Loss: 0.64828682, Test Loss: 0.68662608, AUC: 0.5814, Accuracy: 0.5430\n",
      "Ventana 4, Época: 5, Train Loss: 0.62066859, Test Loss: 0.70098704, AUC: 0.5702, Accuracy: 0.5497\n",
      "Early stopping en la ventana 4, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 4\n",
      "-------------------\n",
      "Ventana 5 de 153\n",
      "Entrenando con semanas: [ 4  5  6  7  8  9 10 11 12 13], testeando en semanas [14 15 16], len train: 449, len test: 249, porcentaje: 0.64\n",
      "Iniciando ventana 5 con pesos de la ventana anterior\n",
      "Ventana 5, Época: 0, Train Loss: 0.65326750, Test Loss: 0.67057717, AUC: 0.6208, Accuracy: 0.5863\n",
      "Ventana 5, Época: 5, Train Loss: 0.62212998, Test Loss: 0.66636920, AUC: 0.6317, Accuracy: 0.6104\n",
      "Ventana 5, Época: 10, Train Loss: 0.60441279, Test Loss: 0.66049343, AUC: 0.6579, Accuracy: 0.6104\n",
      "Ventana 5, Época: 15, Train Loss: 0.56863773, Test Loss: 0.70624387, AUC: 0.6465, Accuracy: 0.6024\n",
      "Early stopping en la ventana 5, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 5\n",
      "-------------------\n",
      "Ventana 6 de 153\n",
      "Entrenando con semanas: [ 5  6  7  8  9 10 11 12 13 14], testeando en semanas [15 16 17], len train: 514, len test: 267, porcentaje: 0.66\n",
      "Iniciando ventana 6 con pesos de la ventana anterior\n",
      "Ventana 6, Época: 0, Train Loss: 0.61521310, Test Loss: 0.67170709, AUC: 0.6874, Accuracy: 0.6105\n",
      "Ventana 6, Época: 5, Train Loss: 0.58518028, Test Loss: 0.68169045, AUC: 0.6896, Accuracy: 0.5993\n",
      "Ventana 6, Época: 10, Train Loss: 0.56906140, Test Loss: 0.65566874, AUC: 0.6967, Accuracy: 0.6217\n",
      "Ventana 6, Época: 12, Train Loss: 0.55781454, Test Loss: 0.70129853, AUC: 0.6710, Accuracy: 0.5918\n",
      "Early stopping en la ventana 6, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 6\n",
      "-------------------\n",
      "Ventana 7 de 153\n",
      "Entrenando con semanas: [ 6  7  8  9 10 11 12 13 14 15], testeando en semanas [16 17 18], len train: 534, len test: 256, porcentaje: 0.68\n",
      "Iniciando ventana 7 con pesos de la ventana anterior\n",
      "Ventana 7, Época: 0, Train Loss: 0.58838046, Test Loss: 0.68108618, AUC: 0.6943, Accuracy: 0.6055\n",
      "Ventana 7, Época: 5, Train Loss: 0.55890387, Test Loss: 0.69185817, AUC: 0.6950, Accuracy: 0.5977\n",
      "Ventana 7, Época: 8, Train Loss: 0.56034023, Test Loss: 0.67248023, AUC: 0.7051, Accuracy: 0.6133\n",
      "Early stopping en la ventana 7, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 7\n",
      "-------------------\n",
      "Ventana 8 de 153\n",
      "Entrenando con semanas: [ 7  8  9 10 11 12 13 14 15 16], testeando en semanas [17 18 19], len train: 620, len test: 194, porcentaje: 0.76\n",
      "Iniciando ventana 8 con pesos de la ventana anterior\n",
      "Ventana 8, Época: 0, Train Loss: 0.59228969, Test Loss: 0.69408524, AUC: 0.7027, Accuracy: 0.5464\n",
      "Ventana 8, Época: 5, Train Loss: 0.57915199, Test Loss: 0.65581757, AUC: 0.7161, Accuracy: 0.6237\n",
      "Ventana 8, Época: 10, Train Loss: 0.56541944, Test Loss: 0.62363905, AUC: 0.7307, Accuracy: 0.6649\n",
      "Ventana 8, Época: 15, Train Loss: 0.54475719, Test Loss: 0.61702061, AUC: 0.7425, Accuracy: 0.6495\n",
      "Ventana 8, Época: 19, Train Loss: 0.52022117, Test Loss: 0.61527264, AUC: 0.7424, Accuracy: 0.6701\n",
      "Early stopping en la ventana 8, época 19\n",
      "Mejor modelo guardado en la época  14 para la ventana 8\n",
      "-------------------\n",
      "Ventana 9 de 153\n",
      "Entrenando con semanas: [ 8  9 10 11 12 13 14 15 16 17], testeando en semanas [18 19 20], len train: 638, len test: 204, porcentaje: 0.76\n",
      "Iniciando ventana 9 con pesos de la ventana anterior\n",
      "Ventana 9, Época: 0, Train Loss: 0.56390160, Test Loss: 0.62964338, AUC: 0.7145, Accuracy: 0.6275\n",
      "Ventana 9, Época: 5, Train Loss: 0.52921891, Test Loss: 0.64496535, AUC: 0.7144, Accuracy: 0.6324\n",
      "Ventana 9, Época: 9, Train Loss: 0.50962913, Test Loss: 0.65539235, AUC: 0.7111, Accuracy: 0.6422\n",
      "Early stopping en la ventana 9, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 9\n",
      "-------------------\n",
      "Ventana 10 de 153\n",
      "Entrenando con semanas: [ 9 10 11 12 13 14 15 16 17 18], testeando en semanas [19 20 21], len train: 573, len test: 273, porcentaje: 0.68\n",
      "Iniciando ventana 10 con pesos de la ventana anterior\n",
      "Ventana 10, Época: 0, Train Loss: 0.54584187, Test Loss: 0.65567815, AUC: 0.7019, Accuracy: 0.6337\n",
      "Ventana 10, Época: 5, Train Loss: 0.50540769, Test Loss: 0.65315652, AUC: 0.6970, Accuracy: 0.6447\n",
      "Ventana 10, Época: 7, Train Loss: 0.49861839, Test Loss: 0.67345291, AUC: 0.7009, Accuracy: 0.6410\n",
      "Early stopping en la ventana 10, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 10\n",
      "-------------------\n",
      "Ventana 11 de 153\n",
      "Entrenando con semanas: [10 11 12 13 14 15 16 17 18 19], testeando en semanas [20 21 22], len train: 609, len test: 244, porcentaje: 0.71\n",
      "Iniciando ventana 11 con pesos de la ventana anterior\n",
      "Ventana 11, Época: 0, Train Loss: 0.54337513, Test Loss: 0.62861484, AUC: 0.7134, Accuracy: 0.6721\n",
      "Ventana 11, Época: 5, Train Loss: 0.50418955, Test Loss: 0.65700001, AUC: 0.7124, Accuracy: 0.6598\n",
      "Early stopping en la ventana 11, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 11\n",
      "-------------------\n",
      "Ventana 12 de 153\n",
      "Entrenando con semanas: [11 12 13 14 15 16 17 18 19 20], testeando en semanas [21 22 23], len train: 690, len test: 166, porcentaje: 0.81\n",
      "Iniciando ventana 12 con pesos de la ventana anterior\n",
      "Ventana 12, Época: 0, Train Loss: 0.54768384, Test Loss: 0.68013030, AUC: 0.6868, Accuracy: 0.6687\n",
      "Ventana 12, Época: 5, Train Loss: 0.51618057, Test Loss: 0.72273654, AUC: 0.6864, Accuracy: 0.6386\n",
      "Ventana 12, Época: 7, Train Loss: 0.52049923, Test Loss: 0.71185559, AUC: 0.6964, Accuracy: 0.6446\n",
      "Early stopping en la ventana 12, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 12\n",
      "-------------------\n",
      "Ventana 13 de 153\n",
      "Entrenando con semanas: [12 13 14 15 16 17 18 19 20 21], testeando en semanas [22 23 24], len train: 727, len test: 75, porcentaje: 0.91\n",
      "Iniciando ventana 13 con pesos de la ventana anterior\n",
      "Ventana 13, Época: 0, Train Loss: 0.55947834, Test Loss: 0.76342583, AUC: 0.6265, Accuracy: 0.6400\n",
      "Ventana 13, Época: 5, Train Loss: 0.53314090, Test Loss: 0.75107056, AUC: 0.6221, Accuracy: 0.6400\n",
      "Ventana 13, Época: 7, Train Loss: 0.52251863, Test Loss: 0.72131044, AUC: 0.6403, Accuracy: 0.5867\n",
      "Early stopping en la ventana 13, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 13\n",
      "-------------------\n",
      "Ventana 14 de 153\n",
      "Entrenando con semanas: [13 14 15 16 17 18 19 20 21 22], testeando en semanas [23 24 25], len train: 712, len test: 107, porcentaje: 0.87\n",
      "Iniciando ventana 14 con pesos de la ventana anterior\n",
      "Ventana 14, Época: 0, Train Loss: 0.54528725, Test Loss: 0.95518422, AUC: 0.5088, Accuracy: 0.4860\n",
      "Ventana 14, Época: 5, Train Loss: 0.52209508, Test Loss: 0.92924923, AUC: 0.5364, Accuracy: 0.5140\n",
      "Ventana 14, Época: 8, Train Loss: 0.51237071, Test Loss: 0.91358626, AUC: 0.5526, Accuracy: 0.5421\n",
      "Early stopping en la ventana 14, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 14\n",
      "-------------------\n",
      "Ventana 15 de 153\n",
      "Entrenando con semanas: [14 15 16 17 18 19 20 21 22 23], testeando en semanas [24 25 26], len train: 713, len test: 149, porcentaje: 0.83\n",
      "Iniciando ventana 15 con pesos de la ventana anterior\n",
      "Ventana 15, Época: 0, Train Loss: 0.53736454, Test Loss: 0.86632115, AUC: 0.5620, Accuracy: 0.5436\n",
      "Ventana 15, Época: 5, Train Loss: 0.52025211, Test Loss: 0.84989733, AUC: 0.5735, Accuracy: 0.5570\n",
      "Ventana 15, Época: 10, Train Loss: 0.49672797, Test Loss: 0.82087076, AUC: 0.5856, Accuracy: 0.5570\n",
      "Ventana 15, Época: 15, Train Loss: 0.46931148, Test Loss: 0.88646930, AUC: 0.5843, Accuracy: 0.5503\n",
      "Early stopping en la ventana 15, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 15\n",
      "-------------------\n",
      "Ventana 16 de 153\n",
      "Entrenando con semanas: [15 16 17 18 19 20 21 22 23 24], testeando en semanas [25 26 27], len train: 654, len test: 186, porcentaje: 0.78\n",
      "Iniciando ventana 16 con pesos de la ventana anterior\n",
      "Ventana 16, Época: 0, Train Loss: 0.50473583, Test Loss: 0.82071269, AUC: 0.6173, Accuracy: 0.6022\n",
      "Ventana 16, Época: 5, Train Loss: 0.47722274, Test Loss: 0.81728345, AUC: 0.6294, Accuracy: 0.5860\n",
      "Ventana 16, Época: 7, Train Loss: 0.46570742, Test Loss: 0.82731652, AUC: 0.6321, Accuracy: 0.5914\n",
      "Early stopping en la ventana 16, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 16\n",
      "-------------------\n",
      "Ventana 17 de 153\n",
      "Entrenando con semanas: [16 17 18 19 20 21 22 23 24 25], testeando en semanas [26 27 28], len train: 668, len test: 225, porcentaje: 0.75\n",
      "Iniciando ventana 17 con pesos de la ventana anterior\n",
      "Ventana 17, Época: 0, Train Loss: 0.52933401, Test Loss: 0.78742653, AUC: 0.6456, Accuracy: 0.6000\n",
      "Ventana 17, Época: 5, Train Loss: 0.50409633, Test Loss: 0.75014013, AUC: 0.6404, Accuracy: 0.5822\n",
      "Ventana 17, Época: 10, Train Loss: 0.45930618, Test Loss: 0.76407361, AUC: 0.6373, Accuracy: 0.5778\n",
      "Early stopping en la ventana 17, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 17\n",
      "-------------------\n",
      "Ventana 18 de 153\n",
      "Entrenando con semanas: [17 18 19 20 21 22 23 24 25 26], testeando en semanas [27 28 29], len train: 613, len test: 267, porcentaje: 0.70\n",
      "Iniciando ventana 18 con pesos de la ventana anterior\n",
      "Ventana 18, Época: 0, Train Loss: 0.52480811, Test Loss: 0.69098663, AUC: 0.7089, Accuracy: 0.6255\n",
      "Ventana 18, Época: 5, Train Loss: 0.46575978, Test Loss: 0.71390045, AUC: 0.6859, Accuracy: 0.6180\n",
      "Ventana 18, Época: 6, Train Loss: 0.47672859, Test Loss: 0.70183080, AUC: 0.6947, Accuracy: 0.6030\n",
      "Early stopping en la ventana 18, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 18\n",
      "-------------------\n",
      "Ventana 19 de 153\n",
      "Entrenando con semanas: [18 19 20 21 22 23 24 25 26 27], testeando en semanas [28 29 30], len train: 573, len test: 224, porcentaje: 0.72\n",
      "Iniciando ventana 19 con pesos de la ventana anterior\n",
      "Ventana 19, Época: 0, Train Loss: 0.54143679, Test Loss: 0.69626135, AUC: 0.7221, Accuracy: 0.5982\n",
      "Ventana 19, Época: 5, Train Loss: 0.50319248, Test Loss: 0.67266399, AUC: 0.7079, Accuracy: 0.5982\n",
      "Ventana 19, Época: 10, Train Loss: 0.45850509, Test Loss: 0.70661670, AUC: 0.7018, Accuracy: 0.6205\n",
      "Ventana 19, Época: 11, Train Loss: 0.44425508, Test Loss: 0.71887654, AUC: 0.6988, Accuracy: 0.6027\n",
      "Early stopping en la ventana 19, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 19\n",
      "-------------------\n",
      "Ventana 20 de 153\n",
      "Entrenando con semanas: [19 20 21 22 23 24 25 26 27 28], testeando en semanas [29 30 31], len train: 637, len test: 212, porcentaje: 0.75\n",
      "Iniciando ventana 20 con pesos de la ventana anterior\n",
      "Ventana 20, Época: 0, Train Loss: 0.51102722, Test Loss: 0.65348113, AUC: 0.7196, Accuracy: 0.6651\n",
      "Ventana 20, Época: 5, Train Loss: 0.47028998, Test Loss: 0.67472172, AUC: 0.7282, Accuracy: 0.6792\n",
      "Early stopping en la ventana 20, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 20\n",
      "-------------------\n",
      "Ventana 21 de 153\n",
      "Entrenando con semanas: [20 21 22 23 24 25 26 27 28 29], testeando en semanas [30 31 32], len train: 686, len test: 136, porcentaje: 0.83\n",
      "Iniciando ventana 21 con pesos de la ventana anterior\n",
      "Ventana 21, Época: 0, Train Loss: 0.54153872, Test Loss: 0.70239675, AUC: 0.6656, Accuracy: 0.6250\n",
      "Ventana 21, Época: 5, Train Loss: 0.49590242, Test Loss: 0.72511065, AUC: 0.6517, Accuracy: 0.6324\n",
      "Ventana 21, Época: 6, Train Loss: 0.48417386, Test Loss: 0.73474264, AUC: 0.6494, Accuracy: 0.6397\n",
      "Early stopping en la ventana 21, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 21\n",
      "-------------------\n",
      "Ventana 22 de 153\n",
      "Entrenando con semanas: [21 22 23 24 25 26 27 28 29 30], testeando en semanas [31 32 33], len train: 593, len test: 137, porcentaje: 0.81\n",
      "Iniciando ventana 22 con pesos de la ventana anterior\n",
      "Ventana 22, Época: 0, Train Loss: 0.53855193, Test Loss: 0.71340257, AUC: 0.6650, Accuracy: 0.6569\n",
      "Ventana 22, Época: 5, Train Loss: 0.47387725, Test Loss: 0.74670047, AUC: 0.6522, Accuracy: 0.6058\n",
      "Early stopping en la ventana 22, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 22\n",
      "-------------------\n",
      "Ventana 23 de 153\n",
      "Entrenando con semanas: [22 23 24 25 26 27 28 29 30 31], testeando en semanas [32 33 34], len train: 576, len test: 96, porcentaje: 0.86\n",
      "Iniciando ventana 23 con pesos de la ventana anterior\n",
      "Ventana 23, Época: 0, Train Loss: 0.57903236, Test Loss: 0.83920223, AUC: 0.5688, Accuracy: 0.4792\n",
      "Ventana 23, Época: 5, Train Loss: 0.51143295, Test Loss: 0.86094642, AUC: 0.5384, Accuracy: 0.4688\n",
      "Ventana 23, Época: 7, Train Loss: 0.50525045, Test Loss: 0.84041375, AUC: 0.5158, Accuracy: 0.5104\n",
      "Early stopping en la ventana 23, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 23\n",
      "-------------------\n",
      "Ventana 24 de 153\n",
      "Entrenando con semanas: [23 24 25 26 27 28 29 30 31 32], testeando en semanas [33 34 35], len train: 578, len test: 116, porcentaje: 0.83\n",
      "Iniciando ventana 24 con pesos de la ventana anterior\n",
      "Ventana 24, Época: 0, Train Loss: 0.58004737, Test Loss: 0.73961711, AUC: 0.6259, Accuracy: 0.5690\n",
      "Ventana 24, Época: 5, Train Loss: 0.53263581, Test Loss: 0.74662632, AUC: 0.6197, Accuracy: 0.5345\n",
      "Ventana 24, Época: 10, Train Loss: 0.48941684, Test Loss: 0.77401245, AUC: 0.6173, Accuracy: 0.5345\n",
      "Ventana 24, Época: 13, Train Loss: 0.46762374, Test Loss: 0.80678922, AUC: 0.6042, Accuracy: 0.5345\n",
      "Early stopping en la ventana 24, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 24\n",
      "-------------------\n",
      "Ventana 25 de 153\n",
      "Entrenando con semanas: [24 25 26 27 28 29 30 31 32 33], testeando en semanas [34 35 36], len train: 564, len test: 106, porcentaje: 0.84\n",
      "Iniciando ventana 25 con pesos de la ventana anterior\n",
      "Ventana 25, Época: 0, Train Loss: 0.51148921, Test Loss: 0.81919968, AUC: 0.5753, Accuracy: 0.5094\n",
      "Ventana 25, Época: 5, Train Loss: 0.47793281, Test Loss: 0.80162442, AUC: 0.5910, Accuracy: 0.5377\n",
      "Ventana 25, Época: 8, Train Loss: 0.45087212, Test Loss: 0.85162944, AUC: 0.5870, Accuracy: 0.5377\n",
      "Early stopping en la ventana 25, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 25\n",
      "-------------------\n",
      "Ventana 26 de 153\n",
      "Entrenando con semanas: [25 26 27 28 29 30 31 32 33 34], testeando en semanas [35 36 37], len train: 597, len test: 69, porcentaje: 0.90\n",
      "Iniciando ventana 26 con pesos de la ventana anterior\n",
      "Ventana 26, Época: 0, Train Loss: 0.52080566, Test Loss: 0.84173787, AUC: 0.6579, Accuracy: 0.5362\n",
      "Ventana 26, Época: 5, Train Loss: 0.47734544, Test Loss: 0.74975002, AUC: 0.6579, Accuracy: 0.6087\n",
      "Ventana 26, Época: 8, Train Loss: 0.47098699, Test Loss: 0.69298679, AUC: 0.6630, Accuracy: 0.6087\n",
      "Early stopping en la ventana 26, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 26\n",
      "-------------------\n",
      "Ventana 27 de 153\n",
      "Entrenando con semanas: [26 27 28 29 30 31 32 33 34 35], testeando en semanas [36 37 38], len train: 587, len test: 20, porcentaje: 0.97\n",
      "Iniciando ventana 27 con pesos de la ventana anterior\n",
      "Ventana 27, Época: 0, Train Loss: 0.52021003, Test Loss: 0.93823910, AUC: 0.3846, Accuracy: 0.4500\n",
      "Ventana 27, Época: 5, Train Loss: 0.46525654, Test Loss: 1.06994820, AUC: 0.3626, Accuracy: 0.4500\n",
      "Early stopping en la ventana 27, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 27\n",
      "-------------------\n",
      "Ventana 28 de 153\n",
      "Entrenando con semanas: [27 28 29 30 31 32 33 34 35 36], testeando en semanas [37 38 39], len train: 521, len test: 117, porcentaje: 0.82\n",
      "Iniciando ventana 28 con pesos de la ventana anterior\n",
      "Ventana 28, Época: 0, Train Loss: 0.52615362, Test Loss: 0.72932774, AUC: 0.6464, Accuracy: 0.6410\n",
      "Ventana 28, Época: 5, Train Loss: 0.46856931, Test Loss: 0.72841692, AUC: 0.6446, Accuracy: 0.6154\n",
      "Ventana 28, Época: 6, Train Loss: 0.45469561, Test Loss: 0.72895026, AUC: 0.6420, Accuracy: 0.6239\n",
      "Early stopping en la ventana 28, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 28\n",
      "-------------------\n",
      "Ventana 29 de 153\n",
      "Entrenando con semanas: [28 29 30 31 32 33 34 35 36 37], testeando en semanas [38 39 40], len train: 480, len test: 218, porcentaje: 0.69\n",
      "Iniciando ventana 29 con pesos de la ventana anterior\n",
      "Ventana 29, Época: 0, Train Loss: 0.51127356, Test Loss: 0.64843684, AUC: 0.7167, Accuracy: 0.6789\n",
      "Ventana 29, Época: 5, Train Loss: 0.45010751, Test Loss: 0.65818340, AUC: 0.7259, Accuracy: 0.6789\n",
      "Ventana 29, Época: 6, Train Loss: 0.43613467, Test Loss: 0.66812617, AUC: 0.7189, Accuracy: 0.6789\n",
      "Early stopping en la ventana 29, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 29\n",
      "-------------------\n",
      "Ventana 30 de 153\n",
      "Entrenando con semanas: [29 30 31 32 33 34 35 36 37 38], testeando en semanas [39 40 41], len train: 382, len test: 224, porcentaje: 0.63\n",
      "Iniciando ventana 30 con pesos de la ventana anterior\n",
      "Ventana 30, Época: 0, Train Loss: 0.51299316, Test Loss: 0.66590363, AUC: 0.7102, Accuracy: 0.6875\n",
      "Ventana 30, Época: 5, Train Loss: 0.44342479, Test Loss: 0.69862783, AUC: 0.6994, Accuracy: 0.6518\n",
      "Ventana 30, Época: 7, Train Loss: 0.41898924, Test Loss: 0.70186538, AUC: 0.7067, Accuracy: 0.6429\n",
      "Early stopping en la ventana 30, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 30\n",
      "-------------------\n",
      "Ventana 31 de 153\n",
      "Entrenando con semanas: [30 31 32 33 34 35 36 37 38 39], testeando en semanas [40 41 42], len train: 371, len test: 137, porcentaje: 0.73\n",
      "Iniciando ventana 31 con pesos de la ventana anterior\n",
      "Ventana 31, Época: 0, Train Loss: 0.56585920, Test Loss: 0.72529775, AUC: 0.7501, Accuracy: 0.6496\n",
      "Ventana 31, Época: 5, Train Loss: 0.49010491, Test Loss: 0.72103381, AUC: 0.7274, Accuracy: 0.6131\n",
      "Ventana 31, Época: 8, Train Loss: 0.44646186, Test Loss: 0.75502747, AUC: 0.7222, Accuracy: 0.6350\n",
      "Early stopping en la ventana 31, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 31\n",
      "-------------------\n",
      "Ventana 32 de 153\n",
      "Entrenando con semanas: [31 32 33 34 35 36 37 38 39 40], testeando en semanas [41 42 43], len train: 474, len test: 66, porcentaje: 0.88\n",
      "Iniciando ventana 32 con pesos de la ventana anterior\n",
      "Ventana 32, Época: 0, Train Loss: 0.53617603, Test Loss: 0.77261627, AUC: 0.6477, Accuracy: 0.5606\n",
      "Ventana 32, Época: 5, Train Loss: 0.46920162, Test Loss: 0.80009508, AUC: 0.6733, Accuracy: 0.5909\n",
      "Ventana 32, Época: 8, Train Loss: 0.42082733, Test Loss: 0.74845117, AUC: 0.6980, Accuracy: 0.6364\n",
      "Early stopping en la ventana 32, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 32\n",
      "-------------------\n",
      "Ventana 33 de 153\n",
      "Entrenando con semanas: [32 33 34 35 36 37 38 39 40 41], testeando en semanas [42 43 44], len train: 394, len test: 100, porcentaje: 0.80\n",
      "Iniciando ventana 33 con pesos de la ventana anterior\n",
      "Ventana 33, Época: 0, Train Loss: 0.51720136, Test Loss: 0.73414332, AUC: 0.7007, Accuracy: 0.6400\n",
      "Ventana 33, Época: 5, Train Loss: 0.44494033, Test Loss: 0.72687250, AUC: 0.7035, Accuracy: 0.6400\n",
      "Ventana 33, Época: 8, Train Loss: 0.40295511, Test Loss: 0.74132150, AUC: 0.7127, Accuracy: 0.6500\n",
      "Early stopping en la ventana 33, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 33\n",
      "-------------------\n",
      "Ventana 34 de 153\n",
      "Entrenando con semanas: [33 34 35 36 37 38 39 40 41 42], testeando en semanas [43 44 45], len train: 372, len test: 153, porcentaje: 0.71\n",
      "Iniciando ventana 34 con pesos de la ventana anterior\n",
      "Ventana 34, Época: 0, Train Loss: 0.46265250, Test Loss: 0.66815931, AUC: 0.7521, Accuracy: 0.6863\n",
      "Ventana 34, Época: 5, Train Loss: 0.37707135, Test Loss: 0.73872268, AUC: 0.7425, Accuracy: 0.6863\n",
      "Early stopping en la ventana 34, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 34\n",
      "-------------------\n",
      "Ventana 35 de 153\n",
      "Entrenando con semanas: [34 35 36 37 38 39 40 41 42 43], testeando en semanas [44 45 46], len train: 403, len test: 199, porcentaje: 0.67\n",
      "Iniciando ventana 35 con pesos de la ventana anterior\n",
      "Ventana 35, Época: 0, Train Loss: 0.50250983, Test Loss: 0.67558712, AUC: 0.7238, Accuracy: 0.6533\n",
      "Ventana 35, Época: 5, Train Loss: 0.39592648, Test Loss: 0.73106778, AUC: 0.7100, Accuracy: 0.6482\n",
      "Early stopping en la ventana 35, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 35\n",
      "-------------------\n",
      "Ventana 36 de 153\n",
      "Entrenando con semanas: [35 36 37 38 39 40 41 42 43 44], testeando en semanas [45 46 47], len train: 398, len test: 189, porcentaje: 0.68\n",
      "Iniciando ventana 36 con pesos de la ventana anterior\n",
      "Ventana 36, Época: 0, Train Loss: 0.49318284, Test Loss: 0.74171698, AUC: 0.7034, Accuracy: 0.6138\n",
      "Ventana 36, Época: 5, Train Loss: 0.38079709, Test Loss: 0.81932616, AUC: 0.6737, Accuracy: 0.6032\n",
      "Early stopping en la ventana 36, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 36\n",
      "-------------------\n",
      "Ventana 37 de 153\n",
      "Entrenando con semanas: [36 37 38 39 40 41 42 43 44 45], testeando en semanas [46 47 48], len train: 409, len test: 229, porcentaje: 0.64\n",
      "Iniciando ventana 37 con pesos de la ventana anterior\n",
      "Ventana 37, Época: 0, Train Loss: 0.50990051, Test Loss: 0.78124362, AUC: 0.6581, Accuracy: 0.5808\n",
      "Ventana 37, Época: 5, Train Loss: 0.41684625, Test Loss: 0.83816969, AUC: 0.6369, Accuracy: 0.5764\n",
      "Ventana 37, Época: 7, Train Loss: 0.37574354, Test Loss: 0.79382598, AUC: 0.6389, Accuracy: 0.5939\n",
      "Early stopping en la ventana 37, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 37\n",
      "-------------------\n",
      "Ventana 38 de 153\n",
      "Entrenando con semanas: [37 38 39 40 41 42 43 44 45 46], testeando en semanas [47 48 49], len train: 496, len test: 164, porcentaje: 0.75\n",
      "Iniciando ventana 38 con pesos de la ventana anterior\n",
      "Ventana 38, Época: 0, Train Loss: 0.51973403, Test Loss: 0.79335839, AUC: 0.6324, Accuracy: 0.5671\n",
      "Ventana 38, Época: 5, Train Loss: 0.42752635, Test Loss: 0.80535686, AUC: 0.6417, Accuracy: 0.5854\n",
      "Early stopping en la ventana 38, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 38\n",
      "-------------------\n",
      "Ventana 39 de 153\n",
      "Entrenando con semanas: [38 39 40 41 42 43 44 45 46 47], testeando en semanas [48 49 50], len train: 518, len test: 154, porcentaje: 0.77\n",
      "Iniciando ventana 39 con pesos de la ventana anterior\n",
      "Ventana 39, Época: 0, Train Loss: 0.51395005, Test Loss: 0.77839309, AUC: 0.6396, Accuracy: 0.5844\n",
      "Ventana 39, Época: 5, Train Loss: 0.42730665, Test Loss: 0.77063656, AUC: 0.6484, Accuracy: 0.5714\n",
      "Ventana 39, Época: 10, Train Loss: 0.35041612, Test Loss: 0.80628365, AUC: 0.6555, Accuracy: 0.5974\n",
      "Early stopping en la ventana 39, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 39\n",
      "-------------------\n",
      "Ventana 40 de 153\n",
      "Entrenando con semanas: [39 40 41 42 43 44 45 46 47 48], testeando en semanas [49 50 51], len train: 618, len test: 117, porcentaje: 0.84\n",
      "Iniciando ventana 40 con pesos de la ventana anterior\n",
      "Ventana 40, Época: 0, Train Loss: 0.46043634, Test Loss: 0.79719412, AUC: 0.6282, Accuracy: 0.6410\n",
      "Ventana 40, Época: 5, Train Loss: 0.40831214, Test Loss: 0.74956876, AUC: 0.6862, Accuracy: 0.6325\n",
      "Ventana 40, Época: 10, Train Loss: 0.34248084, Test Loss: 0.76580787, AUC: 0.6894, Accuracy: 0.6581\n",
      "Ventana 40, Época: 11, Train Loss: 0.33266911, Test Loss: 0.77500123, AUC: 0.6900, Accuracy: 0.6496\n",
      "Early stopping en la ventana 40, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 40\n",
      "-------------------\n",
      "Ventana 41 de 153\n",
      "Entrenando con semanas: [40 41 42 43 44 45 46 47 48 49], testeando en semanas [50 51 52], len train: 543, len test: 139, porcentaje: 0.80\n",
      "Iniciando ventana 41 con pesos de la ventana anterior\n",
      "Ventana 41, Época: 0, Train Loss: 0.41172805, Test Loss: 0.68025106, AUC: 0.7401, Accuracy: 0.6835\n",
      "Ventana 41, Época: 5, Train Loss: 0.33800331, Test Loss: 0.70033604, AUC: 0.7304, Accuracy: 0.6978\n",
      "Ventana 41, Época: 7, Train Loss: 0.33167750, Test Loss: 0.74527341, AUC: 0.7327, Accuracy: 0.6763\n",
      "Early stopping en la ventana 41, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 41\n",
      "-------------------\n",
      "Ventana 42 de 153\n",
      "Entrenando con semanas: [41 42 43 44 45 46 47 48 49 50], testeando en semanas [51 52 53], len train: 454, len test: 136, porcentaje: 0.77\n",
      "Iniciando ventana 42 con pesos de la ventana anterior\n",
      "Ventana 42, Época: 0, Train Loss: 0.41746551, Test Loss: 0.73026478, AUC: 0.7468, Accuracy: 0.6544\n",
      "Ventana 42, Época: 5, Train Loss: 0.33722132, Test Loss: 0.69549918, AUC: 0.7366, Accuracy: 0.6985\n",
      "Ventana 42, Época: 7, Train Loss: 0.34073877, Test Loss: 0.72731543, AUC: 0.7288, Accuracy: 0.6912\n",
      "Early stopping en la ventana 42, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 42\n",
      "-------------------\n",
      "Ventana 43 de 153\n",
      "Entrenando con semanas: [42 43 44 45 46 47 48 49 50 51], testeando en semanas [52 53 54], len train: 511, len test: 144, porcentaje: 0.78\n",
      "Iniciando ventana 43 con pesos de la ventana anterior\n",
      "Ventana 43, Época: 0, Train Loss: 0.42889404, Test Loss: 0.69487858, AUC: 0.7260, Accuracy: 0.6806\n",
      "Ventana 43, Época: 5, Train Loss: 0.36373979, Test Loss: 0.68747580, AUC: 0.7320, Accuracy: 0.6597\n",
      "Ventana 43, Época: 10, Train Loss: 0.30846441, Test Loss: 0.69629091, AUC: 0.7459, Accuracy: 0.6597\n",
      "Ventana 43, Época: 14, Train Loss: 0.26228765, Test Loss: 0.74901056, AUC: 0.7309, Accuracy: 0.6736\n",
      "Early stopping en la ventana 43, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 43\n",
      "-------------------\n",
      "Ventana 44 de 153\n",
      "Entrenando con semanas: [43 44 45 46 47 48 49 50 51 52], testeando en semanas [53 54 55], len train: 545, len test: 149, porcentaje: 0.79\n",
      "Iniciando ventana 44 con pesos de la ventana anterior\n",
      "Ventana 44, Época: 0, Train Loss: 0.33052820, Test Loss: 0.76051933, AUC: 0.7014, Accuracy: 0.6443\n",
      "Ventana 44, Época: 5, Train Loss: 0.26703426, Test Loss: 0.87002909, AUC: 0.6847, Accuracy: 0.6443\n",
      "Early stopping en la ventana 44, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 44\n",
      "-------------------\n",
      "Ventana 45 de 153\n",
      "Entrenando con semanas: [44 45 46 47 48 49 50 51 52 53], testeando en semanas [54 55 56], len train: 524, len test: 257, porcentaje: 0.67\n",
      "Iniciando ventana 45 con pesos de la ventana anterior\n",
      "Ventana 45, Época: 0, Train Loss: 0.33707786, Test Loss: 0.85668010, AUC: 0.6398, Accuracy: 0.5992\n",
      "Ventana 45, Época: 5, Train Loss: 0.27904797, Test Loss: 0.89433384, AUC: 0.6397, Accuracy: 0.5798\n",
      "Early stopping en la ventana 45, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 45\n",
      "-------------------\n",
      "Ventana 46 de 153\n",
      "Entrenando con semanas: [45 46 47 48 49 50 51 52 53 54], testeando en semanas [55 56 57], len train: 555, len test: 277, porcentaje: 0.67\n",
      "Iniciando ventana 46 con pesos de la ventana anterior\n",
      "Ventana 46, Época: 0, Train Loss: 0.40489522, Test Loss: 0.89762771, AUC: 0.6664, Accuracy: 0.6101\n",
      "Ventana 46, Época: 5, Train Loss: 0.34228915, Test Loss: 0.89644331, AUC: 0.6637, Accuracy: 0.6137\n",
      "Ventana 46, Época: 7, Train Loss: 0.32358980, Test Loss: 0.91172487, AUC: 0.6664, Accuracy: 0.6318\n",
      "Early stopping en la ventana 46, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 46\n",
      "-------------------\n",
      "Ventana 47 de 153\n",
      "Entrenando con semanas: [46 47 48 49 50 51 52 53 54 55], testeando en semanas [56 57 58], len train: 541, len test: 237, porcentaje: 0.70\n",
      "Iniciando ventana 47 con pesos de la ventana anterior\n",
      "Ventana 47, Época: 0, Train Loss: 0.42857105, Test Loss: 0.90380687, AUC: 0.6621, Accuracy: 0.5781\n",
      "Ventana 47, Época: 5, Train Loss: 0.34988400, Test Loss: 0.95813519, AUC: 0.6529, Accuracy: 0.5823\n",
      "Early stopping en la ventana 47, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 47\n",
      "-------------------\n",
      "Ventana 48 de 153\n",
      "Entrenando con semanas: [47 48 49 50 51 52 53 54 55 56], testeando en semanas [57 58 59], len train: 582, len test: 131, porcentaje: 0.82\n",
      "Iniciando ventana 48 con pesos de la ventana anterior\n",
      "Ventana 48, Época: 0, Train Loss: 0.55768347, Test Loss: 1.02613223, AUC: 0.6646, Accuracy: 0.5954\n",
      "Ventana 48, Época: 5, Train Loss: 0.40827793, Test Loss: 0.93721253, AUC: 0.6461, Accuracy: 0.5954\n",
      "Ventana 48, Época: 10, Train Loss: 0.36766225, Test Loss: 0.88945520, AUC: 0.6767, Accuracy: 0.6412\n",
      "Ventana 48, Época: 15, Train Loss: 0.29563463, Test Loss: 0.88137031, AUC: 0.6905, Accuracy: 0.6412\n",
      "Ventana 48, Época: 16, Train Loss: 0.27943552, Test Loss: 0.89680225, AUC: 0.6952, Accuracy: 0.6489\n",
      "Early stopping en la ventana 48, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 48\n",
      "-------------------\n",
      "Ventana 49 de 153\n",
      "Entrenando con semanas: [48 49 50 51 52 53 54 55 56 57], testeando en semanas [58 59 60], len train: 643, len test: 95, porcentaje: 0.87\n",
      "Iniciando ventana 49 con pesos de la ventana anterior\n",
      "Ventana 49, Época: 0, Train Loss: 0.41858175, Test Loss: 1.07007194, AUC: 0.5481, Accuracy: 0.5579\n",
      "Ventana 49, Época: 5, Train Loss: 0.35607842, Test Loss: 1.17185986, AUC: 0.5677, Accuracy: 0.5789\n",
      "Ventana 49, Época: 8, Train Loss: 0.28951317, Test Loss: 1.16849816, AUC: 0.5980, Accuracy: 0.6000\n",
      "Early stopping en la ventana 49, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 49\n",
      "-------------------\n",
      "Ventana 50 de 153\n",
      "Entrenando con semanas: [49 50 51 52 53 54 55 56 57 58], testeando en semanas [59 60 61], len train: 549, len test: 192, porcentaje: 0.74\n",
      "Iniciando ventana 50 con pesos de la ventana anterior\n",
      "Ventana 50, Época: 0, Train Loss: 0.40028346, Test Loss: 1.06478536, AUC: 0.6118, Accuracy: 0.5938\n",
      "Ventana 50, Época: 5, Train Loss: 0.29211938, Test Loss: 1.06825328, AUC: 0.6273, Accuracy: 0.6302\n",
      "Ventana 50, Época: 6, Train Loss: 0.27115843, Test Loss: 1.12384653, AUC: 0.6314, Accuracy: 0.6250\n",
      "Early stopping en la ventana 50, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 50\n",
      "-------------------\n",
      "Ventana 51 de 153\n",
      "Entrenando con semanas: [50 51 52 53 54 55 56 57 58 59], testeando en semanas [60 61 62], len train: 549, len test: 283, porcentaje: 0.66\n",
      "Iniciando ventana 51 con pesos de la ventana anterior\n",
      "Ventana 51, Época: 0, Train Loss: 0.39325109, Test Loss: 0.97541964, AUC: 0.6869, Accuracy: 0.6360\n",
      "Ventana 51, Época: 5, Train Loss: 0.29526982, Test Loss: 1.05259001, AUC: 0.6900, Accuracy: 0.6502\n",
      "Ventana 51, Época: 6, Train Loss: 0.26692814, Test Loss: 1.15968204, AUC: 0.6851, Accuracy: 0.6360\n",
      "Early stopping en la ventana 51, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 51\n",
      "-------------------\n",
      "Ventana 52 de 153\n",
      "Entrenando con semanas: [51 52 53 54 55 56 57 58 59 60], testeando en semanas [61 62 63], len train: 584, len test: 233, porcentaje: 0.71\n",
      "Iniciando ventana 52 con pesos de la ventana anterior\n",
      "Ventana 52, Época: 0, Train Loss: 0.41652352, Test Loss: 0.90798444, AUC: 0.7136, Accuracy: 0.6781\n",
      "Ventana 52, Época: 5, Train Loss: 0.31298712, Test Loss: 0.90593517, AUC: 0.7110, Accuracy: 0.6652\n",
      "Ventana 52, Época: 10, Train Loss: 0.26020360, Test Loss: 0.94142735, AUC: 0.7148, Accuracy: 0.6652\n",
      "Ventana 52, Época: 11, Train Loss: 0.23192121, Test Loss: 0.98258829, AUC: 0.7122, Accuracy: 0.6524\n",
      "Early stopping en la ventana 52, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 52\n",
      "-------------------\n",
      "Ventana 53 de 153\n",
      "Entrenando con semanas: [52 53 54 55 56 57 58 59 60 61], testeando en semanas [62 63 64], len train: 624, len test: 135, porcentaje: 0.82\n",
      "Iniciando ventana 53 con pesos de la ventana anterior\n",
      "Ventana 53, Época: 0, Train Loss: 0.45152000, Test Loss: 0.79769558, AUC: 0.7729, Accuracy: 0.6889\n",
      "Ventana 53, Época: 5, Train Loss: 0.34052995, Test Loss: 0.74746215, AUC: 0.7789, Accuracy: 0.6963\n",
      "Ventana 53, Época: 9, Train Loss: 0.28698421, Test Loss: 0.76882350, AUC: 0.7633, Accuracy: 0.6889\n",
      "Early stopping en la ventana 53, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 53\n",
      "-------------------\n",
      "Ventana 54 de 153\n",
      "Entrenando con semanas: [53 54 55 56 57 58 59 60 61 62], testeando en semanas [63 64 65], len train: 693, len test: 49, porcentaje: 0.93\n",
      "Iniciando ventana 54 con pesos de la ventana anterior\n",
      "Ventana 54, Época: 0, Train Loss: 0.41680828, Test Loss: 1.21866584, AUC: 0.6783, Accuracy: 0.5714\n",
      "Ventana 54, Época: 5, Train Loss: 0.35586315, Test Loss: 0.97138065, AUC: 0.6800, Accuracy: 0.5918\n",
      "Ventana 54, Época: 10, Train Loss: 0.28708267, Test Loss: 0.98320007, AUC: 0.6667, Accuracy: 0.6122\n",
      "Ventana 54, Época: 14, Train Loss: 0.25368720, Test Loss: 1.08583236, AUC: 0.6517, Accuracy: 0.5510\n",
      "Early stopping en la ventana 54, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 54\n",
      "-------------------\n",
      "Ventana 55 de 153\n",
      "Entrenando con semanas: [54 55 56 57 58 59 60 61 62 63], testeando en semanas [64 65 66], len train: 681, len test: 52, porcentaje: 0.93\n",
      "Iniciando ventana 55 con pesos de la ventana anterior\n",
      "Ventana 55, Época: 0, Train Loss: 0.29620802, Test Loss: 1.38361037, AUC: 0.6167, Accuracy: 0.5577\n",
      "Ventana 55, Época: 5, Train Loss: 0.25158730, Test Loss: 1.53250647, AUC: 0.5985, Accuracy: 0.5192\n",
      "Ventana 55, Época: 7, Train Loss: 0.22933382, Test Loss: 1.43456709, AUC: 0.5970, Accuracy: 0.5769\n",
      "Early stopping en la ventana 55, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 55\n",
      "-------------------\n",
      "Ventana 56 de 153\n",
      "Entrenando con semanas: [55 56 57 58 59 60 61 62 63 64], testeando en semanas [65 66 67], len train: 615, len test: 107, porcentaje: 0.85\n",
      "Iniciando ventana 56 con pesos de la ventana anterior\n",
      "Ventana 56, Época: 0, Train Loss: 0.29168531, Test Loss: 1.32025361, AUC: 0.6175, Accuracy: 0.5981\n",
      "Ventana 56, Época: 5, Train Loss: 0.24233755, Test Loss: 1.25887179, AUC: 0.6456, Accuracy: 0.6168\n",
      "Ventana 56, Época: 7, Train Loss: 0.21785212, Test Loss: 1.31020617, AUC: 0.6239, Accuracy: 0.5794\n",
      "Early stopping en la ventana 56, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 56\n",
      "-------------------\n",
      "Ventana 57 de 153\n",
      "Entrenando con semanas: [56 57 58 59 60 61 62 63 64 65], testeando en semanas [66 67 68], len train: 593, len test: 155, porcentaje: 0.79\n",
      "Iniciando ventana 57 con pesos de la ventana anterior\n",
      "Ventana 57, Época: 0, Train Loss: 0.32360554, Test Loss: 1.49859965, AUC: 0.5643, Accuracy: 0.5548\n",
      "Ventana 57, Época: 5, Train Loss: 0.24258341, Test Loss: 1.53901720, AUC: 0.5589, Accuracy: 0.5935\n",
      "Early stopping en la ventana 57, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 57\n",
      "-------------------\n",
      "Ventana 58 de 153\n",
      "Entrenando con semanas: [57 58 59 60 61 62 63 64 65 66], testeando en semanas [67 68 69], len train: 476, len test: 193, porcentaje: 0.71\n",
      "Iniciando ventana 58 con pesos de la ventana anterior\n",
      "Ventana 58, Época: 0, Train Loss: 0.41026661, Test Loss: 1.42277646, AUC: 0.5698, Accuracy: 0.5648\n",
      "Ventana 58, Época: 5, Train Loss: 0.26446095, Test Loss: 1.42266905, AUC: 0.5731, Accuracy: 0.5699\n",
      "Ventana 58, Época: 6, Train Loss: 0.28158602, Test Loss: 1.47600675, AUC: 0.5693, Accuracy: 0.5699\n",
      "Early stopping en la ventana 58, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 58\n",
      "-------------------\n",
      "Ventana 59 de 153\n",
      "Entrenando con semanas: [58 59 60 61 62 63 64 65 66 67], testeando en semanas [68 69 70], len train: 445, len test: 237, porcentaje: 0.65\n",
      "Iniciando ventana 59 con pesos de la ventana anterior\n",
      "Ventana 59, Época: 0, Train Loss: 0.49405062, Test Loss: 1.52568221, AUC: 0.5195, Accuracy: 0.5401\n",
      "Ventana 59, Época: 5, Train Loss: 0.31003746, Test Loss: 1.46191776, AUC: 0.5196, Accuracy: 0.5359\n",
      "Ventana 59, Época: 10, Train Loss: 0.24672741, Test Loss: 1.45004082, AUC: 0.5135, Accuracy: 0.5443\n",
      "Ventana 59, Época: 13, Train Loss: 0.22420049, Test Loss: 1.42165864, AUC: 0.5139, Accuracy: 0.5105\n",
      "Early stopping en la ventana 59, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 59\n",
      "-------------------\n",
      "Ventana 60 de 153\n",
      "Entrenando con semanas: [59 60 61 62 63 64 65 66 67 68], testeando en semanas [69 70 71], len train: 511, len test: 271, porcentaje: 0.65\n",
      "Iniciando ventana 60 con pesos de la ventana anterior\n",
      "Ventana 60, Época: 0, Train Loss: 0.44830611, Test Loss: 1.16600823, AUC: 0.5912, Accuracy: 0.5720\n",
      "Ventana 60, Época: 5, Train Loss: 0.31967199, Test Loss: 1.18540883, AUC: 0.5838, Accuracy: 0.5535\n",
      "Ventana 60, Época: 8, Train Loss: 0.25463751, Test Loss: 1.21268356, AUC: 0.5952, Accuracy: 0.5609\n",
      "Early stopping en la ventana 60, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 60\n",
      "-------------------\n",
      "Ventana 61 de 153\n",
      "Entrenando con semanas: [60 61 62 63 64 65 66 67 68 69], testeando en semanas [70 71 72], len train: 538, len test: 231, porcentaje: 0.70\n",
      "Iniciando ventana 61 con pesos de la ventana anterior\n",
      "Ventana 61, Época: 0, Train Loss: 0.46479031, Test Loss: 1.20704687, AUC: 0.5961, Accuracy: 0.5411\n",
      "Ventana 61, Época: 5, Train Loss: 0.31340295, Test Loss: 1.10541677, AUC: 0.5912, Accuracy: 0.5801\n",
      "Ventana 61, Época: 10, Train Loss: 0.25156364, Test Loss: 1.11569309, AUC: 0.5992, Accuracy: 0.5584\n",
      "Ventana 61, Época: 11, Train Loss: 0.22876100, Test Loss: 1.15746188, AUC: 0.6023, Accuracy: 0.5541\n",
      "Early stopping en la ventana 61, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 61\n",
      "-------------------\n",
      "Ventana 62 de 153\n",
      "Entrenando con semanas: [61 62 63 64 65 66 67 68 69 70], testeando en semanas [71 72 73], len train: 587, len test: 145, porcentaje: 0.80\n",
      "Iniciando ventana 62 con pesos de la ventana anterior\n",
      "Ventana 62, Época: 0, Train Loss: 0.46471247, Test Loss: 1.10817671, AUC: 0.6949, Accuracy: 0.5931\n",
      "Ventana 62, Época: 5, Train Loss: 0.33304977, Test Loss: 1.18505263, AUC: 0.6823, Accuracy: 0.5862\n",
      "Ventana 62, Época: 6, Train Loss: 0.31008631, Test Loss: 1.09791136, AUC: 0.6823, Accuracy: 0.5862\n",
      "Early stopping en la ventana 62, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 62\n",
      "-------------------\n",
      "Ventana 63 de 153\n",
      "Entrenando con semanas: [62 63 64 65 66 67 68 69 70 71], testeando en semanas [72 73 74], len train: 590, len test: 95, porcentaje: 0.86\n",
      "Iniciando ventana 63 con pesos de la ventana anterior\n",
      "Ventana 63, Época: 0, Train Loss: 0.50025058, Test Loss: 1.18047833, AUC: 0.6847, Accuracy: 0.6105\n",
      "Ventana 63, Época: 5, Train Loss: 0.35701206, Test Loss: 1.17485893, AUC: 0.6473, Accuracy: 0.5789\n",
      "Ventana 63, Época: 6, Train Loss: 0.34153238, Test Loss: 1.16291106, AUC: 0.6454, Accuracy: 0.5895\n",
      "Early stopping en la ventana 63, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 63\n",
      "-------------------\n",
      "Ventana 64 de 153\n",
      "Entrenando con semanas: [63 64 65 66 67 68 69 70 71 72], testeando en semanas [73 74 75], len train: 486, len test: 108, porcentaje: 0.82\n",
      "Iniciando ventana 64 con pesos de la ventana anterior\n",
      "Ventana 64, Época: 0, Train Loss: 0.55887496, Test Loss: 0.92995924, AUC: 0.7136, Accuracy: 0.6481\n",
      "Ventana 64, Época: 5, Train Loss: 0.36137107, Test Loss: 0.86907613, AUC: 0.6970, Accuracy: 0.6296\n",
      "Ventana 64, Época: 9, Train Loss: 0.30417177, Test Loss: 0.83966231, AUC: 0.7060, Accuracy: 0.6389\n",
      "Early stopping en la ventana 64, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 64\n",
      "-------------------\n",
      "Ventana 65 de 153\n",
      "Entrenando con semanas: [64 65 66 67 68 69 70 71 72 73], testeando en semanas [74 75 76], len train: 499, len test: 168, porcentaje: 0.75\n",
      "Iniciando ventana 65 con pesos de la ventana anterior\n",
      "Ventana 65, Época: 0, Train Loss: 0.40882024, Test Loss: 0.78729886, AUC: 0.6780, Accuracy: 0.6369\n",
      "Ventana 65, Época: 5, Train Loss: 0.32397762, Test Loss: 0.90331912, AUC: 0.6407, Accuracy: 0.6071\n",
      "Early stopping en la ventana 65, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 65\n",
      "-------------------\n",
      "Ventana 66 de 153\n",
      "Entrenando con semanas: [65 66 67 68 69 70 71 72 73 74], testeando en semanas [75 76 77], len train: 550, len test: 162, porcentaje: 0.77\n",
      "Iniciando ventana 66 con pesos de la ventana anterior\n",
      "Ventana 66, Época: 0, Train Loss: 0.44364572, Test Loss: 1.02957690, AUC: 0.5795, Accuracy: 0.5556\n",
      "Ventana 66, Época: 5, Train Loss: 0.30856904, Test Loss: 1.11086035, AUC: 0.5527, Accuracy: 0.5247\n",
      "Ventana 66, Época: 7, Train Loss: 0.29480514, Test Loss: 1.13171768, AUC: 0.5559, Accuracy: 0.5185\n",
      "Early stopping en la ventana 66, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 66\n",
      "-------------------\n",
      "Ventana 67 de 153\n",
      "Entrenando con semanas: [66 67 68 69 70 71 72 73 74 75], testeando en semanas [76 77 78], len train: 545, len test: 140, porcentaje: 0.80\n",
      "Iniciando ventana 67 con pesos de la ventana anterior\n",
      "Ventana 67, Época: 0, Train Loss: 0.40231276, Test Loss: 1.18566370, AUC: 0.5463, Accuracy: 0.5071\n",
      "Ventana 67, Época: 5, Train Loss: 0.30023843, Test Loss: 1.31592929, AUC: 0.5376, Accuracy: 0.5214\n",
      "Ventana 67, Época: 8, Train Loss: 0.28236613, Test Loss: 1.23678005, AUC: 0.5354, Accuracy: 0.5357\n",
      "Early stopping en la ventana 67, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 67\n",
      "-------------------\n",
      "Ventana 68 de 153\n",
      "Entrenando con semanas: [67 68 69 70 71 72 73 74 75 76], testeando en semanas [77 78 79], len train: 615, len test: 70, porcentaje: 0.90\n",
      "Iniciando ventana 68 con pesos de la ventana anterior\n",
      "Ventana 68, Época: 0, Train Loss: 0.41033056, Test Loss: 1.42250633, AUC: 0.4678, Accuracy: 0.5000\n",
      "Ventana 68, Época: 5, Train Loss: 0.35827470, Test Loss: 1.38168073, AUC: 0.4759, Accuracy: 0.4714\n",
      "Ventana 68, Época: 9, Train Loss: 0.27661139, Test Loss: 1.43170810, AUC: 0.4735, Accuracy: 0.5000\n",
      "Early stopping en la ventana 68, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 68\n",
      "-------------------\n",
      "Ventana 69 de 153\n",
      "Entrenando con semanas: [68 69 70 71 72 73 74 75 76 77], testeando en semanas [78 79 80], len train: 605, len test: 21, porcentaje: 0.97\n",
      "Iniciando ventana 69 con pesos de la ventana anterior\n",
      "Ventana 69, Época: 0, Train Loss: 0.44948801, Test Loss: 1.64408529, AUC: 0.3846, Accuracy: 0.3810\n",
      "Ventana 69, Época: 5, Train Loss: 0.34407115, Test Loss: 1.39193285, AUC: 0.5000, Accuracy: 0.5714\n",
      "Ventana 69, Época: 10, Train Loss: 0.28513846, Test Loss: 1.75111639, AUC: 0.4519, Accuracy: 0.3333\n",
      "Early stopping en la ventana 69, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 69\n",
      "-------------------\n",
      "Ventana 70 de 153\n",
      "Entrenando con semanas: [69 70 71 72 73 74 75 76 77 78], testeando en semanas [79 80 81], len train: 530, len test: 120, porcentaje: 0.82\n",
      "Iniciando ventana 70 con pesos de la ventana anterior\n",
      "Ventana 70, Época: 0, Train Loss: 0.36885175, Test Loss: 0.91823375, AUC: 0.6563, Accuracy: 0.6167\n",
      "Ventana 70, Época: 5, Train Loss: 0.29296243, Test Loss: 1.09636414, AUC: 0.5982, Accuracy: 0.5417\n",
      "Early stopping en la ventana 70, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 70\n",
      "-------------------\n",
      "Ventana 71 de 153\n",
      "Entrenando con semanas: [70 71 72 73 74 75 76 77 78 79], testeando en semanas [80 81 82], len train: 492, len test: 222, porcentaje: 0.69\n",
      "Iniciando ventana 71 con pesos de la ventana anterior\n",
      "Ventana 71, Época: 0, Train Loss: 0.38699374, Test Loss: 0.90207237, AUC: 0.6824, Accuracy: 0.6396\n",
      "Ventana 71, Época: 5, Train Loss: 0.29060283, Test Loss: 0.96243602, AUC: 0.6671, Accuracy: 0.5946\n",
      "Early stopping en la ventana 71, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 71\n",
      "-------------------\n",
      "Ventana 72 de 153\n",
      "Entrenando con semanas: [71 72 73 74 75 76 77 78 79 80], testeando en semanas [81 82 83], len train: 389, len test: 227, porcentaje: 0.63\n",
      "Iniciando ventana 72 con pesos de la ventana anterior\n",
      "Ventana 72, Época: 0, Train Loss: 0.41027099, Test Loss: 0.92861611, AUC: 0.6649, Accuracy: 0.5991\n",
      "Ventana 72, Época: 5, Train Loss: 0.31184644, Test Loss: 0.91912490, AUC: 0.6754, Accuracy: 0.6167\n",
      "Ventana 72, Época: 7, Train Loss: 0.28726825, Test Loss: 0.97085452, AUC: 0.6636, Accuracy: 0.6300\n",
      "Early stopping en la ventana 72, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 72\n",
      "-------------------\n",
      "Ventana 73 de 153\n",
      "Entrenando con semanas: [72 73 74 75 76 77 78 79 80 81], testeando en semanas [82 83 84], len train: 379, len test: 138, porcentaje: 0.73\n",
      "Iniciando ventana 73 con pesos de la ventana anterior\n",
      "Ventana 73, Época: 0, Train Loss: 0.55914330, Test Loss: 0.92353362, AUC: 0.6789, Accuracy: 0.6014\n",
      "Ventana 73, Época: 5, Train Loss: 0.39738306, Test Loss: 0.88055360, AUC: 0.6761, Accuracy: 0.6594\n",
      "Ventana 73, Época: 9, Train Loss: 0.32540450, Test Loss: 0.89556748, AUC: 0.6831, Accuracy: 0.6377\n",
      "Early stopping en la ventana 73, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 73\n",
      "-------------------\n",
      "Ventana 74 de 153\n",
      "Entrenando con semanas: [73 74 75 76 77 78 79 80 81 82], testeando en semanas [83 84 85], len train: 483, len test: 66, porcentaje: 0.88\n",
      "Iniciando ventana 74 con pesos de la ventana anterior\n",
      "Ventana 74, Época: 0, Train Loss: 0.52596205, Test Loss: 0.82801557, AUC: 0.7000, Accuracy: 0.6061\n",
      "Ventana 74, Época: 5, Train Loss: 0.37247089, Test Loss: 0.81770784, AUC: 0.6861, Accuracy: 0.6212\n",
      "Ventana 74, Época: 10, Train Loss: 0.30189210, Test Loss: 0.89205045, AUC: 0.6796, Accuracy: 0.6364\n",
      "Ventana 74, Época: 11, Train Loss: 0.27387935, Test Loss: 0.90238351, AUC: 0.6713, Accuracy: 0.5909\n",
      "Early stopping en la ventana 74, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 74\n",
      "-------------------\n",
      "Ventana 75 de 153\n",
      "Entrenando con semanas: [74 75 76 77 78 79 80 81 82 83], testeando en semanas [84 85 86], len train: 471, len test: 106, porcentaje: 0.82\n",
      "Iniciando ventana 75 con pesos de la ventana anterior\n",
      "Ventana 75, Época: 0, Train Loss: 0.34927043, Test Loss: 0.91197127, AUC: 0.6593, Accuracy: 0.6226\n",
      "Ventana 75, Época: 5, Train Loss: 0.25959280, Test Loss: 1.02109492, AUC: 0.6493, Accuracy: 0.6132\n",
      "Early stopping en la ventana 75, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 75\n",
      "-------------------\n",
      "Ventana 76 de 153\n",
      "Entrenando con semanas: [75 76 77 78 79 80 81 82 83 84], testeando en semanas [85 86 87], len train: 422, len test: 156, porcentaje: 0.73\n",
      "Iniciando ventana 76 con pesos de la ventana anterior\n",
      "Ventana 76, Época: 0, Train Loss: 0.35147101, Test Loss: 0.94694853, AUC: 0.6461, Accuracy: 0.6346\n",
      "Ventana 76, Época: 5, Train Loss: 0.23200966, Test Loss: 1.06399786, AUC: 0.6413, Accuracy: 0.6282\n",
      "Early stopping en la ventana 76, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 76\n",
      "-------------------\n",
      "Ventana 77 de 153\n",
      "Entrenando con semanas: [76 77 78 79 80 81 82 83 84 85], testeando en semanas [86 87 88], len train: 441, len test: 218, porcentaje: 0.67\n",
      "Iniciando ventana 77 con pesos de la ventana anterior\n",
      "Ventana 77, Época: 0, Train Loss: 0.39947003, Test Loss: 0.93078637, AUC: 0.6422, Accuracy: 0.6147\n",
      "Ventana 77, Época: 5, Train Loss: 0.26881951, Test Loss: 1.04799712, AUC: 0.6485, Accuracy: 0.6055\n",
      "Early stopping en la ventana 77, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 77\n",
      "-------------------\n",
      "Ventana 78 de 153\n",
      "Entrenando con semanas: [77 78 79 80 81 82 83 84 85 86], testeando en semanas [87 88 89], len train: 409, len test: 192, porcentaje: 0.68\n",
      "Iniciando ventana 78 con pesos de la ventana anterior\n",
      "Ventana 78, Época: 0, Train Loss: 0.45979053, Test Loss: 0.91675407, AUC: 0.6515, Accuracy: 0.6406\n",
      "Ventana 78, Época: 5, Train Loss: 0.32514876, Test Loss: 0.96829480, AUC: 0.6325, Accuracy: 0.6198\n",
      "Ventana 78, Época: 7, Train Loss: 0.28803170, Test Loss: 0.93749219, AUC: 0.6479, Accuracy: 0.6198\n",
      "Early stopping en la ventana 78, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 78\n",
      "-------------------\n",
      "Ventana 79 de 153\n",
      "Entrenando con semanas: [78 79 80 81 82 83 84 85 86 87], testeando en semanas [88 89 90], len train: 416, len test: 233, porcentaje: 0.64\n",
      "Iniciando ventana 79 con pesos de la ventana anterior\n",
      "Ventana 79, Época: 0, Train Loss: 0.45193323, Test Loss: 0.89047784, AUC: 0.6385, Accuracy: 0.5794\n",
      "Ventana 79, Época: 5, Train Loss: 0.31453764, Test Loss: 0.97782308, AUC: 0.6145, Accuracy: 0.5966\n",
      "Early stopping en la ventana 79, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 79\n",
      "-------------------\n",
      "Ventana 80 de 153\n",
      "Entrenando con semanas: [79 80 81 82 83 84 85 86 87 88], testeando en semanas [89 90 91], len train: 519, len test: 151, porcentaje: 0.77\n",
      "Iniciando ventana 80 con pesos de la ventana anterior\n",
      "Ventana 80, Época: 0, Train Loss: 0.51652783, Test Loss: 0.93925726, AUC: 0.6196, Accuracy: 0.5695\n",
      "Ventana 80, Época: 5, Train Loss: 0.38805234, Test Loss: 0.84261703, AUC: 0.6389, Accuracy: 0.5960\n",
      "Ventana 80, Época: 10, Train Loss: 0.33626059, Test Loss: 0.88859731, AUC: 0.6090, Accuracy: 0.5563\n",
      "Ventana 80, Época: 12, Train Loss: 0.28715822, Test Loss: 0.87391847, AUC: 0.6389, Accuracy: 0.5762\n",
      "Early stopping en la ventana 80, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 80\n",
      "-------------------\n",
      "Ventana 81 de 153\n",
      "Entrenando con semanas: [80 81 82 83 84 85 86 87 88 89], testeando en semanas [90 91 92], len train: 531, len test: 150, porcentaje: 0.78\n",
      "Iniciando ventana 81 con pesos de la ventana anterior\n",
      "Ventana 81, Época: 0, Train Loss: 0.35580334, Test Loss: 0.86409116, AUC: 0.6338, Accuracy: 0.6000\n",
      "Ventana 81, Época: 5, Train Loss: 0.25270188, Test Loss: 0.97462481, AUC: 0.6094, Accuracy: 0.5667\n",
      "Ventana 81, Época: 6, Train Loss: 0.24108677, Test Loss: 0.98712200, AUC: 0.6112, Accuracy: 0.5667\n",
      "Early stopping en la ventana 81, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 81\n",
      "-------------------\n",
      "Ventana 82 de 153\n",
      "Entrenando con semanas: [81 82 83 84 85 86 87 88 89 90], testeando en semanas [91 92 93], len train: 628, len test: 125, porcentaje: 0.83\n",
      "Iniciando ventana 82 con pesos de la ventana anterior\n",
      "Ventana 82, Época: 0, Train Loss: 0.40297210, Test Loss: 0.93267614, AUC: 0.6057, Accuracy: 0.6080\n",
      "Ventana 82, Época: 5, Train Loss: 0.29115865, Test Loss: 1.07654977, AUC: 0.5795, Accuracy: 0.5680\n",
      "Early stopping en la ventana 82, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 82\n",
      "-------------------\n",
      "Ventana 83 de 153\n",
      "Entrenando con semanas: [82 83 84 85 86 87 88 89 90 91], testeando en semanas [92 93 94], len train: 550, len test: 174, porcentaje: 0.76\n",
      "Iniciando ventana 83 con pesos de la ventana anterior\n",
      "Ventana 83, Época: 0, Train Loss: 0.40421879, Test Loss: 0.92887437, AUC: 0.6126, Accuracy: 0.5920\n",
      "Ventana 83, Época: 5, Train Loss: 0.32143721, Test Loss: 0.96158278, AUC: 0.6480, Accuracy: 0.6322\n",
      "Early stopping en la ventana 83, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 83\n",
      "-------------------\n",
      "Ventana 84 de 153\n",
      "Entrenando con semanas: [83 84 85 86 87 88 89 90 91 92], testeando en semanas [93 94 95], len train: 459, len test: 256, porcentaje: 0.64\n",
      "Iniciando ventana 84 con pesos de la ventana anterior\n",
      "Ventana 84, Época: 0, Train Loss: 0.45754626, Test Loss: 0.97214955, AUC: 0.6003, Accuracy: 0.5859\n",
      "Ventana 84, Época: 5, Train Loss: 0.32717329, Test Loss: 0.93104440, AUC: 0.6279, Accuracy: 0.5781\n",
      "Ventana 84, Época: 10, Train Loss: 0.25399461, Test Loss: 0.96121758, AUC: 0.6244, Accuracy: 0.6016\n",
      "Ventana 84, Época: 11, Train Loss: 0.24716450, Test Loss: 0.97301638, AUC: 0.6253, Accuracy: 0.5977\n",
      "Early stopping en la ventana 84, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 84\n",
      "-------------------\n",
      "Ventana 85 de 153\n",
      "Entrenando con semanas: [84 85 86 87 88 89 90 91 92 93], testeando en semanas [94 95 96], len train: 526, len test: 201, porcentaje: 0.72\n",
      "Iniciando ventana 85 con pesos de la ventana anterior\n",
      "Ventana 85, Época: 0, Train Loss: 0.39374104, Test Loss: 0.93241179, AUC: 0.6218, Accuracy: 0.6020\n",
      "Ventana 85, Época: 5, Train Loss: 0.26148620, Test Loss: 0.94064170, AUC: 0.6483, Accuracy: 0.5970\n",
      "Ventana 85, Época: 9, Train Loss: 0.21963449, Test Loss: 0.98840886, AUC: 0.6414, Accuracy: 0.6070\n",
      "Early stopping en la ventana 85, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 85\n",
      "-------------------\n",
      "Ventana 86 de 153\n",
      "Entrenando con semanas: [85 86 87 88 89 90 91 92 93 94], testeando en semanas [95 96 97], len train: 586, len test: 237, porcentaje: 0.71\n",
      "Iniciando ventana 86 con pesos de la ventana anterior\n",
      "Ventana 86, Época: 0, Train Loss: 0.34640181, Test Loss: 1.08908665, AUC: 0.5968, Accuracy: 0.5527\n",
      "Ventana 86, Época: 5, Train Loss: 0.24524947, Test Loss: 1.10562277, AUC: 0.6097, Accuracy: 0.5654\n",
      "Ventana 86, Época: 8, Train Loss: 0.21578777, Test Loss: 1.15496218, AUC: 0.6199, Accuracy: 0.5781\n",
      "Early stopping en la ventana 86, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 86\n",
      "-------------------\n",
      "Ventana 87 de 153\n",
      "Entrenando con semanas: [86 87 88 89 90 91 92 93 94 95], testeando en semanas [96 97 98], len train: 649, len test: 154, porcentaje: 0.81\n",
      "Iniciando ventana 87 con pesos de la ventana anterior\n",
      "Ventana 87, Época: 0, Train Loss: 0.39227760, Test Loss: 1.14776957, AUC: 0.6052, Accuracy: 0.5649\n",
      "Ventana 87, Época: 5, Train Loss: 0.31196550, Test Loss: 1.05086505, AUC: 0.6062, Accuracy: 0.5844\n",
      "Ventana 87, Época: 10, Train Loss: 0.25384647, Test Loss: 1.07244205, AUC: 0.6188, Accuracy: 0.5909\n",
      "Early stopping en la ventana 87, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 87\n",
      "-------------------\n",
      "Ventana 88 de 153\n",
      "Entrenando con semanas: [87 88 89 90 91 92 93 94 95 96], testeando en semanas [97 98 99], len train: 621, len test: 260, porcentaje: 0.70\n",
      "Iniciando ventana 88 con pesos de la ventana anterior\n",
      "Ventana 88, Época: 0, Train Loss: 0.33469561, Test Loss: 1.09478092, AUC: 0.6068, Accuracy: 0.5731\n",
      "Ventana 88, Época: 5, Train Loss: 0.24218039, Test Loss: 1.01206517, AUC: 0.6343, Accuracy: 0.6115\n",
      "Ventana 88, Época: 10, Train Loss: 0.20629519, Test Loss: 1.02924335, AUC: 0.6434, Accuracy: 0.6192\n",
      "Early stopping en la ventana 88, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 88\n",
      "-------------------\n",
      "Ventana 89 de 153\n",
      "Entrenando con semanas: [88 89 90 91 92 93 94 95 96 97], testeando en semanas [ 98  99 100], len train: 667, len test: 247, porcentaje: 0.73\n",
      "Iniciando ventana 89 con pesos de la ventana anterior\n",
      "Ventana 89, Época: 0, Train Loss: 0.39658824, Test Loss: 1.01057112, AUC: 0.6505, Accuracy: 0.6275\n",
      "Ventana 89, Época: 5, Train Loss: 0.29300308, Test Loss: 1.05521691, AUC: 0.6283, Accuracy: 0.5830\n",
      "Ventana 89, Época: 8, Train Loss: 0.23337293, Test Loss: 1.12346804, AUC: 0.6125, Accuracy: 0.5911\n",
      "Early stopping en la ventana 89, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 89\n",
      "-------------------\n",
      "Ventana 90 de 153\n",
      "Entrenando con semanas: [89 90 91 92 93 94 95 96 97 98], testeando en semanas [ 99 100 101], len train: 585, len test: 235, porcentaje: 0.71\n",
      "Iniciando ventana 90 con pesos de la ventana anterior\n",
      "Ventana 90, Época: 0, Train Loss: 0.37398067, Test Loss: 1.02623308, AUC: 0.6456, Accuracy: 0.6255\n",
      "Ventana 90, Época: 5, Train Loss: 0.30307251, Test Loss: 1.05011022, AUC: 0.6292, Accuracy: 0.5957\n",
      "Ventana 90, Época: 6, Train Loss: 0.27074578, Test Loss: 1.04093552, AUC: 0.6310, Accuracy: 0.6000\n",
      "Early stopping en la ventana 90, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 90\n",
      "-------------------\n",
      "Ventana 91 de 153\n",
      "Entrenando con semanas: [90 91 92 93 94 95 96 97 98 99], testeando en semanas [100 101 102], len train: 689, len test: 129, porcentaje: 0.84\n",
      "Iniciando ventana 91 con pesos de la ventana anterior\n",
      "Ventana 91, Época: 0, Train Loss: 0.42945510, Test Loss: 1.05854106, AUC: 0.6370, Accuracy: 0.6124\n",
      "Ventana 91, Época: 5, Train Loss: 0.32838932, Test Loss: 1.07446134, AUC: 0.6231, Accuracy: 0.6047\n",
      "Early stopping en la ventana 91, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 91\n",
      "-------------------\n",
      "Ventana 92 de 153\n",
      "Entrenando con semanas: [ 91  92  93  94  95  96  97  98  99 100], testeando en semanas [101 102 103], len train: 681, len test: 96, porcentaje: 0.88\n",
      "Iniciando ventana 92 con pesos de la ventana anterior\n",
      "Ventana 92, Época: 0, Train Loss: 0.59039783, Test Loss: 1.12178648, AUC: 0.6280, Accuracy: 0.6354\n",
      "Ventana 92, Época: 5, Train Loss: 0.42953163, Test Loss: 1.09739137, AUC: 0.5996, Accuracy: 0.6146\n",
      "Ventana 92, Época: 10, Train Loss: 0.35810748, Test Loss: 1.05374753, AUC: 0.6134, Accuracy: 0.6042\n",
      "Ventana 92, Época: 15, Train Loss: 0.30006793, Test Loss: 1.20782030, AUC: 0.5671, Accuracy: 0.5417\n",
      "Ventana 92, Época: 16, Train Loss: 0.28633958, Test Loss: 1.20846069, AUC: 0.5634, Accuracy: 0.5312\n",
      "Early stopping en la ventana 92, época 16\n",
      "Mejor modelo guardado en la época  11 para la ventana 92\n",
      "-------------------\n",
      "Ventana 93 de 153\n",
      "Entrenando con semanas: [ 92  93  94  95  96  97  98  99 100 101], testeando en semanas [102 103 104], len train: 669, len test: 191, porcentaje: 0.78\n",
      "Iniciando ventana 93 con pesos de la ventana anterior\n",
      "Ventana 93, Época: 0, Train Loss: 0.36193889, Test Loss: 1.07146549, AUC: 0.5677, Accuracy: 0.5445\n",
      "Ventana 93, Época: 5, Train Loss: 0.26526013, Test Loss: 1.24775064, AUC: 0.5452, Accuracy: 0.4921\n",
      "Early stopping en la ventana 93, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 93\n",
      "-------------------\n",
      "Ventana 94 de 153\n",
      "Entrenando con semanas: [ 93  94  95  96  97  98  99 100 101 102], testeando en semanas [103 104 105], len train: 668, len test: 284, porcentaje: 0.70\n",
      "Iniciando ventana 94 con pesos de la ventana anterior\n",
      "Ventana 94, Época: 0, Train Loss: 0.35457811, Test Loss: 1.09463358, AUC: 0.6225, Accuracy: 0.5599\n",
      "Ventana 94, Época: 5, Train Loss: 0.29288015, Test Loss: 1.31620598, AUC: 0.5896, Accuracy: 0.5282\n",
      "Early stopping en la ventana 94, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 94\n",
      "-------------------\n",
      "Ventana 95 de 153\n",
      "Entrenando con semanas: [ 94  95  96  97  98  99 100 101 102 103], testeando en semanas [104 105 106], len train: 652, len test: 233, porcentaje: 0.74\n",
      "Iniciando ventana 95 con pesos de la ventana anterior\n",
      "Ventana 95, Época: 0, Train Loss: 0.43223163, Test Loss: 1.09075522, AUC: 0.6256, Accuracy: 0.5708\n",
      "Ventana 95, Época: 5, Train Loss: 0.31614146, Test Loss: 1.01658988, AUC: 0.6470, Accuracy: 0.5794\n",
      "Ventana 95, Época: 10, Train Loss: 0.23993576, Test Loss: 1.10068488, AUC: 0.6450, Accuracy: 0.5966\n",
      "Ventana 95, Época: 11, Train Loss: 0.24433662, Test Loss: 1.11657894, AUC: 0.6472, Accuracy: 0.6052\n",
      "Early stopping en la ventana 95, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 95\n",
      "-------------------\n",
      "Ventana 96 de 153\n",
      "Entrenando con semanas: [ 95  96  97  98  99 100 101 102 103 104], testeando en semanas [105 106 107], len train: 686, len test: 139, porcentaje: 0.83\n",
      "Iniciando ventana 96 con pesos de la ventana anterior\n",
      "Ventana 96, Época: 0, Train Loss: 0.44127449, Test Loss: 0.90684825, AUC: 0.7412, Accuracy: 0.6906\n",
      "Ventana 96, Época: 5, Train Loss: 0.36777326, Test Loss: 0.91593343, AUC: 0.7070, Accuracy: 0.6403\n",
      "Ventana 96, Época: 9, Train Loss: 0.29812557, Test Loss: 0.91859913, AUC: 0.7065, Accuracy: 0.6187\n",
      "Early stopping en la ventana 96, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 96\n",
      "-------------------\n",
      "Ventana 97 de 153\n",
      "Entrenando con semanas: [ 96  97  98  99 100 101 102 103 104 105], testeando en semanas [106 107 108], len train: 696, len test: 68, porcentaje: 0.91\n",
      "Iniciando ventana 97 con pesos de la ventana anterior\n",
      "Ventana 97, Época: 0, Train Loss: 0.49222416, Test Loss: 1.50522447, AUC: 0.6116, Accuracy: 0.6176\n",
      "Ventana 97, Época: 5, Train Loss: 0.35216257, Test Loss: 1.39625025, AUC: 0.5890, Accuracy: 0.6176\n",
      "Ventana 97, Época: 10, Train Loss: 0.29540515, Test Loss: 1.32436764, AUC: 0.5935, Accuracy: 0.6324\n",
      "Ventana 97, Época: 15, Train Loss: 0.23968497, Test Loss: 1.54189396, AUC: 0.5781, Accuracy: 0.6176\n",
      "Early stopping en la ventana 97, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 97\n",
      "-------------------\n",
      "Ventana 98 de 153\n",
      "Entrenando con semanas: [ 97  98  99 100 101 102 103 104 105 106], testeando en semanas [107 108 109], len train: 684, len test: 123, porcentaje: 0.85\n",
      "Iniciando ventana 98 con pesos de la ventana anterior\n",
      "Ventana 98, Época: 0, Train Loss: 0.28477186, Test Loss: 1.56613624, AUC: 0.5306, Accuracy: 0.5772\n",
      "Ventana 98, Época: 5, Train Loss: 0.22365755, Test Loss: 1.75494874, AUC: 0.5494, Accuracy: 0.5772\n",
      "Early stopping en la ventana 98, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 98\n",
      "-------------------\n",
      "Ventana 99 de 153\n",
      "Entrenando con semanas: [ 98  99 100 101 102 103 104 105 106 107], testeando en semanas [108 109 110], len train: 588, len test: 189, porcentaje: 0.76\n",
      "Iniciando ventana 99 con pesos de la ventana anterior\n",
      "Ventana 99, Época: 0, Train Loss: 0.29717815, Test Loss: 1.45743835, AUC: 0.5600, Accuracy: 0.5767\n",
      "Ventana 99, Época: 5, Train Loss: 0.24077500, Test Loss: 1.65873420, AUC: 0.5536, Accuracy: 0.5503\n",
      "Early stopping en la ventana 99, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 99\n",
      "-------------------\n",
      "Ventana 100 de 153\n",
      "Entrenando con semanas: [ 99 100 101 102 103 104 105 106 107 108], testeando en semanas [109 110 111], len train: 610, len test: 194, porcentaje: 0.76\n",
      "Iniciando ventana 100 con pesos de la ventana anterior\n",
      "Ventana 100, Época: 0, Train Loss: 0.39492762, Test Loss: 1.30782402, AUC: 0.5953, Accuracy: 0.5876\n",
      "Ventana 100, Época: 5, Train Loss: 0.32950151, Test Loss: 1.33330655, AUC: 0.5955, Accuracy: 0.5773\n",
      "Ventana 100, Época: 7, Train Loss: 0.29493928, Test Loss: 1.34051454, AUC: 0.6004, Accuracy: 0.5567\n",
      "Early stopping en la ventana 100, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 100\n",
      "-------------------\n",
      "Ventana 101 de 153\n",
      "Entrenando con semanas: [100 101 102 103 104 105 106 107 108 109], testeando en semanas [110 111 112], len train: 547, len test: 234, porcentaje: 0.70\n",
      "Iniciando ventana 101 con pesos de la ventana anterior\n",
      "Ventana 101, Época: 0, Train Loss: 0.53920889, Test Loss: 1.29230440, AUC: 0.5749, Accuracy: 0.5556\n",
      "Ventana 101, Época: 5, Train Loss: 0.43130067, Test Loss: 1.10680306, AUC: 0.5915, Accuracy: 0.5513\n",
      "Ventana 101, Época: 10, Train Loss: 0.33307821, Test Loss: 1.07956743, AUC: 0.5825, Accuracy: 0.5385\n",
      "Ventana 101, Época: 12, Train Loss: 0.31529129, Test Loss: 1.05635023, AUC: 0.5835, Accuracy: 0.5684\n",
      "Early stopping en la ventana 101, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 101\n",
      "-------------------\n",
      "Ventana 102 de 153\n",
      "Entrenando con semanas: [101 102 103 104 105 106 107 108 109 110], testeando en semanas [111 112 113], len train: 530, len test: 267, porcentaje: 0.66\n",
      "Iniciando ventana 102 con pesos de la ventana anterior\n",
      "Ventana 102, Época: 0, Train Loss: 0.50524908, Test Loss: 0.95014369, AUC: 0.6183, Accuracy: 0.5618\n",
      "Ventana 102, Época: 5, Train Loss: 0.36549672, Test Loss: 0.97778296, AUC: 0.6040, Accuracy: 0.5730\n",
      "Ventana 102, Época: 10, Train Loss: 0.30396360, Test Loss: 0.91313732, AUC: 0.6135, Accuracy: 0.5805\n",
      "Ventana 102, Época: 14, Train Loss: 0.23407833, Test Loss: 0.99594104, AUC: 0.6029, Accuracy: 0.5730\n",
      "Early stopping en la ventana 102, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 102\n",
      "-------------------\n",
      "Ventana 103 de 153\n",
      "Entrenando con semanas: [102 103 104 105 106 107 108 109 110 111], testeando en semanas [112 113 114], len train: 569, len test: 227, porcentaje: 0.71\n",
      "Iniciando ventana 103 con pesos de la ventana anterior\n",
      "Ventana 103, Época: 0, Train Loss: 0.35150540, Test Loss: 0.94018501, AUC: 0.5989, Accuracy: 0.5463\n",
      "Ventana 103, Época: 5, Train Loss: 0.26663771, Test Loss: 1.00429773, AUC: 0.6149, Accuracy: 0.5595\n",
      "Early stopping en la ventana 103, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 103\n",
      "-------------------\n",
      "Ventana 104 de 153\n",
      "Entrenando con semanas: [103 104 105 106 107 108 109 110 111 112], testeando en semanas [113 114 115], len train: 652, len test: 156, porcentaje: 0.81\n",
      "Iniciando ventana 104 con pesos de la ventana anterior\n",
      "Ventana 104, Época: 0, Train Loss: 0.44914714, Test Loss: 0.93591565, AUC: 0.6517, Accuracy: 0.5962\n",
      "Ventana 104, Época: 5, Train Loss: 0.32088560, Test Loss: 0.91551250, AUC: 0.6688, Accuracy: 0.5897\n",
      "Ventana 104, Época: 9, Train Loss: 0.24841873, Test Loss: 0.92259753, AUC: 0.6793, Accuracy: 0.5962\n",
      "Early stopping en la ventana 104, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 104\n",
      "-------------------\n",
      "Ventana 105 de 153\n",
      "Entrenando con semanas: [104 105 106 107 108 109 110 111 112 113], testeando en semanas [114 115 116], len train: 701, len test: 157, porcentaje: 0.82\n",
      "Iniciando ventana 105 con pesos de la ventana anterior\n",
      "Ventana 105, Época: 0, Train Loss: 0.42486545, Test Loss: 1.05068839, AUC: 0.6299, Accuracy: 0.5860\n",
      "Ventana 105, Época: 5, Train Loss: 0.33757490, Test Loss: 1.04810417, AUC: 0.6209, Accuracy: 0.5796\n",
      "Ventana 105, Época: 10, Train Loss: 0.27718684, Test Loss: 1.00443327, AUC: 0.6333, Accuracy: 0.5478\n",
      "Ventana 105, Época: 15, Train Loss: 0.22707228, Test Loss: 1.07947481, AUC: 0.6312, Accuracy: 0.5669\n",
      "Early stopping en la ventana 105, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 105\n",
      "-------------------\n",
      "Ventana 106 de 153\n",
      "Entrenando con semanas: [105 106 107 108 109 110 111 112 113 114], testeando en semanas [115 116 117], len train: 605, len test: 182, porcentaje: 0.77\n",
      "Iniciando ventana 106 con pesos de la ventana anterior\n",
      "Ventana 106, Época: 0, Train Loss: 0.29641753, Test Loss: 0.97917831, AUC: 0.6477, Accuracy: 0.5769\n",
      "Ventana 106, Época: 5, Train Loss: 0.24349955, Test Loss: 1.07999361, AUC: 0.6375, Accuracy: 0.5824\n",
      "Early stopping en la ventana 106, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 106\n",
      "-------------------\n",
      "Ventana 107 de 153\n",
      "Entrenando con semanas: [106 107 108 109 110 111 112 113 114 115], testeando en semanas [116 117 118], len train: 524, len test: 201, porcentaje: 0.72\n",
      "Iniciando ventana 107 con pesos de la ventana anterior\n",
      "Ventana 107, Época: 0, Train Loss: 0.34987184, Test Loss: 1.21804428, AUC: 0.5790, Accuracy: 0.5124\n",
      "Ventana 107, Época: 5, Train Loss: 0.25927800, Test Loss: 1.29414570, AUC: 0.5685, Accuracy: 0.5124\n",
      "Ventana 107, Época: 7, Train Loss: 0.22883424, Test Loss: 1.36905921, AUC: 0.5787, Accuracy: 0.5075\n",
      "Early stopping en la ventana 107, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 107\n",
      "-------------------\n",
      "Ventana 108 de 153\n",
      "Entrenando con semanas: [107 108 109 110 111 112 113 114 115 116], testeando en semanas [117 118 119], len train: 625, len test: 172, porcentaje: 0.78\n",
      "Iniciando ventana 108 con pesos de la ventana anterior\n",
      "Ventana 108, Época: 0, Train Loss: 0.44784486, Test Loss: 1.17590690, AUC: 0.5924, Accuracy: 0.5523\n",
      "Ventana 108, Época: 5, Train Loss: 0.37588862, Test Loss: 1.09189785, AUC: 0.5935, Accuracy: 0.5465\n",
      "Ventana 108, Época: 6, Train Loss: 0.38653550, Test Loss: 1.08388162, AUC: 0.5661, Accuracy: 0.5349\n",
      "Early stopping en la ventana 108, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 108\n",
      "-------------------\n",
      "Ventana 109 de 153\n",
      "Entrenando con semanas: [108 109 110 111 112 113 114 115 116 117], testeando en semanas [118 119 120], len train: 648, len test: 190, porcentaje: 0.77\n",
      "Iniciando ventana 109 con pesos de la ventana anterior\n",
      "Ventana 109, Época: 0, Train Loss: 0.43447396, Test Loss: 1.12170863, AUC: 0.5654, Accuracy: 0.5526\n",
      "Ventana 109, Época: 5, Train Loss: 0.37076968, Test Loss: 0.99241918, AUC: 0.5666, Accuracy: 0.5368\n",
      "Ventana 109, Época: 10, Train Loss: 0.32648233, Test Loss: 0.95236707, AUC: 0.5898, Accuracy: 0.5316\n",
      "Ventana 109, Época: 12, Train Loss: 0.27158615, Test Loss: 0.93504316, AUC: 0.6007, Accuracy: 0.5474\n",
      "Early stopping en la ventana 109, época 12\n",
      "Mejor modelo guardado en la época  7 para la ventana 109\n",
      "-------------------\n",
      "Ventana 110 de 153\n",
      "Entrenando con semanas: [109 110 111 112 113 114 115 116 117 118], testeando en semanas [119 120 121], len train: 657, len test: 138, porcentaje: 0.83\n",
      "Iniciando ventana 110 con pesos de la ventana anterior\n",
      "Ventana 110, Época: 0, Train Loss: 0.41124597, Test Loss: 0.79650933, AUC: 0.6617, Accuracy: 0.6014\n",
      "Ventana 110, Época: 5, Train Loss: 0.33074650, Test Loss: 0.93081689, AUC: 0.6196, Accuracy: 0.5362\n",
      "Early stopping en la ventana 110, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 110\n",
      "-------------------\n",
      "Ventana 111 de 153\n",
      "Entrenando con semanas: [110 111 112 113 114 115 116 117 118 119], testeando en semanas [120 121 122], len train: 674, len test: 68, porcentaje: 0.91\n",
      "Iniciando ventana 111 con pesos de la ventana anterior\n",
      "Ventana 111, Época: 0, Train Loss: 0.45636594, Test Loss: 0.87213528, AUC: 0.6474, Accuracy: 0.6029\n",
      "Ventana 111, Época: 5, Train Loss: 0.38731900, Test Loss: 0.71144277, AUC: 0.7289, Accuracy: 0.6471\n",
      "Ventana 111, Época: 10, Train Loss: 0.28999099, Test Loss: 0.80976176, AUC: 0.6798, Accuracy: 0.6324\n",
      "Early stopping en la ventana 111, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 111\n",
      "-------------------\n",
      "Ventana 112 de 153\n",
      "Entrenando con semanas: [111 112 113 114 115 116 117 118 119 120], testeando en semanas [121 122 123], len train: 649, len test: 138, porcentaje: 0.82\n",
      "Iniciando ventana 112 con pesos de la ventana anterior\n",
      "Ventana 112, Época: 0, Train Loss: 0.41809699, Test Loss: 0.90800852, AUC: 0.6106, Accuracy: 0.5942\n",
      "Ventana 112, Época: 5, Train Loss: 0.31262332, Test Loss: 0.93410224, AUC: 0.6066, Accuracy: 0.6014\n",
      "Ventana 112, Época: 8, Train Loss: 0.36925054, Test Loss: 0.92455029, AUC: 0.6271, Accuracy: 0.6232\n",
      "Early stopping en la ventana 112, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 112\n",
      "-------------------\n",
      "Ventana 113 de 153\n",
      "Entrenando con semanas: [112 113 114 115 116 117 118 119 120 121], testeando en semanas [122 123 124], len train: 601, len test: 233, porcentaje: 0.72\n",
      "Iniciando ventana 113 con pesos de la ventana anterior\n",
      "Ventana 113, Época: 0, Train Loss: 0.36773488, Test Loss: 0.80751294, AUC: 0.6919, Accuracy: 0.6567\n",
      "Ventana 113, Época: 5, Train Loss: 0.29823488, Test Loss: 0.92111415, AUC: 0.6621, Accuracy: 0.6180\n",
      "Early stopping en la ventana 113, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 113\n",
      "-------------------\n",
      "Ventana 114 de 153\n",
      "Entrenando con semanas: [113 114 115 116 117 118 119 120 121 122], testeando en semanas [123 124 125], len train: 508, len test: 231, porcentaje: 0.69\n",
      "Iniciando ventana 114 con pesos de la ventana anterior\n",
      "Ventana 114, Época: 0, Train Loss: 0.39161459, Test Loss: 0.84013188, AUC: 0.6838, Accuracy: 0.6234\n",
      "Ventana 114, Época: 5, Train Loss: 0.28740683, Test Loss: 0.79721081, AUC: 0.7084, Accuracy: 0.6667\n",
      "Ventana 114, Época: 10, Train Loss: 0.21473704, Test Loss: 0.89693916, AUC: 0.6937, Accuracy: 0.6494\n",
      "Ventana 114, Época: 11, Train Loss: 0.22769812, Test Loss: 0.92278671, AUC: 0.7089, Accuracy: 0.6320\n",
      "Early stopping en la ventana 114, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 114\n",
      "-------------------\n",
      "Ventana 115 de 153\n",
      "Entrenando con semanas: [114 115 116 117 118 119 120 121 122 123], testeando en semanas [124 125 126], len train: 520, len test: 119, porcentaje: 0.81\n",
      "Iniciando ventana 115 con pesos de la ventana anterior\n",
      "Ventana 115, Época: 0, Train Loss: 0.44978067, Test Loss: 0.78128552, AUC: 0.7457, Accuracy: 0.6555\n",
      "Ventana 115, Época: 5, Train Loss: 0.33187848, Test Loss: 0.81985676, AUC: 0.7483, Accuracy: 0.6975\n",
      "Ventana 115, Época: 7, Train Loss: 0.31316188, Test Loss: 0.77414435, AUC: 0.7690, Accuracy: 0.7059\n",
      "Early stopping en la ventana 115, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 115\n",
      "-------------------\n",
      "Ventana 116 de 153\n",
      "Entrenando con semanas: [115 116 117 118 119 120 121 122 123 124], testeando en semanas [125 126 127], len train: 607, len test: 73, porcentaje: 0.89\n",
      "Iniciando ventana 116 con pesos de la ventana anterior\n",
      "Ventana 116, Época: 0, Train Loss: 0.43782780, Test Loss: 1.12270832, AUC: 0.5617, Accuracy: 0.5616\n",
      "Ventana 116, Época: 5, Train Loss: 0.31921086, Test Loss: 1.07627344, AUC: 0.6241, Accuracy: 0.5479\n",
      "Ventana 116, Época: 10, Train Loss: 0.24576332, Test Loss: 1.05527735, AUC: 0.6541, Accuracy: 0.6027\n",
      "Ventana 116, Época: 15, Train Loss: 0.18686667, Test Loss: 1.20154798, AUC: 0.6504, Accuracy: 0.6438\n",
      "Early stopping en la ventana 116, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 116\n",
      "-------------------\n",
      "Ventana 117 de 153\n",
      "Entrenando con semanas: [116 117 118 119 120 121 122 123 124 125], testeando en semanas [126 127 128], len train: 583, len test: 135, porcentaje: 0.81\n",
      "Iniciando ventana 117 con pesos de la ventana anterior\n",
      "Ventana 117, Época: 0, Train Loss: 0.25843400, Test Loss: 1.22232676, AUC: 0.5869, Accuracy: 0.5704\n",
      "Ventana 117, Época: 5, Train Loss: 0.19524334, Test Loss: 1.41544247, AUC: 0.5871, Accuracy: 0.5852\n",
      "Early stopping en la ventana 117, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 117\n",
      "-------------------\n",
      "Ventana 118 de 153\n",
      "Entrenando con semanas: [117 118 119 120 121 122 123 124 125 126], testeando en semanas [127 128 129], len train: 482, len test: 184, porcentaje: 0.72\n",
      "Iniciando ventana 118 con pesos de la ventana anterior\n",
      "Ventana 118, Época: 0, Train Loss: 0.25696403, Test Loss: 1.15931535, AUC: 0.6075, Accuracy: 0.5815\n",
      "Ventana 118, Época: 5, Train Loss: 0.15886001, Test Loss: 1.30320227, AUC: 0.6121, Accuracy: 0.5761\n",
      "Early stopping en la ventana 118, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 118\n",
      "-------------------\n",
      "Ventana 119 de 153\n",
      "Entrenando con semanas: [118 119 120 121 122 123 124 125 126 127], testeando en semanas [128 129 130], len train: 498, len test: 235, porcentaje: 0.68\n",
      "Iniciando ventana 119 con pesos de la ventana anterior\n",
      "Ventana 119, Época: 0, Train Loss: 0.33082145, Test Loss: 1.15497077, AUC: 0.5953, Accuracy: 0.5574\n",
      "Ventana 119, Época: 5, Train Loss: 0.24340110, Test Loss: 1.11981142, AUC: 0.6251, Accuracy: 0.5787\n",
      "Ventana 119, Época: 10, Train Loss: 0.20292944, Test Loss: 1.08944201, AUC: 0.6374, Accuracy: 0.6085\n",
      "Ventana 119, Época: 15, Train Loss: 0.16399591, Test Loss: 1.19457388, AUC: 0.6230, Accuracy: 0.5957\n",
      "Early stopping en la ventana 119, época 15\n",
      "Mejor modelo guardado en la época  10 para la ventana 119\n",
      "-------------------\n",
      "Ventana 120 de 153\n",
      "Entrenando con semanas: [119 120 121 122 123 124 125 126 127 128], testeando en semanas [129 130 131], len train: 517, len test: 187, porcentaje: 0.73\n",
      "Iniciando ventana 120 con pesos de la ventana anterior\n",
      "Ventana 120, Época: 0, Train Loss: 0.50296599, Test Loss: 1.08914769, AUC: 0.6418, Accuracy: 0.6310\n",
      "Ventana 120, Época: 5, Train Loss: 0.27153283, Test Loss: 1.21500874, AUC: 0.5973, Accuracy: 0.5722\n",
      "Early stopping en la ventana 120, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 120\n",
      "-------------------\n",
      "Ventana 121 de 153\n",
      "Entrenando con semanas: [120 121 122 123 124 125 126 127 128 129], testeando en semanas [130 131 132], len train: 494, len test: 226, porcentaje: 0.69\n",
      "Iniciando ventana 121 con pesos de la ventana anterior\n",
      "Ventana 121, Época: 0, Train Loss: 0.44175035, Test Loss: 1.26985371, AUC: 0.6102, Accuracy: 0.5752\n",
      "Ventana 121, Época: 5, Train Loss: 0.31378415, Test Loss: 1.10640061, AUC: 0.6233, Accuracy: 0.5973\n",
      "Ventana 121, Época: 10, Train Loss: 0.26365638, Test Loss: 1.10250926, AUC: 0.6342, Accuracy: 0.5929\n",
      "Ventana 121, Época: 13, Train Loss: 0.24287510, Test Loss: 1.07725108, AUC: 0.6179, Accuracy: 0.5708\n",
      "Early stopping en la ventana 121, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 121\n",
      "-------------------\n",
      "Ventana 122 de 153\n",
      "Entrenando con semanas: [121 122 123 124 125 126 127 128 129 130], testeando en semanas [131 132 133], len train: 543, len test: 149, porcentaje: 0.78\n",
      "Iniciando ventana 122 con pesos de la ventana anterior\n",
      "Ventana 122, Época: 0, Train Loss: 0.40943685, Test Loss: 1.00249243, AUC: 0.6407, Accuracy: 0.6376\n",
      "Ventana 122, Época: 5, Train Loss: 0.32366934, Test Loss: 0.93507582, AUC: 0.6576, Accuracy: 0.6577\n",
      "Ventana 122, Época: 9, Train Loss: 0.24814962, Test Loss: 0.95396894, AUC: 0.6537, Accuracy: 0.6242\n",
      "Early stopping en la ventana 122, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 122\n",
      "-------------------\n",
      "Ventana 123 de 153\n",
      "Entrenando con semanas: [122 123 124 125 126 127 128 129 130 131], testeando en semanas [132 133 134], len train: 566, len test: 148, porcentaje: 0.79\n",
      "Iniciando ventana 123 con pesos de la ventana anterior\n",
      "Ventana 123, Época: 0, Train Loss: 0.36741492, Test Loss: 0.91136849, AUC: 0.6625, Accuracy: 0.6284\n",
      "Ventana 123, Época: 5, Train Loss: 0.23540939, Test Loss: 0.97798324, AUC: 0.6460, Accuracy: 0.6149\n",
      "Ventana 123, Época: 7, Train Loss: 0.21037801, Test Loss: 0.93173838, AUC: 0.6590, Accuracy: 0.6419\n",
      "Early stopping en la ventana 123, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 123\n",
      "-------------------\n",
      "Ventana 124 de 153\n",
      "Entrenando con semanas: [123 124 125 126 127 128 129 130 131 132], testeando en semanas [133 134 135], len train: 652, len test: 117, porcentaje: 0.85\n",
      "Iniciando ventana 124 con pesos de la ventana anterior\n",
      "Ventana 124, Época: 0, Train Loss: 0.38182214, Test Loss: 1.04279542, AUC: 0.6772, Accuracy: 0.6410\n",
      "Ventana 124, Época: 5, Train Loss: 0.28778303, Test Loss: 1.10332668, AUC: 0.6540, Accuracy: 0.6496\n",
      "Ventana 124, Época: 8, Train Loss: 0.26088828, Test Loss: 1.12471938, AUC: 0.6696, Accuracy: 0.6496\n",
      "Early stopping en la ventana 124, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 124\n",
      "-------------------\n",
      "Ventana 125 de 153\n",
      "Entrenando con semanas: [124 125 126 127 128 129 130 131 132 133], testeando en semanas [134 135 136], len train: 554, len test: 135, porcentaje: 0.80\n",
      "Iniciando ventana 125 con pesos de la ventana anterior\n",
      "Ventana 125, Época: 0, Train Loss: 0.36076403, Test Loss: 1.20417070, AUC: 0.5896, Accuracy: 0.5630\n",
      "Ventana 125, Época: 5, Train Loss: 0.26199132, Test Loss: 1.31747401, AUC: 0.5856, Accuracy: 0.5259\n",
      "Early stopping en la ventana 125, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 125\n",
      "-------------------\n",
      "Ventana 126 de 153\n",
      "Entrenando con semanas: [125 126 127 128 129 130 131 132 133 134], testeando en semanas [135 136 137], len train: 481, len test: 214, porcentaje: 0.69\n",
      "Iniciando ventana 126 con pesos de la ventana anterior\n",
      "Ventana 126, Época: 0, Train Loss: 0.39420772, Test Loss: 1.20506024, AUC: 0.5973, Accuracy: 0.5654\n",
      "Ventana 126, Época: 5, Train Loss: 0.27443284, Test Loss: 1.22426271, AUC: 0.6035, Accuracy: 0.5748\n",
      "Ventana 126, Época: 9, Train Loss: 0.21330570, Test Loss: 1.26566696, AUC: 0.5937, Accuracy: 0.5841\n",
      "Early stopping en la ventana 126, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 126\n",
      "-------------------\n",
      "Ventana 127 de 153\n",
      "Entrenando con semanas: [126 127 128 129 130 131 132 133 134 135], testeando en semanas [136 137 138], len train: 538, len test: 165, porcentaje: 0.77\n",
      "Iniciando ventana 127 con pesos de la ventana anterior\n",
      "Ventana 127, Época: 0, Train Loss: 0.35984516, Test Loss: 1.24066925, AUC: 0.5905, Accuracy: 0.5515\n",
      "Ventana 127, Época: 5, Train Loss: 0.28856981, Test Loss: 1.12308383, AUC: 0.6130, Accuracy: 0.5515\n",
      "Ventana 127, Época: 10, Train Loss: 0.21431081, Test Loss: 1.18277764, AUC: 0.6151, Accuracy: 0.5576\n",
      "Early stopping en la ventana 127, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 127\n",
      "-------------------\n",
      "Ventana 128 de 153\n",
      "Entrenando con semanas: [127 128 129 130 131 132 133 134 135 136], testeando en semanas [137 138 139], len train: 570, len test: 228, porcentaje: 0.71\n",
      "Iniciando ventana 128 con pesos de la ventana anterior\n",
      "Ventana 128, Época: 0, Train Loss: 0.35081947, Test Loss: 1.11705136, AUC: 0.6163, Accuracy: 0.6096\n",
      "Ventana 128, Época: 5, Train Loss: 0.24301498, Test Loss: 1.11016512, AUC: 0.5946, Accuracy: 0.5351\n",
      "Ventana 128, Época: 9, Train Loss: 0.18639474, Test Loss: 1.12796533, AUC: 0.6062, Accuracy: 0.5789\n",
      "Early stopping en la ventana 128, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 128\n",
      "-------------------\n",
      "Ventana 129 de 153\n",
      "Entrenando con semanas: [128 129 130 131 132 133 134 135 136 137], testeando en semanas [138 139 140], len train: 622, len test: 148, porcentaje: 0.81\n",
      "Iniciando ventana 129 con pesos de la ventana anterior\n",
      "Ventana 129, Época: 0, Train Loss: 0.36721036, Test Loss: 1.18528306, AUC: 0.5658, Accuracy: 0.5541\n",
      "Ventana 129, Época: 5, Train Loss: 0.33604687, Test Loss: 1.10038948, AUC: 0.6053, Accuracy: 0.5676\n",
      "Ventana 129, Época: 10, Train Loss: 0.26910079, Test Loss: 1.13237774, AUC: 0.5670, Accuracy: 0.5608\n",
      "Ventana 129, Época: 11, Train Loss: 0.31505194, Test Loss: 1.13125384, AUC: 0.5762, Accuracy: 0.5608\n",
      "Early stopping en la ventana 129, época 11\n",
      "Mejor modelo guardado en la época  6 para la ventana 129\n",
      "-------------------\n",
      "Ventana 130 de 153\n",
      "Entrenando con semanas: [129 130 131 132 133 134 135 136 137 138], testeando en semanas [139 140 141], len train: 568, len test: 256, porcentaje: 0.69\n",
      "Iniciando ventana 130 con pesos de la ventana anterior\n",
      "Ventana 130, Época: 0, Train Loss: 0.36171517, Test Loss: 1.15474796, AUC: 0.5737, Accuracy: 0.5391\n",
      "Ventana 130, Época: 5, Train Loss: 0.29906911, Test Loss: 1.18297350, AUC: 0.5547, Accuracy: 0.5547\n",
      "Ventana 130, Época: 6, Train Loss: 0.23102346, Test Loss: 1.16289163, AUC: 0.5522, Accuracy: 0.5312\n",
      "Early stopping en la ventana 130, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 130\n",
      "-------------------\n",
      "Ventana 131 de 153\n",
      "Entrenando con semanas: [130 131 132 133 134 135 136 137 138 139], testeando en semanas [140 141 142], len train: 614, len test: 243, porcentaje: 0.72\n",
      "Iniciando ventana 131 con pesos de la ventana anterior\n",
      "Ventana 131, Época: 0, Train Loss: 0.44235781, Test Loss: 1.07704651, AUC: 0.6082, Accuracy: 0.5432\n",
      "Ventana 131, Época: 5, Train Loss: 0.32703716, Test Loss: 1.02398407, AUC: 0.6008, Accuracy: 0.5844\n",
      "Ventana 131, Época: 10, Train Loss: 0.25949046, Test Loss: 1.02608645, AUC: 0.6029, Accuracy: 0.5720\n",
      "Ventana 131, Época: 13, Train Loss: 0.21053690, Test Loss: 1.02832806, AUC: 0.6086, Accuracy: 0.5761\n",
      "Early stopping en la ventana 131, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 131\n",
      "-------------------\n",
      "Ventana 132 de 153\n",
      "Entrenando con semanas: [131 132 133 134 135 136 137 138 139 140], testeando en semanas [141 142 143], len train: 535, len test: 230, porcentaje: 0.70\n",
      "Iniciando ventana 132 con pesos de la ventana anterior\n",
      "Ventana 132, Época: 0, Train Loss: 0.33258194, Test Loss: 1.01128650, AUC: 0.5924, Accuracy: 0.5522\n",
      "Ventana 132, Época: 5, Train Loss: 0.23803322, Test Loss: 1.07033980, AUC: 0.6111, Accuracy: 0.5870\n",
      "Early stopping en la ventana 132, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 132\n",
      "-------------------\n",
      "Ventana 133 de 153\n",
      "Entrenando con semanas: [132 133 134 135 136 137 138 139 140 141], testeando en semanas [142 143 144], len train: 637, len test: 126, porcentaje: 0.83\n",
      "Iniciando ventana 133 con pesos de la ventana anterior\n",
      "Ventana 133, Época: 0, Train Loss: 0.47241843, Test Loss: 0.94277352, AUC: 0.6986, Accuracy: 0.6270\n",
      "Ventana 133, Época: 5, Train Loss: 0.38623980, Test Loss: 0.86918807, AUC: 0.7004, Accuracy: 0.6667\n",
      "Ventana 133, Época: 10, Train Loss: 0.30500573, Test Loss: 0.86298251, AUC: 0.6961, Accuracy: 0.6349\n",
      "Ventana 133, Época: 15, Train Loss: 0.25307512, Test Loss: 0.92468518, AUC: 0.6921, Accuracy: 0.6508\n",
      "Ventana 133, Época: 18, Train Loss: 0.22687189, Test Loss: 0.98228478, AUC: 0.6840, Accuracy: 0.6349\n",
      "Early stopping en la ventana 133, época 18\n",
      "Mejor modelo guardado en la época  13 para la ventana 133\n",
      "-------------------\n",
      "Ventana 134 de 153\n",
      "Entrenando con semanas: [133 134 135 136 137 138 139 140 141 142], testeando en semanas [143 144 145], len train: 631, len test: 91, porcentaje: 0.87\n",
      "Iniciando ventana 134 con pesos de la ventana anterior\n",
      "Ventana 134, Época: 0, Train Loss: 0.36566567, Test Loss: 1.30294573, AUC: 0.5945, Accuracy: 0.5714\n",
      "Ventana 134, Época: 5, Train Loss: 0.33243683, Test Loss: 1.23677814, AUC: 0.6424, Accuracy: 0.6374\n",
      "Ventana 134, Época: 10, Train Loss: 0.29754412, Test Loss: 1.23791957, AUC: 0.6100, Accuracy: 0.6154\n",
      "Early stopping en la ventana 134, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 134\n",
      "-------------------\n",
      "Ventana 135 de 153\n",
      "Entrenando con semanas: [134 135 136 137 138 139 140 141 142 143], testeando en semanas [144 145 146], len train: 616, len test: 191, porcentaje: 0.76\n",
      "Iniciando ventana 135 con pesos de la ventana anterior\n",
      "Ventana 135, Época: 0, Train Loss: 0.34997544, Test Loss: 1.16999292, AUC: 0.6191, Accuracy: 0.5812\n",
      "Ventana 135, Época: 5, Train Loss: 0.25569370, Test Loss: 1.07667816, AUC: 0.6017, Accuracy: 0.5759\n",
      "Ventana 135, Época: 9, Train Loss: 0.23576003, Test Loss: 1.16718626, AUC: 0.6226, Accuracy: 0.5812\n",
      "Early stopping en la ventana 135, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 135\n",
      "-------------------\n",
      "Ventana 136 de 153\n",
      "Entrenando con semanas: [135 136 137 138 139 140 141 142 143 144], testeando en semanas [145 146 147], len train: 615, len test: 277, porcentaje: 0.69\n",
      "Iniciando ventana 136 con pesos de la ventana anterior\n",
      "Ventana 136, Época: 0, Train Loss: 0.29572108, Test Loss: 0.94474578, AUC: 0.7073, Accuracy: 0.6173\n",
      "Ventana 136, Época: 5, Train Loss: 0.20902643, Test Loss: 1.01665652, AUC: 0.7076, Accuracy: 0.6534\n",
      "Early stopping en la ventana 136, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 136\n",
      "-------------------\n",
      "Ventana 137 de 153\n",
      "Entrenando con semanas: [136 137 138 139 140 141 142 143 144 145], testeando en semanas [146 147 148], len train: 605, len test: 241, porcentaje: 0.72\n",
      "Iniciando ventana 137 con pesos de la ventana anterior\n",
      "Ventana 137, Época: 0, Train Loss: 0.38504723, Test Loss: 0.88178331, AUC: 0.7350, Accuracy: 0.6515\n",
      "Ventana 137, Época: 5, Train Loss: 0.26381519, Test Loss: 0.88792646, AUC: 0.7411, Accuracy: 0.6598\n",
      "Ventana 137, Época: 10, Train Loss: 0.22081047, Test Loss: 0.87155849, AUC: 0.7284, Accuracy: 0.6598\n",
      "Ventana 137, Época: 14, Train Loss: 0.16652398, Test Loss: 0.87054229, AUC: 0.7478, Accuracy: 0.6432\n",
      "Early stopping en la ventana 137, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 137\n",
      "-------------------\n",
      "Ventana 138 de 153\n",
      "Entrenando con semanas: [137 138 139 140 141 142 143 144 145 146], testeando en semanas [147 148 149], len train: 672, len test: 160, porcentaje: 0.81\n",
      "Iniciando ventana 138 con pesos de la ventana anterior\n",
      "Ventana 138, Época: 0, Train Loss: 0.34021220, Test Loss: 0.80047667, AUC: 0.7823, Accuracy: 0.7188\n",
      "Ventana 138, Época: 5, Train Loss: 0.22285417, Test Loss: 0.80447471, AUC: 0.7657, Accuracy: 0.7063\n",
      "Ventana 138, Época: 10, Train Loss: 0.20421630, Test Loss: 0.72824782, AUC: 0.7854, Accuracy: 0.7000\n",
      "Ventana 138, Época: 14, Train Loss: 0.17112951, Test Loss: 0.81652224, AUC: 0.7805, Accuracy: 0.7250\n",
      "Early stopping en la ventana 138, época 14\n",
      "Mejor modelo guardado en la época  9 para la ventana 138\n",
      "-------------------\n",
      "Ventana 139 de 153\n",
      "Entrenando con semanas: [138 139 140 141 142 143 144 145 146 147], testeando en semanas [148 149 150], len train: 678, len test: 68, porcentaje: 0.91\n",
      "Iniciando ventana 139 con pesos de la ventana anterior\n",
      "Ventana 139, Época: 0, Train Loss: 0.29936206, Test Loss: 1.13097107, AUC: 0.6319, Accuracy: 0.6324\n",
      "Ventana 139, Época: 5, Train Loss: 0.19297820, Test Loss: 1.11266780, AUC: 0.6632, Accuracy: 0.6471\n",
      "Ventana 139, Época: 9, Train Loss: 0.13738768, Test Loss: 1.12942314, AUC: 0.6762, Accuracy: 0.6324\n",
      "Early stopping en la ventana 139, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 139\n",
      "-------------------\n",
      "Ventana 140 de 153\n",
      "Entrenando con semanas: [139 140 141 142 143 144 145 146 147 148], testeando en semanas [149 150 151], len train: 681, len test: 102, porcentaje: 0.87\n",
      "Iniciando ventana 140 con pesos de la ventana anterior\n",
      "Ventana 140, Época: 0, Train Loss: 0.21955410, Test Loss: 1.24024153, AUC: 0.5791, Accuracy: 0.5588\n",
      "Ventana 140, Época: 5, Train Loss: 0.15166415, Test Loss: 1.32261765, AUC: 0.5926, Accuracy: 0.5490\n",
      "Early stopping en la ventana 140, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 140\n",
      "-------------------\n",
      "Ventana 141 de 153\n",
      "Entrenando con semanas: [140 141 142 143 144 145 146 147 148 149], testeando en semanas [150 151 152], len train: 604, len test: 143, porcentaje: 0.81\n",
      "Iniciando ventana 141 con pesos de la ventana anterior\n",
      "Ventana 141, Época: 0, Train Loss: 0.26598382, Test Loss: 1.70509684, AUC: 0.4755, Accuracy: 0.4825\n",
      "Ventana 141, Época: 5, Train Loss: 0.15990566, Test Loss: 1.71011102, AUC: 0.4865, Accuracy: 0.4965\n",
      "Ventana 141, Época: 7, Train Loss: 0.13777795, Test Loss: 1.68242502, AUC: 0.5086, Accuracy: 0.5035\n",
      "Early stopping en la ventana 141, época 7\n",
      "Mejor modelo guardado en la época  2 para la ventana 141\n",
      "-------------------\n",
      "Ventana 142 de 153\n",
      "Entrenando con semanas: [141 142 143 144 145 146 147 148 149 150], testeando en semanas [151 152 153], len train: 598, len test: 185, porcentaje: 0.76\n",
      "Iniciando ventana 142 con pesos de la ventana anterior\n",
      "Ventana 142, Época: 0, Train Loss: 0.28003067, Test Loss: 1.70220315, AUC: 0.5054, Accuracy: 0.5405\n",
      "Ventana 142, Época: 5, Train Loss: 0.14106877, Test Loss: 1.79798865, AUC: 0.4876, Accuracy: 0.4811\n",
      "Early stopping en la ventana 142, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 142\n",
      "-------------------\n",
      "Ventana 143 de 153\n",
      "Entrenando con semanas: [142 143 144 145 146 147 148 149 150 151], testeando en semanas [152 153 154], len train: 527, len test: 237, porcentaje: 0.69\n",
      "Iniciando ventana 143 con pesos de la ventana anterior\n",
      "Ventana 143, Época: 0, Train Loss: 0.35697043, Test Loss: 1.65252614, AUC: 0.5286, Accuracy: 0.5232\n",
      "Ventana 143, Época: 5, Train Loss: 0.25660402, Test Loss: 1.56565428, AUC: 0.5328, Accuracy: 0.5527\n",
      "Ventana 143, Época: 10, Train Loss: 0.20197828, Test Loss: 1.59446764, AUC: 0.5208, Accuracy: 0.5021\n",
      "Early stopping en la ventana 143, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 143\n",
      "-------------------\n",
      "Ventana 144 de 153\n",
      "Entrenando con semanas: [143 144 145 146 147 148 149 150 151 152], testeando en semanas [153 154 155], len train: 504, len test: 275, porcentaje: 0.65\n",
      "Iniciando ventana 144 con pesos de la ventana anterior\n",
      "Ventana 144, Época: 0, Train Loss: 0.46069586, Test Loss: 1.22104275, AUC: 0.6539, Accuracy: 0.6291\n",
      "Ventana 144, Época: 5, Train Loss: 0.32110253, Test Loss: 1.14772856, AUC: 0.6442, Accuracy: 0.5964\n",
      "Ventana 144, Época: 10, Train Loss: 0.20260917, Test Loss: 1.22337401, AUC: 0.6328, Accuracy: 0.5673\n",
      "Early stopping en la ventana 144, época 10\n",
      "Mejor modelo guardado en la época  5 para la ventana 144\n",
      "-------------------\n",
      "Ventana 145 de 153\n",
      "Entrenando con semanas: [144 145 146 147 148 149 150 151 152 153], testeando en semanas [154 155 156], len train: 553, len test: 226, porcentaje: 0.71\n",
      "Iniciando ventana 145 con pesos de la ventana anterior\n",
      "Ventana 145, Época: 0, Train Loss: 0.41533738, Test Loss: 1.11666119, AUC: 0.6689, Accuracy: 0.6150\n",
      "Ventana 145, Época: 5, Train Loss: 0.26104778, Test Loss: 1.15692115, AUC: 0.6467, Accuracy: 0.5929\n",
      "Early stopping en la ventana 145, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 145\n",
      "-------------------\n",
      "Ventana 146 de 153\n",
      "Entrenando con semanas: [145 146 147 148 149 150 151 152 153 154], testeando en semanas [155 156 157], len train: 638, len test: 191, porcentaje: 0.77\n",
      "Iniciando ventana 146 con pesos de la ventana anterior\n",
      "Ventana 146, Época: 0, Train Loss: 0.51923257, Test Loss: 1.05904496, AUC: 0.6833, Accuracy: 0.6440\n",
      "Ventana 146, Época: 5, Train Loss: 0.33378631, Test Loss: 0.94792145, AUC: 0.6707, Accuracy: 0.6283\n",
      "Ventana 146, Época: 10, Train Loss: 0.24746375, Test Loss: 0.95702559, AUC: 0.6734, Accuracy: 0.6021\n",
      "Ventana 146, Época: 13, Train Loss: 0.22074251, Test Loss: 0.94160467, AUC: 0.6929, Accuracy: 0.6126\n",
      "Early stopping en la ventana 146, época 13\n",
      "Mejor modelo guardado en la época  8 para la ventana 146\n",
      "-------------------\n",
      "Ventana 147 de 153\n",
      "Entrenando con semanas: [146 147 148 149 150 151 152 153 154 155], testeando en semanas [156 157 158], len train: 688, len test: 186, porcentaje: 0.79\n",
      "Iniciando ventana 147 con pesos de la ventana anterior\n",
      "Ventana 147, Época: 0, Train Loss: 0.38578334, Test Loss: 1.14742076, AUC: 0.6044, Accuracy: 0.5376\n",
      "Ventana 147, Época: 5, Train Loss: 0.28094539, Test Loss: 1.20255256, AUC: 0.6098, Accuracy: 0.5484\n",
      "Early stopping en la ventana 147, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 147\n",
      "-------------------\n",
      "Ventana 148 de 153\n",
      "Entrenando con semanas: [147 148 149 150 151 152 153 154 155 156], testeando en semanas [157 158 159], len train: 588, len test: 212, porcentaje: 0.73\n",
      "Iniciando ventana 148 con pesos de la ventana anterior\n",
      "Ventana 148, Época: 0, Train Loss: 0.37158743, Test Loss: 1.15740299, AUC: 0.5896, Accuracy: 0.5142\n",
      "Ventana 148, Época: 5, Train Loss: 0.26505485, Test Loss: 1.17682660, AUC: 0.5955, Accuracy: 0.5519\n",
      "Early stopping en la ventana 148, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 148\n",
      "-------------------\n",
      "Ventana 149 de 153\n",
      "Entrenando con semanas: [148 149 150 151 152 153 154 155 156 157], testeando en semanas [158 159 160], len train: 552, len test: 161, porcentaje: 0.77\n",
      "Iniciando ventana 149 con pesos de la ventana anterior\n",
      "Ventana 149, Época: 0, Train Loss: 0.49360734, Test Loss: 1.12067616, AUC: 0.6144, Accuracy: 0.5590\n",
      "Ventana 149, Época: 5, Train Loss: 0.31612125, Test Loss: 1.13954663, AUC: 0.5946, Accuracy: 0.6025\n",
      "Ventana 149, Época: 6, Train Loss: 0.30748433, Test Loss: 1.12425220, AUC: 0.6017, Accuracy: 0.5901\n",
      "Early stopping en la ventana 149, época 6\n",
      "Mejor modelo guardado en la época  1 para la ventana 149\n",
      "-------------------\n",
      "Ventana 150 de 153\n",
      "Entrenando con semanas: [149 150 151 152 153 154 155 156 157 158], testeando en semanas [159 160 161], len train: 633, len test: 136, porcentaje: 0.82\n",
      "Iniciando ventana 150 con pesos de la ventana anterior\n",
      "Ventana 150, Época: 0, Train Loss: 0.53797007, Test Loss: 1.00077939, AUC: 0.5846, Accuracy: 0.5441\n",
      "Ventana 150, Época: 5, Train Loss: 0.36702570, Test Loss: 0.99698973, AUC: 0.5621, Accuracy: 0.5441\n",
      "Ventana 150, Época: 8, Train Loss: 0.32060871, Test Loss: 1.01577437, AUC: 0.5658, Accuracy: 0.5294\n",
      "Early stopping en la ventana 150, época 8\n",
      "Mejor modelo guardado en la época  3 para la ventana 150\n",
      "-------------------\n",
      "Ventana 151 de 153\n",
      "Entrenando con semanas: [150 151 152 153 154 155 156 157 158 159], testeando en semanas [160 161 162], len train: 640, len test: 154, porcentaje: 0.81\n",
      "Iniciando ventana 151 con pesos de la ventana anterior\n",
      "Ventana 151, Época: 0, Train Loss: 0.43586516, Test Loss: 1.01257920, AUC: 0.5862, Accuracy: 0.5584\n",
      "Ventana 151, Época: 5, Train Loss: 0.32854652, Test Loss: 1.09537888, AUC: 0.5558, Accuracy: 0.5260\n",
      "Early stopping en la ventana 151, época 5\n",
      "Mejor modelo guardado en la época  0 para la ventana 151\n",
      "-------------------\n",
      "Ventana 152 de 153\n",
      "Entrenando con semanas: [151 152 153 154 155 156 157 158 159 160], testeando en semanas [161 162 163], len train: 645, len test: 134, porcentaje: 0.83\n",
      "Iniciando ventana 152 con pesos de la ventana anterior\n",
      "Ventana 152, Época: 0, Train Loss: 0.42796814, Test Loss: 1.08512509, AUC: 0.5574, Accuracy: 0.5075\n",
      "Ventana 152, Época: 5, Train Loss: 0.30792511, Test Loss: 1.06634378, AUC: 0.5876, Accuracy: 0.5522\n",
      "Ventana 152, Época: 9, Train Loss: 0.25596148, Test Loss: 1.13795578, AUC: 0.5948, Accuracy: 0.5448\n",
      "Early stopping en la ventana 152, época 9\n",
      "Mejor modelo guardado en la época  4 para la ventana 152\n",
      "-------------------\n",
      "Ventana 153 de 153\n",
      "Entrenando con semanas: [152 153 154 155 156 157 158 159 160 161], testeando en semanas [162 163 164], len train: 667, len test: 69, porcentaje: 0.91\n",
      "Iniciando ventana 153 con pesos de la ventana anterior\n",
      "Ventana 153, Época: 0, Train Loss: 0.41123948, Test Loss: 1.16352403, AUC: 0.5536, Accuracy: 0.5942\n",
      "Ventana 153, Época: 5, Train Loss: 0.34353283, Test Loss: 1.07008779, AUC: 0.5952, Accuracy: 0.6087\n",
      "Ventana 153, Época: 10, Train Loss: 0.27056196, Test Loss: 1.01768565, AUC: 0.6409, Accuracy: 0.6522\n",
      "Ventana 153, Época: 15, Train Loss: 0.22814249, Test Loss: 1.11796033, AUC: 0.6151, Accuracy: 0.6232\n",
      "Ventana 153, Época: 17, Train Loss: 0.17952573, Test Loss: 1.10726726, AUC: 0.6240, Accuracy: 0.6087\n",
      "Early stopping en la ventana 153, época 17\n",
      "Mejor modelo guardado en la época  12 para la ventana 153\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class TennisRNN(nn.Module):\n",
    "    def __init__(self, input_size_actual, input_size_previos, hidden_size, num_layers, output_size, dropout_rate):\n",
    "        super(TennisRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU para datos históricos del jugador local\n",
    "        self.gru_home = nn.GRU(\n",
    "            input_size=input_size_previos,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0\n",
    "        )\n",
    "        # GRU para datos históricos del jugador visitante\n",
    "        self.gru_away = nn.GRU(\n",
    "            input_size=input_size_previos,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0\n",
    "        )\n",
    "        # Capa de proyección para las características actuales\n",
    "        self.actual_projection = nn.Linear(input_size_actual, input_size_actual * 2)\n",
    "\n",
    "        # Capa de concatenación y fully connected\n",
    "        combined_size = hidden_size * 2 + input_size_actual * 2  \n",
    "        self.fc1 = nn.Linear(combined_size, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size//2, output_size)\n",
    "        \n",
    "    def forward(self, x_actual, x_home, x_away):\n",
    "        _, (home_features, _) = self.gru_home(x_home)\n",
    "        _, (away_features, _) = self.gru_away(x_away)\n",
    "\n",
    "        # Proyección adicional para las características actuales\n",
    "        x_actual_projection = self.actual_projection(x_actual)\n",
    "        combined = torch.cat((home_features, away_features, x_actual_projection), dim=1)\n",
    "\n",
    "        # Pasar por las capas fully connected\n",
    "        x = torch.relu(self.fc1(combined))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        # Utilizamos sigmoid para obtener un valor entre 0 y 1 (probabilidad)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# Cálculo del R2 para tener una medida de bondad de ajuste\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    # Convertir probabilidades a clases binarias\n",
    "    pred_class = (pred >= threshold).float().cpu().numpy()\n",
    "    target_class = target.cpu().numpy()\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(target_class, pred_class)\n",
    "    precision = precision_score(target_class, pred_class, zero_division=0)\n",
    "    recall = recall_score(target_class, pred_class, zero_division=0)\n",
    "    f1 = f1_score(target_class, pred_class, zero_division=0)\n",
    "    auc = roc_auc_score(target_class, pred.cpu().numpy())\n",
    " \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "total_partidos = len(actual_diferencias)\n",
    "num_previos = 50  \n",
    "input_size_actual = actual_diferencias.drop(columns=['winnerCode', 'year_week_id']).shape[1]\n",
    "input_size_previos = previos.shape[1]\n",
    "\n",
    "df_visualization_global = pd.DataFrame({\n",
    "    'Window': pd.Series(dtype='int'),\n",
    "    'Epoch': pd.Series(dtype='int'),\n",
    "    'TrainingLoss': pd.Series(dtype='float'),\n",
    "    'ValidationLoss': pd.Series(dtype='float'),\n",
    "    'Accuracy': pd.Series(dtype='float'),\n",
    "    'Precision': pd.Series(dtype='float'),\n",
    "    'Recall': pd.Series(dtype='float'),\n",
    "    'F1': pd.Series(dtype='float'),\n",
    "    'AUC': pd.Series(dtype='float'),\n",
    "})\n",
    "\n",
    "\n",
    "# Inicialización del modelo\n",
    "model = TennisRNN(\n",
    "    input_size_actual=input_size_actual,\n",
    "    input_size_previos=input_size_previos,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    output_size=1,\n",
    "    dropout_rate=0.2,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Inicializar el estado del modelo para la primera ventana\n",
    "# Parámetros para early stopping\n",
    "previous_best_model_state = None\n",
    "patience = 5  # Número de épocas a esperar antes de detener el entrenamiento si no hay mejora\n",
    "min_delta = 0.00001  # Mejora mínima requerida para considerar que hay progreso\n",
    "\n",
    "# Parámetros de entrenamiento\n",
    "epochs = 100\n",
    "view_step = 5\n",
    "\n",
    "training_weeks = 10  # Número de semanas para entrenamiento\n",
    "testing_weeks = 3    # Número de semanas para prueba\n",
    "step_size = 1        # Paso de avance entre ventanas (en semanas)\n",
    "all_year_weeks = actual_diferencias['year_week_id'].unique()\n",
    "\n",
    "total_windows = (len(all_year_weeks) - (training_weeks + testing_weeks)) // step_size + 1\n",
    "# Bucle de entrenamiento con ventanas de tiempo\n",
    "for i in range(0, len(all_year_weeks) - (training_weeks + testing_weeks) + 1, step_size):\n",
    "    # Índice de la ventana actual (comenzando desde 1)\n",
    "    current_window = i // step_size + 1\n",
    "    print(f\"Ventana {current_window} de {total_windows}\")\n",
    "\n",
    "    # Semanas para entrenamiento y prueba\n",
    "    train_year_weeks = all_year_weeks[i:i+training_weeks]\n",
    "    test_year_weeks = all_year_weeks[i+training_weeks:i+training_weeks+testing_weeks]\n",
    "   \n",
    "    train_indices = actual_diferencias[actual_diferencias['year_week_id'].isin(train_year_weeks)].index\n",
    "    test_indices = actual_diferencias[actual_diferencias['year_week_id'].isin(test_year_weeks)].index\n",
    "    \n",
    "    print(f\"Entrenando con semanas: {train_year_weeks}, testeando en semanas {test_year_weeks}, len train: {len(train_indices)}, len test: {len(test_indices)}, porcentaje: {len(train_indices)/(len(train_indices)+len(test_indices)):.2f}\")\n",
    "\n",
    "    # Comprobar si hay suficientes datos\n",
    "    if len(train_indices) < 50 or len(test_indices) < 10:\n",
    "        print(f\"Saltando ventana {current_window} por datos insuficientes: train={len(train_indices)}, test={len(test_indices)}\")\n",
    "        continue\n",
    "    \n",
    "    # Preparar los datos de entrenamiento y test\n",
    "    X_train_actual = actual_diferencias.iloc[train_indices].drop(columns=['winnerCode', 'year_week_id'])\n",
    "    Y_train_actual = actual_diferencias.iloc[train_indices]['winnerCode'].values.reshape(-1, 1)\n",
    "    \n",
    "    X_test_actual = actual_diferencias.iloc[test_indices].drop(columns=['winnerCode', 'year_week_id'])\n",
    "    Y_test_actual = actual_diferencias.iloc[test_indices]['winnerCode'].values.reshape(-1, 1)\n",
    "\n",
    "    previos_train_index= []\n",
    "    for idx in train_indices:\n",
    "        inicio = idx * num_previos\n",
    "        fin = inicio + num_previos \n",
    "        previos_train_index.extend(range(inicio, fin))\n",
    "    \n",
    "    previos_test_index= []\n",
    "    for idx in test_indices:\n",
    "        inicio = idx * num_previos\n",
    "        fin = inicio + num_previos  \n",
    "        previos_test_index.extend(range(inicio, fin))\n",
    "    \n",
    "    previos_train_home = previos_home.iloc[previos_train_index].values\n",
    "    previos_train_away = previos_away.iloc[previos_train_index].values\n",
    "    previos_test_home = previos_home.iloc[previos_test_index].values\n",
    "    previos_test_away = previos_away.iloc[previos_test_index].values\n",
    "\n",
    "    # Reshape para GRU: (n_samples, seq_length, n_features)\n",
    "    n_train_samples= len(train_indices)\n",
    "    n_test_samples= len(test_indices)\n",
    "    seq_length = num_previos\n",
    "    n_features = input_size_previos\n",
    "\n",
    "    X_train_previos_home = previos_train_home.reshape(n_train_samples, seq_length, n_features)\n",
    "    X_train_previos_away = previos_train_away.reshape(n_train_samples, seq_length, n_features)\n",
    "    X_test_previos_home = previos_test_home.reshape(n_test_samples, seq_length, n_features)\n",
    "    X_test_previos_away = previos_test_away.reshape(n_test_samples, seq_length, n_features)\n",
    "\n",
    "    # Convertir a tensores\n",
    "    tensor_X_train_actual = torch.tensor(X_train_actual.values, dtype=torch.float32).to(device)\n",
    "    tensor_Y_train_actual = torch.tensor(Y_train_actual, dtype=torch.float32).to(device)\n",
    "    tensor_X_test_actual = torch.tensor(X_test_actual.values, dtype=torch.float32).to(device)\n",
    "    tensor_Y_test_actual = torch.tensor(Y_test_actual, dtype=torch.float32).to(device)\n",
    "\n",
    "    tensor_X_train_previos_home = torch.tensor(X_train_previos_home, dtype=torch.float32).to(device)\n",
    "    tensor_X_train_previos_away = torch.tensor(X_train_previos_away, dtype=torch.float32).to(device)\n",
    "    tensor_X_test_previos_home = torch.tensor(X_test_previos_home, dtype=torch.float32).to(device)\n",
    "    tensor_X_test_previos_away = torch.tensor(X_test_previos_away, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_predictions = None\n",
    "    best_true_values = None\n",
    "    patience_counter = 0\n",
    "    epoca_mejor = 0\n",
    "\n",
    "    # Aplicar warm-up si no es la primera ventana\n",
    "    if i > 0 and previous_best_model_state is not None:\n",
    "        model.load_state_dict(previous_best_model_state)\n",
    "        print(f\"Iniciando ventana {current_window} con pesos de la ventana anterior\")\n",
    "    \n",
    "    # Entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(tensor_X_train_actual, tensor_X_train_previos_home, tensor_X_train_previos_away)\n",
    "        loss = criterion(y_pred, tensor_Y_train_actual)\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.item()\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_test_pred = model(tensor_X_test_actual, tensor_X_test_previos_home, tensor_X_test_previos_away)\n",
    "            test_loss = criterion(y_test_pred, tensor_Y_test_actual).item()\n",
    "\n",
    "            # Calcular métricas de clasificación\n",
    "            metrics = calculate_metrics(y_test_pred, tensor_Y_test_actual)\n",
    "\n",
    "            # Early stopping\n",
    "            if best_val_loss - test_loss > min_delta:\n",
    "                best_val_loss = test_loss\n",
    "                # Guardar el estado del modelo\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                patience_counter = 0\n",
    "                epoca_mejor = epoch\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Ventana {current_window}, Época: {epoch}, Train Loss: {train_loss:.8f}, Test Loss: {test_loss:.8f}, AUC: {metrics[\"auc\"]:.4f}, Accuracy: {metrics[\"accuracy\"]:.4f}')\n",
    "                # Guardar información para visualización\n",
    "                new_row = pd.DataFrame({\n",
    "                    'Window': [current_window],\n",
    "                    'Epoch': [epoch],\n",
    "                    'TrainingLoss': [train_loss],\n",
    "                    'ValidationLoss': [test_loss],\n",
    "                    'Accuracy': [metrics[\"accuracy\"]],\n",
    "                    'Precision': [metrics[\"precision\"]],\n",
    "                    'Recall': [metrics[\"recall\"]],\n",
    "                    'F1': [metrics[\"f1\"]],\n",
    "                    'AUC': [metrics[\"auc\"]],\n",
    "                })\n",
    "                df_visualization_global = pd.concat([df_visualization_global, new_row], ignore_index=True)\n",
    "                print(f\"Early stopping en la ventana {current_window}, época {epoch}\")\n",
    "                break\n",
    "                \n",
    "\n",
    "        if epoch % view_step == 0:\n",
    "            print(f'Ventana {current_window}, Época: {epoch}, Train Loss: {train_loss:.8f}, Test Loss: {test_loss:.8f}, AUC: {metrics[\"auc\"]:.4f}, Accuracy: {metrics[\"accuracy\"]:.4f}')\n",
    "            \n",
    "\n",
    "\n",
    "        # Guardar información para visualización\n",
    "        new_row = pd.DataFrame({\n",
    "            'Window': [current_window],\n",
    "            'Epoch': [epoch],\n",
    "            'TrainingLoss': [train_loss],\n",
    "            'ValidationLoss': [test_loss],\n",
    "            'Accuracy': [metrics[\"accuracy\"]],\n",
    "            'Precision': [metrics[\"precision\"]],\n",
    "            'Recall': [metrics[\"recall\"]],\n",
    "            'F1': [metrics[\"f1\"]],\n",
    "            'AUC': [metrics[\"auc\"]],\n",
    "        })\n",
    "        df_visualization_global = pd.concat([df_visualization_global, new_row], ignore_index=True)\n",
    "\n",
    "    # Cargar el mejor modelo\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)  # Cargar el mejor modelo de esta ventana\n",
    "        previous_best_model_state = copy.deepcopy(best_model_state)  # Guardar para la siguiente ventana\n",
    "        print(f\"Mejor modelo guardado en la época  {epoca_mejor} para la ventana {current_window}\")\n",
    "\n",
    "    print(\"-------------------\") \n",
    "\n",
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'tennis_rnn_model_CLASSIFICATION.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "990c6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization_global.to_csv('resultados/df_visualization_global_CLASSIFICATION.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
